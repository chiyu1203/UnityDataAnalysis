{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Session 0.0: Load packages and customised functions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "%reload_ext autoreload\n",
                "%autoreload 2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "## a useful function to generate a data list for further analysis\n",
                "import os,json,sys,itertools\n",
                "from pathlib import Path\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from locustvr_converter import preprocess_matrex_data\n",
                "from locustvr_extractor import extract_locustvr_dat\n",
                "from behavioural_classification import classify_heading_direction\n",
                "from trajectory_analysis import *\n",
                "##need to add this additional cell because useful tools are in another folder. Need to integrate these two folders one day\n",
                "current_working_directory = Path.cwd()\n",
                "parent_dir = current_working_directory.resolve().parents[0]\n",
                "if os.name == 'nt':\n",
                "    sys.path.insert(0, str(parent_dir) + \"\\\\utilities\")\n",
                "else:\n",
                "    sys.path.insert(0, str(parent_dir) + \"/utilities\")\n",
                "from useful_tools import select_animals_gpt,find_file,read_seq_config\n",
                "from data_cleaning import findLongestConseqSubseq,interp_fill"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Session 0.1: Load analysis methods in python dictionary form"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "json_file = \"./analysis_methods_dictionary.json\"\n",
                "with open(json_file, \"r\") as f:\n",
                "    analysis_methods = json.loads(f.read())\n",
                "    \n",
                "\n",
                "#Put the folder of your Unity experiment below\n",
                "#thisDataset =\"D:/MatrexVR_Swarm_Data/RunData\"\n",
                "#thisDataset =\"D:/MatrexVR_blackbackground_Data/RunData\"\n",
                "#thisDataset =\"D:/MatrexVR_grass1_Data/RunData\"\n",
                "#thisDataset =\"D:/MatrexVR_navigation_Data/RunData\"\n",
                "thisDataset =\"D:\\MatrexVR_2024_Data\\RunData\"\n",
                "#thisDataset =\"D:/MatrexVR_2024_3_Data/RunData\"\n",
                "#thisDataset =\"Z:\\DATA\\experiment_trackball_Optomotor\\locustVR\"\n",
                "#parameter name means independent variable in the experiment\n",
                "#variable_name='kappa' \n",
                "#variable_name='mu'\n",
                "variable_name='location'\n",
                "#variable_name='teleport'\n",
                "#variable_name='initial_position'\n",
                "#variable_name='agent_speed'\n",
                "exp_name=analysis_methods.get(\"experiment_name\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Session 0.2: Load animals' experiment directory into a list"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## this cell searches for a folder with csv files, usually that is the folder saving the tracking data.\n",
                "## Since data from the 4 VRs are saved in the same folder, this command will return that one folder for the 4 experiment\n",
                "dir_list = []\n",
                "if exp_name ==\"locustvr\":\n",
                "    file_type=\".dat\"\n",
                "else:\n",
                "    file_type=\".csv\"\n",
                "for root, dirs, files in os.walk(thisDataset):\n",
                "    for folder in dirs:\n",
                "        folder_path=os.path.join(root,folder)\n",
                "        if any(name.endswith(file_type) for name in os.listdir(folder_path)):\n",
                "            dir_list.append(folder_path.replace(\"\\\\\", \"/\"))\n",
                "\n",
                "print(f\"these directories are found {dir_list}\")\n",
                "dir_list.sort()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Session 0.3: pass temperature information into each folder"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "##This cell is used to move data of the thermo-humidity logger to animals'folder\n",
                "import shutil\n",
                "#tmp_file_name='locustVR_20250624_2050628.txt'\n",
                "#tmp_file_name='DL220THP_Thermo2_241012_241014.csv'\n",
                "tmp_file_name='DL220THP_Thermo3_250709_250710.csv'\n",
                "tmp_source=os.path.join('Z:/Users/chiyu',tmp_file_name)\n",
                "for this_dir in dir_list:\n",
                "    tmp_new_dir = os.path.join(this_dir,tmp_file_name)\n",
                "    if os.path.isfile(tmp_new_dir):\n",
                "        print(\"Found EL USB temperature file in the new directory already\")\n",
                "    else:\n",
                "        shutil.copy(tmp_source, tmp_new_dir)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Session 1.0: Create curated dataset based on a list of experiment directories"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#This function receives directory path that contains the 4-VR data and save the tracking + stimulus information as h5 file\n",
                "pattern=\"*.h5\"\n",
                "#pattern=\"VR*.parquet\"\n",
                "for this_dir in dir_list:\n",
                "    if \"archive\" in this_dir:\n",
                "        print(f\"skip archive folder for {this_dir}\")\n",
                "        continue\n",
                "    if any(Path(this_dir).glob(pattern)) and analysis_methods.get(\"overwrite_curated_dataset\")==False:\n",
                "        print(f\"curated matrexvr h5 database found in {this_dir}. Skip this file\")\n",
                "        continue\n",
                "    elif exp_name ==\"locustvr\":\n",
                "        print(f\"no curated locustvr h5 database in {this_dir}. Create curated file\")\n",
                "        extract_locustvr_dat(this_dir,analysis_methods)\n",
                "    else:\n",
                "        print(f\"no curated matrexvr h5 database in {this_dir}. Create curated file\")\n",
                "        preprocess_matrex_data(this_dir,analysis_methods)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Session 2.0: analyse animal's trajectory"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Session 2.1: select animal based on condition and return which a directory list and a list of vr rig number to specify which animal to analyse"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# build up dir_list of animals based on condition.\n",
                "dir_list = []\n",
                "file_type=\".h5\"\n",
                "using_google_sheet=True\n",
                "sheet_name = \"Unity_MatrexVR\"\n",
                "scene_name=analysis_methods.get(\"experiment_name\")\n",
                "if analysis_methods.get(\"load_individual_data\") == True:\n",
                "    if using_google_sheet==True:\n",
                "        database_id = \"1UL4eEUrQMapx9xz11-IyOSlPBcep1I9vBJ2uGgVudb8\"\n",
                "                #https://docs.google.com/spreadsheets/d/1UL4eEUrQMapx9xz11-IyOSlPBcep1I9vBJ2uGgVudb8/edit?usp=sharing\n",
                "        url = f\"https://docs.google.com/spreadsheets/d/{database_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}\"\n",
                "        #df = pd.read_excel(url, engine='openpyxl')## use this function if the file is not google sheet but uploaded excel file\n",
                "        df = pd.read_csv(url)\n",
                "    else:\n",
                "        excel_file_path = \"Z:/DATA/experiment_trackball_Optomotor/Locusts Management.xlsx\"\n",
                "        print(f\"using a database {excel_file_path} from the server but this file might be outdated\")\n",
                "        # Create a 'with' statement to open and read the Excel file\n",
                "        with pd.ExcelFile(excel_file_path) as xls:\n",
                "            # Read the Excel sheet into a DataFrame with the sheet name (folder name)\n",
                "            df = pd.read_excel(xls, sheet_name)\n",
                "        ##list up the conditions and answers as strings for input argument to select animal. One condition must pair with one answer\n",
                "    if analysis_methods.get(\"select_animals_by_condition\") == True:\n",
                "        #animal_of_interest=select_animals_gpt(df,\"Independent variable1\",variable_name,\"Independent variable2\",\"bifuration_vr_locust_sta_black_locust\",\"Excluding this animal from analysis (Usually when animals die or molt, T/F)\",\"F\")\n",
                "        #animal_of_interest=select_animals_gpt(df,\"Independent variable1\",variable_name,\"Excluding this animal from analysis (Usually when animals die or molt, T/F)\",\"F\")\n",
                "        #animal_of_interest=select_animals_gpt(df,\"Independent variable2\",\"marching_band_black_vs_leader_locust_animated_vs_inanimated\",\"Excluding this animal from analysis (Usually when animals die or molt, T/F)\",\"F\")\n",
                "        #animal_of_interest=select_animals_gpt(df,\"Independent variable2\",\"marching_band_black_vs_leader_locust_constant_speed&distance\",\"Excluding this animal from analysis (Usually when animals die or molt, T/F)\",\"F\")\n",
                "        #animal_of_interest=select_animals_gpt(df,\"Independent variable (list up all of them in the experiment)\",variable_name)\n",
                "        animal_of_interest=select_animals_gpt(df,\"Independent variable2\",\"teleport_ring7_space8\",\"Excluding this animal from analysis (Usually when animals die or molt, T/F)\",\"F\")\n",
                "    else:\n",
                "        animal_of_interest=df\n",
                "    folder_name=animal_of_interest[\"folder name\"].values\n",
                "    dir_tile=np.tile(thisDataset, (len(folder_name), 1))\n",
                "    vr_no=animal_of_interest[\"VR number\"].values\n",
                "    vr_no = vr_no.astype('int')\n",
                "    no_food=animal_of_interest[\"Food retriction (-1 or the number of hours)\"].values\n",
                "    no_food = no_food.astype('int')\n",
                "    dir_list = [''.join([x[0], '/', y]) for x,y in zip(dir_tile,folder_name)]\n",
                "    dir_dict = zip(dir_list, vr_no.tolist())\n",
                "else:\n",
                "    for root, dirs, files in os.walk(thisDataset):\n",
                "        for folder in dirs:\n",
                "            folder_path=os.path.join(root,folder)\n",
                "            if any(name.endswith(file_type) for name in os.listdir(folder_path)):\n",
                "                dir_list.append(folder_path.replace(\"\\\\\", \"/\"))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Session 2.2: load hdf files and sequence config of those animals and create a common index between each others"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 57,
            "metadata": {},
            "outputs": [],
            "source": [
                "trial_evaluation_list=[]\n",
                "raster_list=[]\n",
                "seq_config_list=[]\n",
                "animal_id=0\n",
                "for this_dir,this_vr in zip(dir_list,vr_no):\n",
                "    if Path(this_dir).is_dir()==False:\n",
                "        continue\n",
                "    if analysis_methods.get(\"time_series_analysis\")==True:\n",
                "        summary_pattern = f\"VR{this_vr}*score_full.h5\"\n",
                "        xy_pattern = f\"VR{this_vr}*XY_full.h5\"\n",
                "    else:\n",
                "        summary_pattern = f\"VR{this_vr}*score.h5\"\n",
                "        xy_pattern = f\"VR{this_vr}*XY.h5\"\n",
                "    found_result = find_file(Path(this_dir), summary_pattern)     \n",
                "    trial_evaluation = pd.read_hdf(found_result)\n",
                "    trial_evaluation['VR'] = np.tile(f\"VR{this_vr}\", (len(trial_evaluation), 1))\n",
                "    trial_evaluation['VR'] =trial_evaluation[\"VR\"]+\"_\"+trial_evaluation[\"fname\"]\n",
                "    trial_evaluation.insert(0, 'animal_id',np.repeat(animal_id,trial_evaluation.shape[0]))\n",
                "    trial_evaluation_list.append(trial_evaluation)\n",
                "    found_result = find_file(Path(this_dir), xy_pattern)        \n",
                "    dfxy = pd.read_hdf(found_result)\n",
                "    dfxy['VR'] = np.tile(f\"VR{this_vr}\", (len(dfxy), 1))\n",
                "    dfxy['VR'] =dfxy[\"VR\"]+\"_\"+dfxy[\"fname\"]\n",
                "    dfxy.insert(0, 'animal_id',np.repeat(animal_id,dfxy.shape[0]))\n",
                "    raster_list.append(dfxy)\n",
                "    seq_config_pattern=f\"*sequenceConfig.json\"\n",
                "    seq_config_file=find_file(Path(this_dir), seq_config_pattern)\n",
                "    seq_config_pd=read_seq_config(seq_config_file)\n",
                "    seq_config_pd['VR']=trial_evaluation['VR'].values\n",
                "    seq_config_pd.insert(0, 'step_id',np.arange(seq_config_pd.shape[0]))\n",
                "    seq_config_pd.insert(0, 'animal_id',np.repeat(animal_id,seq_config_pd.shape[0]))\n",
                "    seq_config_list.append(seq_config_pd)\n",
                "    animal_id +=1"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Session 2.2.1: concatenate animal's data from the list into a big pandas dataframe"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 58,
            "metadata": {},
            "outputs": [],
            "source": [
                "trial_evaluation_all=pd.concat(trial_evaluation_list)\n",
                "seq_config_all=pd.concat(seq_config_list)\n",
                "raster_all=pd.concat(raster_list)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "raster_all"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Session 2.2.1.5: check each animal's walking distance durning ISI"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "trial_evaluation_all[['VR_num', 'Date','Time']] = trial_evaluation_all['VR'].str.split('_', expand=True)\n",
                "trial_evaluation_ISI=trial_evaluation_all[trial_evaluation_all['density']==0]\n",
                "ISI_evaluation_aba = trial_evaluation_ISI.groupby('animal_id').agg(\n",
                "    travel_distance=('distTotal', 'mean'),\n",
                "    vr_no=('VR_num', 'first'),\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sns.histplot(data=ISI_evaluation_aba, x=\"travel_distance\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "trial_evaluation_all[['VR_num', 'Date','Time']] = trial_evaluation_all['VR'].str.split('_', expand=True)\n",
                "trial_evaluation_ISI=trial_evaluation_all[trial_evaluation_all['type']==\"LocustBand\"]\n",
                "evaluation_aba_prechoice = trial_evaluation_ISI.groupby('animal_id').agg(\n",
                "    travel_distance=('distTotal', 'mean'),\n",
                "    travel_vector_x=('distX', 'mean'),\n",
                ")\n",
                "trial_evaluation_ISI=trial_evaluation_all[trial_evaluation_all['type']==\"SimulatedLocust\"]\n",
                "evaluation_aba_network = trial_evaluation_ISI.groupby('animal_id').agg(\n",
                "    travel_distance=('distTotal', 'mean'),\n",
                "    travel_vector_x=('distX', 'mean'),\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#travel distance animal by animal\n",
                "ax=evaluation_aba_prechoice.plot.scatter(x='travel_distance',y='travel_vector_x')\n",
                "ax2=evaluation_aba_network.plot.scatter(x='travel_distance',y='travel_vector_x')\n",
                "ax.set(ylim=(-100,1250))\n",
                "ax2.set(ylim=(-100,1250))\n",
                "ax=evaluation_aba_prechoice.plot.hist(column=['travel_distance'],figsize=(10, 8))\n",
                "ax2=evaluation_aba_network.plot.hist(column=['travel_distance'],figsize=(10, 8))\n",
                "#travel distance trial by trial\n",
                "ax=trial_evaluation_all.plot.hist(column=['distTotal'],by=\"type\", figsize=(10, 8))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Session 2.2.2: select active moving trials for plotting only or include all the trials with good tracking"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 59,
            "metadata": {},
            "outputs": [],
            "source": [
                "body_length=analysis_methods.get(\"body_length\")  # Default body length if not specified\n",
                "good_tracking=trial_evaluation_all['loss']< 0.05\n",
                "active_trials=(good_tracking) & (trial_evaluation_all[\"distTotal\"]>body_length*6)\n",
                "# 6 body length seems to reduce enough autocorrelation of heading direction based on https://github.com/jgraving/sayin_locust_mixture_model/blob/main/locust_mixture_model.ipynb\n",
                "if analysis_methods.get(\"active_trials_only\"):\n",
                "    trial_evaluation_interest=trial_evaluation_all[active_trials]\n",
                "else:\n",
                "    trial_evaluation_interest=trial_evaluation_all[good_tracking]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "this_evaluation"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Session 2.2.3: plot the distribution of the heading angle along x (cos) or y (sin) axis, histogram of heading direction, walking distance"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "trial_count=0\n",
                "plot_individual_data=True\n",
                "for key,grp  in seq_config_all.groupby('configFile'):\n",
                "    print(f\"analyse {key}\")\n",
                "    this_evaluation=trial_evaluation_interest.loc[trial_evaluation_interest['VR'].isin(grp['VR'])]\n",
                "    if plot_individual_data:\n",
                "        for this_animal_id, this_animal_data in this_evaluation.groupby('animal_id'):\n",
                "            plot_sercansincos(this_animal_data,analysis_methods,key.split(\".\")[0],'trial',vr_num=this_animal_id)\n",
                "            plot_travel_histrogram(this_animal_data,analysis_methods,key.split(\".\")[0],'trial',vr_num=this_animal_id)\n",
                "            plot_circular_histrogram(this_animal_data,analysis_methods,key.split(\".\")[0],'trial',vr_num=this_animal_id)\n",
                "\n",
                "    else:\n",
                "        print(this_evaluation.shape[0])\n",
                "        plot_sercansincos(this_evaluation,analysis_methods,key.split(\".\")[0],'trial')\n",
                "        plot_travel_histrogram(this_evaluation,analysis_methods,key.split(\".\")[0],'trial')\n",
                "        plot_circular_histrogram(this_evaluation,analysis_methods,key.split(\".\")[0],'trial')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ith_step_heading=10\n",
                "plot_individual_data=False\n",
                "for key,grp  in seq_config_all.groupby('configFile'):\n",
                "    print(f\"analyse {key}\")\n",
                "    df_trials=raster_all.loc[raster_all['VR'].isin(grp['VR']) & (raster_all['VR'].isin(trial_evaluation_interest['VR']))]\n",
                "    heading_of_interest=[]\n",
                "    for key,this_session in df_trials.groupby('VR'):\n",
                "        heading_of_interest.append(this_session.iloc[1]['heading'])\n",
                "    angles=np.array(heading_of_interest)\n",
                "    fig, axs = plt.subplots(1, 2, figsize=(5, 8), subplot_kw={'projection': 'polar'},\n",
                "                        layout='constrained')\n",
                "    ax=axs[0]\n",
                "    #fig, (ax1,ax2) = plt.subplot(121, polar=True)\n",
                "    #ax = plt.subplot(111, polar=True)\n",
                "    ax.hist(angles, bins=24, alpha=0.75)\n",
                "    #ax.set_xticks([])\n",
                "    ax.set_yticks([5,10])\n",
                "    ax.set_xticklabels([])\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Session 2.2.4: plot animal's trajectory across trials (can choose whether to plot individual animal's trajectory or all animal's trajectory in the same plot)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plot_individual_data=False\n",
                "for key,grp  in seq_config_all.groupby('configFile'):\n",
                "    print(f\"analyse {key}\")\n",
                "    df_trials=raster_all.loc[raster_all['VR'].isin(grp['VR']) & (raster_all['VR'].isin(trial_evaluation_interest['VR']))]\n",
                "    if plot_individual_data:\n",
                "        for this_animal_id, this_animal_data in df_trials.groupby('animal_id'):\n",
                "            plot_sercantrajec(this_animal_data,analysis_methods,key.split(\".\")[0],'trial',trajec_lim=500,vr_num=this_animal_id)\n",
                "    else:\n",
                "        plot_sercantrajec(df_trials,analysis_methods,key.split(\".\")[0],'trial',trajec_lim=500,vr_num='all')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Session 2.2.4.5: plot heading angle or polarisation index across time."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def compute_polarization(v_arr):\n",
                "    \"\"\"\n",
                "    Compute polarization (alignment).\n",
                "\n",
                "    Parameters\n",
                "    ----------\n",
                "    v_arr : np.ndarray\n",
                "        Array of shape (T, N, D) — velocities for N individuals in D dimensions.\n",
                "\n",
                "    Returns\n",
                "    -------\n",
                "    P : np.ndarray\n",
                "        Polarization time series of shape (T,).\n",
                "    \"\"\"\n",
                "    # 1) Compute speeds (magnitude of velocity vectors) → (T, N)\n",
                "    speeds = np.linalg.norm(v_arr, axis=-1)\n",
                "\n",
                "    # 2) Normalize all velocity vectors to unit length\n",
                "    #    (may produce NaNs if speeds == 0)\n",
                "    vhat = v_arr / speeds[..., None]\n",
                "\n",
                "    # 3) Mean direction across individuals → (T, D)\n",
                "    mean_dir = vhat.mean(axis=1)\n",
                "\n",
                "    # 4) Polarization = magnitude of the mean direction → (T,)\n",
                "    P = np.linalg.norm(mean_dir, axis=-1)\n",
                "\n",
                "    return P"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plot_individual_data=False\n",
                "for key,grp  in seq_config_all.groupby('configFile'):\n",
                "    print(f\"analyse {key}\")\n",
                "    df_trials=raster_all.loc[raster_all['VR'].isin(grp['VR']) & (raster_all['VR'].isin(trial_evaluation_interest['VR']))]\n",
                "    #select certain pair of animals to plot depending on the condition\n",
                "    if \"animated\" in key:\n",
                "        figure_title='swarm'\n",
                "    elif \"1toself\" in key:\n",
                "        figure_title='1 to self'\n",
                "    elif \"1to1\" in key:\n",
                "        figure_title='1 to 1'\n",
                "    elif \"unidirection\" in key:\n",
                "        figure_title='unidirection'\n",
                "    for this_trial_time, this_trial_data in df_trials.groupby('fname'):\n",
                "        plt.figure()\n",
                "        heading_list=[]\n",
                "        x_diff_list=[]\n",
                "        y_diff_list=[]\n",
                "        (x_diff_vr12,y_diff_vr12,x_diff_vr34,y_diff_vr34)=(None,None,None,None)\n",
                "        for vr_value_time, df_vr in this_trial_data.groupby('VR'):\n",
                "            vr_value=vr_value_time.split('_')[0]\n",
                "            plt.plot(df_vr['ts'],df_vr['heading'],label=f'{vr_value}')\n",
                "            heading_list.append(df_vr['heading'].values)\n",
                "            x_diff_list.append(np.diff(df_vr['X'].values))\n",
                "            y_diff_list.append(np.diff(df_vr['Y'].values))\n",
                "            if vr_value==\"VR1\":\n",
                "                x_diff_vr12=np.diff(df_vr['X'].values)\n",
                "                y_diff_vr12=np.diff(df_vr['Y'].values)\n",
                "            if vr_value==\"VR2\" and x_diff_vr12 is not None:\n",
                "                x_diff_vr12=np.column_stack((x_diff_vr12,np.diff(df_vr['X'].values)))\n",
                "                y_diff_vr12=np.column_stack((y_diff_vr12,np.diff(df_vr['Y'].values)))\n",
                "            if vr_value==\"VR3\":\n",
                "                x_diff_vr34=np.diff(df_vr['X'].values)\n",
                "                y_diff_vr34=np.diff(df_vr['Y'].values)\n",
                "            if vr_value==\"VR4\" and x_diff_vr34 is not None:\n",
                "                x_diff_vr34=np.column_stack((x_diff_vr34,np.diff(df_vr['X'].values)))\n",
                "                y_diff_vr34=np.column_stack((y_diff_vr34,np.diff(df_vr['Y'].values)))\n",
                "        plt.title(f'Trial time: {this_trial_time}; Condition: {figure_title}')\n",
                "        plt.legend()\n",
                "        plt.xlabel('Time (s)')\n",
                "        plt.ylabel('Heading (radians')\n",
                "\n",
                "        if \"1to1\" in key:\n",
                "            if type(x_diff_vr12)==np.ndarray and x_diff_vr12.ndim ==2:\n",
                "                ts_vr12=np.transpose(np.tile(np.diff(df_vr['ts'].values),(x_diff_vr12.shape[1],1)))\n",
                "                Vx_arr_vr12=x_diff_vr12/ts_vr12\n",
                "                Vy_arr_vr12=y_diff_vr12/ts_vr12\n",
                "                V_arr_vr12=np.dstack((Vx_arr_vr12,Vy_arr_vr12))\n",
                "                polarisation_12=compute_polarization(V_arr_vr12)\n",
                "            else:\n",
                "                print(this_trial_time)\n",
                "                print(\"Missing one of the animal from VR1 or VR2, so skip analysis of 1 to 1 interaction\")\n",
                "                polarisation_12=None\n",
                "            if type(x_diff_vr34)==np.ndarray and x_diff_vr34.ndim ==2:\n",
                "                ts_vr34=np.transpose(np.tile(np.diff(df_vr['ts'].values),(x_diff_vr34.shape[1],1)))\n",
                "                Vx_arr_vr34=x_diff_vr34/ts_vr34\n",
                "                Vy_arr_vr34=y_diff_vr34/ts_vr34            \n",
                "                V_arr_vr34=np.dstack((Vx_arr_vr34,Vy_arr_vr34))\n",
                "                polarisation_34=compute_polarization(V_arr_vr34)\n",
                "            else:\n",
                "                print(this_trial_time)\n",
                "                print(\"Missing one of the animal from VR3 or VR4, so skip analysis of 1 to 1 interaction\")\n",
                "                polarisation_34=None  \n",
                "            fig,(ax,ax2)=plt.subplots(nrows=1, ncols=2, figsize=(12, 6), tight_layout=True)\n",
                "            ax.set(title=f'Trial time: {this_trial_time}',xlabel='Time (s)')\n",
                "            if polarisation_12 is not None:\n",
                "                ax.scatter(df_vr['ts'].values[1:],polarisation_12)\n",
                "                ax2.hist(polarisation_12)\n",
                "            if polarisation_34 is not None:\n",
                "                ax.scatter(df_vr['ts'].values[1:],polarisation_34)\n",
                "                ax2.hist(polarisation_34)\n",
                "        else:\n",
                "            heading_array=np.array(heading_list)\n",
                "            Vx_arr=np.array(x_diff_list)/np.diff(df_vr['ts'].values)\n",
                "            Vy_arr=np.array(y_diff_list)/np.diff(df_vr['ts'].values)\n",
                "            V_arr=np.dstack((np.transpose(Vx_arr),np.transpose(Vy_arr)))\n",
                "            polarisation=compute_polarization(V_arr)\n",
                "            #mean_dir=circmean(heading_array,axis=0)\n",
                "            #magnitude_direction = np.linalg.norm(mean_dir, axis=-1)\n",
                "            fig,(ax,ax2)=plt.subplots(nrows=1, ncols=2, figsize=(12, 6), tight_layout=True)\n",
                "            ax.scatter(df_vr['ts'].values[1:],polarisation)\n",
                "            ax.set(title=f'Trial time: {this_trial_time}',xlabel='Time (s)')\n",
                "            ax2.hist(polarisation)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Session 2.2.5: do further analysis on the animal's choice trial by trial"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "left_right_preference_all=[]\n",
                "oi_preference_all=[]\n",
                "pi_preference_all=[]\n",
                "labels_all=[]\n",
                "for this_animal_id,this_animal_data in trial_evaluation_interest.groupby('animal_id'):\n",
                "    left_right_preference_this_animal=[]\n",
                "    oi_preference_this_animal=[]\n",
                "    pi_preference_this_animal=[]\n",
                "    labels_this_animal=[]\n",
                "    for this_fname,this_data in this_animal_data.groupby('fname'):\n",
                "        this_trial=raster_all.loc[raster_all['VR'].values==this_data['VR'].values]    \n",
                "        labels,oi,pi,pi_follow_of_only,left_right_preference=classify_heading_direction(this_trial['heading'].values,0)\n",
                "        left_right_preference_this_animal.append(left_right_preference)\n",
                "        oi_preference_this_animal.append(oi)\n",
                "        pi_preference_this_animal.append(pi_follow_of_only)\n",
                "        labels_this_animal.append(labels)\n",
                "    left_right_preference_all.append(left_right_preference_this_animal)\n",
                "    oi_preference_all.append(oi_preference_this_animal)\n",
                "    pi_preference_all.append(pi_preference_this_animal)\n",
                "    labels_all.append(labels_this_animal)\n",
                "trial_evaluation_interest.insert(0, 'left_right_preference', np.hstack(left_right_preference_all))\n",
                "trial_evaluation_interest.insert(0, 'optic_flow_preference',np.hstack(oi_preference_all))\n",
                "trial_evaluation_interest.insert(0, 'directional_cues_preference', np.hstack(pi_preference_all))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Session 2.2.5.1: plot the preference trial by trial"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plot_individual_data=True\n",
                "for key,grp  in seq_config_all.groupby('configFile'):\n",
                "    print(f\"analyse {key}\")\n",
                "    this_evaluation=trial_evaluation_interest.loc[trial_evaluation_interest['VR'].isin(grp['VR'])]\n",
                "    if plot_individual_data:\n",
                "        for this_animal_id, this_animal_data in this_evaluation.groupby('animal_id'):\n",
                "            sns.jointplot(data=this_animal_data.reset_index(drop=True), x=\"left_right_preference\", y=\"directional_cues_preference\")\n",
                "    else:\n",
                "        sns.jointplot(data=this_evaluation.reset_index(drop=True), x=\"left_right_preference\", y=\"directional_cues_preference\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Session 2.2.5.2: a quick way to plot left right preference animal by animal"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plot_individual_data=False\n",
                "left_right_preference_all=[]\n",
                "conditions_this_analysis=[]\n",
                "for key,grp  in seq_config_all.groupby('configFile'):\n",
                "    print(f\"analyse {key}\")\n",
                "    df_trials=raster_all.loc[raster_all['VR'].isin(grp['VR']) & (raster_all['VR'].isin(trial_evaluation_interest['VR']))]\n",
                "    if plot_individual_data:\n",
                "        left_right_preference_this_condition=[]\n",
                "        for this_animal_id, this_animal_data in df_trials.groupby('animal_id'):\n",
                "            l,oi,pi,pi_follow_of_only,left_right_preference=classify_heading_direction(this_animal_data['heading'].values,0)\n",
                "            left_right_preference_this_condition.append(left_right_preference)\n",
                "        left_right_preference_all.append(left_right_preference_this_condition)\n",
                "        conditions_this_analysis.append(key)\n",
                "    else:\n",
                "        l,oi,pi,pi_follow_of_only,left_right_preference=classify_heading_direction(df_trials['heading'].values,0)\n",
                "        left_right_preference_all.append(left_right_preference)\n",
                "### plot individual left/right preference for each trial condition. This can be used when we not pooling data across trial condition\n",
                "for left_right_preference_this_condition,sequence_config_this_condition in zip(left_right_preference_all,conditions_this_analysis):\n",
                "    this_data=np.column_stack(left_right_preference_this_condition)\n",
                "    data=this_data[0,:]\n",
                "    plot_scatter_violin(data,sequence_config_this_condition)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Session 2.2.5.3: when plotting left right preference animal by animal across trial conditions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## firstly, sort out the trial condition based on alphabetically order\n",
                "trial_type_list=seq_config_all['configFile'].unique()\n",
                "trial_type_list[2:]=sorted(trial_type_list[2:], key=str,reverse=True)\n",
                "trial_type_list[:2]=sorted(trial_type_list[:2], key=str,reverse=True)\n",
                "print(trial_type_list)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": [
                "## select trial type for further analysis. Note: only pick two at a time\n",
                "#trial_type_of_interest=[trial_type_list[8],trial_type_list[5]]\n",
                "#trial_type_of_interest=[trial_type_list[5],trial_type_list[8]]\n",
                "trial_type_of_interest=[trial_type_list[5],trial_type_list[7]] #data from the constant distance experiment in the constant speed & constatnt distance dataset\n",
                "#trial_type_of_interest=[trial_type_list[6],trial_type_list[9]]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plot_individual_data=True\n",
                "labels_all=[]\n",
                "conditions_this_analysis=[]\n",
                "for key,grp  in seq_config_all.groupby('configFile'):\n",
                "    if key in trial_type_of_interest:\n",
                "        print(f\"analyse {key}\")\n",
                "        df_trials=raster_all.loc[raster_all['VR'].isin(grp['VR']) & (raster_all['VR'].isin(trial_evaluation_interest['VR']))]\n",
                "        if plot_individual_data:\n",
                "            labels_this_condition=[]\n",
                "            for this_animal_id, this_animal_data in df_trials.groupby('animal_id'):\n",
                "\n",
                "                labels,oi,pi,pi_follow_of_only,left_right_preference=classify_heading_direction(this_animal_data['heading'].values,0)\n",
                "                labels_this_condition.append(labels)\n",
                "                print(this_animal_id,this_animal_data['VR'].values[0])\n",
                "            labels_all.append(labels_this_condition)\n",
                "            conditions_this_analysis.append(key)\n",
                "        else:\n",
                "            labels,oi,pi,pi_follow_of_only,left_right_preference=classify_heading_direction(df_trials['heading'].values,0)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [],
            "source": [
                "## calculate the orietnate epochs for left and right\n",
                "epochs_arr=np.zeros((len(trial_type_of_interest)*2,len(labels_all[0])))\n",
                "if len(trial_type_of_interest)==1:\n",
                "    for j in range(len(labels_all[0])):\n",
                "            epochs_arr[0,j]=sum(labels_all[0][j]==\"for_left\")\n",
                "            epochs_arr[1,j]=sum(labels_all[0][j]==\"for_right\")\n",
                "else:\n",
                "    for i in range(len(trial_type_of_interest)):\n",
                "        for j in range(len(labels_all[0])):\n",
                "            if i==0:\n",
                "                epochs_arr[i,j]=sum(labels_all[i][j]==\"for_left\")\n",
                "                epochs_arr[i+2,j]=sum(labels_all[i][j]==\"for_right\")\n",
                "            else:\n",
                "                epochs_arr[i,j]=sum(labels_all[i][j]==\"for_left\")\n",
                "                epochs_arr[i+2,j]=sum(labels_all[i][j]==\"for_right\")\n",
                "## sum the epochs across trial types\n",
                "if len(trial_type_of_interest)==1:\n",
                "    epochs_for_L=epochs_arr[0,:]\n",
                "    epochs_for_R=epochs_arr[1,:]\n",
                "else:\n",
                "    epochs_for_L=epochs_arr[0,:]+epochs_arr[1,:]\n",
                "    epochs_for_R=epochs_arr[2,:]+epochs_arr[3,:]\n",
                "## when summing the epochs for a particular agent type, we need to flip the epochs for left or right to meet the design of the experiment\n",
                "if len(trial_type_of_interest[0].split(\"_x_\"))==1:\n",
                "    epochs_for_exp=epochs_for_L\n",
                "    epochs_for_con=epochs_for_R\n",
                "elif trial_type_of_interest[0].split(\"_x_\")[1].split(\".\")[0]=='gregarious_animated':\n",
                "    epochs_for_exp=epochs_arr[0,:]+epochs_arr[3,:]\n",
                "    epochs_for_con=epochs_arr[1,:]+epochs_arr[2,:]\n",
                "else:\n",
                "    epochs_for_exp=epochs_arr[1,:]+epochs_arr[2,:]\n",
                "    epochs_for_con=epochs_arr[0,:]+epochs_arr[3,:]\n",
                "## calcualte agent preference and left right preference\n",
                "agent_preference=(epochs_for_exp-epochs_for_con)/(epochs_for_exp+epochs_for_con)\n",
                "left_right_preference=(epochs_for_L-epochs_for_R)/(epochs_for_L+epochs_for_R)\n",
                "#np.savetxt('BA_BI.csv',np.transpose(agent_preference))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[-0.52941176 -0.18367347 -0.26732673 -0.55555556 -0.92405063  0.02857143\n",
                        " -0.05376344 -0.38983051 -0.31818182 -0.6350365  -0.61165049 -0.7037037\n",
                        " -0.4        -0.51612903 -0.42056075 -0.66666667 -0.35849057  0.07692308\n",
                        " -0.16216216 -0.47058824  0.59259259 -0.03846154 -0.2        -0.34375\n",
                        "  0.0625     -0.57446809 -0.62962963 -0.68571429 -0.36416185 -0.7037037\n",
                        "  0.23529412 -0.09259259 -0.06666667 -0.61702128 -0.02702703]\n"
                    ]
                }
            ],
            "source": [
                "print(agent_preference)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [],
            "source": [
                "np.savetxt('exp_con_preference_constant_distanceT.csv',np.transpose(agent_preference))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## plot the result\n",
                "fig_parent=trial_type_of_interest[0].split(\".\")[0]\n",
                "fig_name=f\"agent_{fig_parent}\"\n",
                "plot_scatter_violin(agent_preference,fig_name)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "arr = np.loadtxt('exp_con_preference_constant_speed.csv',\n",
                "\t\t\t\tdelimiter=\",\")\n",
                "display(arr)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 71,
            "metadata": {},
            "outputs": [],
            "source": [
                "preference_across_assays=np.vstack((agent_preference,arr[0,:]))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 78,
            "metadata": {},
            "outputs": [],
            "source": [
                "preference_across_assays_noNaN=preference_across_assays[:,~np.isnan(preference_across_assays[1,:])]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 95,
            "metadata": {},
            "outputs": [],
            "source": [
                "preference_across_assays_no1=preference_across_assays_noNaN[:,(preference_across_assays_noNaN[1,:]!=1) & (preference_across_assays_noNaN[1,:]!=-1)]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 96,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 600x600 with 1 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "fig,ax=plt.subplots(nrows=1, ncols=1, figsize=(6, 6), tight_layout=True)\n",
                "ax.scatter(preference_across_assays_no1[0,:],preference_across_assays_no1[1,:])\n",
                "ax.set(xlim=(-1,1),ylim=(-1,1),xticks=[-1,0,1],yticks=[-1,0,1],xlabel='constant distance condition',ylabel='constant speed condition',title='preference index across conditions')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 97,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "2.639057329615258\n",
                        "2.3303177453847335\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "c:\\Users\\neuroPC\\anaconda3\\envs\\matrexvr_analysis\\Lib\\site-packages\\sklearn\\metrics\\cluster\\_supervised.py:58: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and continuous values for target\n",
                        "  warnings.warn(msg, UserWarning)\n",
                        "c:\\Users\\neuroPC\\anaconda3\\envs\\matrexvr_analysis\\Lib\\site-packages\\sklearn\\metrics\\cluster\\_supervised.py:58: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and continuous values for target\n",
                        "  warnings.warn(msg, UserWarning)\n"
                    ]
                }
            ],
            "source": [
                "from sklearn.metrics import mutual_info_score\n",
                "print(mutual_info_score(preference_across_assays_no1[0,:],preference_across_assays_no1[1,:]))\n",
                "print(mutual_info_score(preference_across_assays_noNaN[0,:],preference_across_assays_noNaN[1,:]))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### (deprecated) Session 2.2.2: combine tables in the two lists in to 2 big tables"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# When using spatial discretization, information about tracking quality is not logged in the dfXY, \n",
                "# hence there is a need to pass that information from df\n",
                "def connect_two_tables(dir_list,analysis_methods,test_parameter='kappa',vr_no=[]):\n",
                "    scene_name=analysis_methods.get(\"experiment_name\")\n",
                "    df_all=[]\n",
                "    dfxy_all=[]\n",
                "    dir_iterator=[]\n",
                "    if len(vr_no)>0:\n",
                "        print(\"i am using list\")\n",
                "        dir_iterator=zip(dir_list,vr_no)\n",
                "    elif type(dir_list)==dict:\n",
                "        print(\"i am using dictionary\")\n",
                "        dir_iterator=dir_dict\n",
                "    else:\n",
                "        print(\"there is a bug\")\n",
                "        return df_all,dfxy_all\n",
                "    for this_dir,this_vr in dir_iterator:\n",
                "        if Path(this_dir).is_dir()==False:\n",
                "            continue\n",
                "        summary_pattern = f\"VR{this_vr}*score_full.h5\"\n",
                "        xy_pattern = f\"VR{this_vr}*XY_full.h5\"\n",
                "        found_result = find_file(Path(this_dir), summary_pattern)        \n",
                "        df = pd.read_hdf(found_result)\n",
                "        df['VR'] = np.tile(f\"VR{this_vr}\", (len(df), 1))\n",
                "        df['VR'] =df[\"VR\"]+\"_\"+df[\"fname\"]\n",
                "        #COL = MplColorHelper(colormap_name, 0, num_independent_variable)\n",
                "        found_result = find_file(Path(this_dir), xy_pattern)\n",
                "        dfxy = pd.read_hdf(found_result)\n",
                "        dfxy['VR'] = np.tile(f\"VR{this_vr}\", (len(dfxy), 1))\n",
                "        dfxy['VR'] =dfxy[\"VR\"]+\"_\"+dfxy[\"fname\"]\n",
                "        #df.loc[(df[\"distTotal\"]<10.0) | (df[\"loss\"]> 0.05), \"distTotal\"] = np.nan\n",
                "        ##hardcode color code here for scatter plot\n",
                "        if test_parameter == 'kappa':\n",
                "            color_code={0.1: 0.2, 1.0: 0.4, 10.0: 0.6,100000.0:1}\n",
                "        elif test_parameter == 'mu':\n",
                "            if scene_name.lower()=='choice':\n",
                "                #color_code={0: 0.1,45: 0.4,315: 0.7}\n",
                "                color_code={0: 0.1,135: 0.4,225: 0.7}\n",
                "            elif scene_name.lower()=='swarm':\n",
                "                color_code={0: 0.1, 45: 0.2, 90: 0.3,135:0.4,180: 0.5, 225: 0.6, 270: 0.7,315:0.8}\n",
                "            elif scene_name.lower()=='band':\n",
                "                color_code={0: 0.1, 45: 0.2, 90: 0.3, 270: 0.7,315:0.8}\n",
                "            else:\n",
                "                return Warning('scene name not found')\n",
                "        elif test_parameter == 'agent_speed':\n",
                "            color_code={1.0: 0.2,2.0: 0.4, 4.0: 0.6,8.0:1}\n",
                "        else:\n",
                "            return Warning('test parameter not found')\n",
                "        df['color_code'] = df[test_parameter].map(color_code)\n",
                "        df_all.append(df)\n",
                "        dfxy_all.append(dfxy)\n",
                "    return df_all,dfxy_all"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if 'vr_no' in locals():\n",
                "    df_all,dfxy_all=connect_two_tables(dir_list,analysis_methods,variable_name,vr_no)\n",
                "else:\n",
                "    df_all,dfxy_all=connect_two_tables(dir_dict,analysis_methods,variable_name)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### (deprecated) Session 2.3: plot animals' response during the trial with customised plotting functions."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#plot responses (mean angle and travel distance) from individual experiments (usually every 4 animal an experiment; different colour mark different animals in that experiment) \n",
                "#or comparing trial by trial response through normalised response (e.g. ratio to previous trial) or scatter plot (each dot means a comparison, \n",
                "#different colour means data from different rigs, different independent variables is marked with different kappa value)\n",
                "## 1st: plots with independent variables such as kappa or mu against travel distance or angle\n",
                "if len(df_all)>0:\n",
                "    plot_travel_distance_set(df_all,analysis_methods,variable_name,y_axis_lim=[0,12])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### (deprecated) Session 2.3.3: combine pandas dataframe across animals and filter out trials with bad tracking (these are preprocessing steps to use Sercan's functions)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Firstly, concatenate every animal's dataframe into a big table and then sort them based on conditions.\n",
                "if len(dfxy_all)>0:\n",
                "    dfxy_con = pd.concat(dfxy_all)\n",
                "if len(df_all)>0:\n",
                "    df_con = pd.concat(df_all)\n",
                "good_tracking=df_con['loss']< 0.05\n",
                "active_trials=(df_con['loss'] < 0.05) & (df_con[\"distTotal\"]>50)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "analysis_methods.update({\"save_output\": True})"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### (deprecated) Session 2.3.4: plot trial by trial trajectory"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#plotting trajectory\n",
                "#differentiate between stim and ISI based on columns in dfxy_con\n",
                "if analysis_methods.get(\"active_trials_only\"):\n",
                "    df_interest=df_con[active_trials]\n",
                "else:\n",
                "    df_interest=df_con[good_tracking]\n",
                "\n",
                "\n",
                "if analysis_methods.get(\"experiment_name\")==\"choice\":\n",
                "    stim_or_isi=dfxy_con['radial_distance']\n",
                "elif analysis_methods.get(\"experiment_name\")==\"swarm\" or analysis_methods.get(\"experiment_name\")==\"band\":\n",
                "    stim_or_isi=dfxy_con['density']\n",
                "df_stim=dfxy_con.loc[(dfxy_con['VR'].isin(df_interest['VR'])) & (stim_or_isi>0)]\n",
                "for key, grp in df_stim.groupby([variable_name,'type']):\n",
                "    print(f\"{variable_name}:{key}\")\n",
                "    plot_sercantrajec(grp,analysis_methods,key[0],variable_name,500)\n",
                "df_isi=dfxy_con.loc[(dfxy_con['VR'].isin(df_interest[\"VR\"])) & (stim_or_isi==0)]\n",
                "for key, grp in df_isi.groupby([variable_name,'type']):\n",
                "#for key, grp in df_isi.groupby(variable_name):\n",
                "    print(f\"{variable_name}:{key}\")\n",
                "    plot_sercantrajec(grp,analysis_methods,key[0],variable_name,500)\n",
                "#xy_lim at around 2000 is good for trial lasts around 4 or 5 min\n",
                "#xy_lim at around 500 is good for trial lasts around 1 min"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### (deprecated) Session 2.3.5: pool mean angle together to make KDE plots"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Visualise the distribution of mean angle at sin and cos using seaborn kernel density estimation plot\n",
                "#differentiate between stim and ISI based on columns in df_con\n",
                "if analysis_methods.get(\"active_trials_only\"):\n",
                "    df_interest=df_con[active_trials]\n",
                "else:\n",
                "    df_interest=df_con\n",
                "\n",
                "if analysis_methods.get(\"experiment_name\")==\"choice\":\n",
                "    stim_or_isi=df_interest['radial_distance']\n",
                "elif analysis_methods.get(\"experiment_name\")==\"swarm\" or analysis_methods.get(\"experiment_name\")==\"band\":\n",
                "    stim_or_isi=df_interest['density']\n",
                "df_stim=df_interest[stim_or_isi>0]\n",
                "\n",
                "for key, grp in df_stim.groupby([variable_name,'type']):\n",
                "    print(f\"{variable_name}:{key}\")\n",
                "    plot_sercansincos(grp,analysis_methods,key[0],variable_name)\n",
                "df_isi=df_interest[stim_or_isi==0]\n",
                "for key, grp in df_isi.groupby([variable_name,'type']):\n",
                "    print(f\"{variable_name}:{key}\")\n",
                "    plot_sercansincos(grp,analysis_methods,key[0],variable_name)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Visualise the distribution of  mean angle using seaborn kernel density estimation plot\n",
                "#differentiate between stim and ISI based on columns in df_con\n",
                "if analysis_methods.get(\"active_trials_only\"):\n",
                "    df_interest=df_con[active_trials]\n",
                "else:\n",
                "    df_interest=df_con\n",
                "if analysis_methods.get(\"experiment_name\")==\"choice\":\n",
                "    stim_or_isi=df_interest['radial_distance']\n",
                "elif analysis_methods.get(\"experiment_name\")==\"swarm\" or analysis_methods.get(\"experiment_name\")==\"band\":\n",
                "    stim_or_isi=df_interest['density']\n",
                "#df_stim=df_con[stim_or_isi>0]\n",
                "df_stim=df_interest[stim_or_isi>0]\n",
                "for key, grp in df_stim.groupby(parameter_name):\n",
                "    print(f\"{parameter_name}:{key}\")\n",
                "    plot_travel_histrogram(grp,analysis_methods,key,parameter_name)\n",
                "    #plot_circular_histrogram(grp,analysis_methods,key,parameter_name)\n",
                "#df_isi=df_con[stim_or_isi==0]\n",
                "df_isi=df_interest[stim_or_isi==0]\n",
                "for key, grp in df_isi.groupby(parameter_name):\n",
                "    print(f\"{parameter_name}:{key}\")\n",
                "    plot_travel_histrogram(grp,analysis_methods,key,parameter_name)\n",
                "    #plot_circular_histrogram(grp,analysis_methods,key,parameter_name)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### (deprecated) Session 2.3.5: plot individual animal's trajectory"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dir_iterator=[]\n",
                "if len(vr_no)>0:\n",
                "    print(\"i am using list\")\n",
                "    dir_iterator=zip(dir_list,vr_no)\n",
                "elif type(dir_list)==dict:\n",
                "    print(\"i am using dictionary\")\n",
                "    dir_iterator=dir_dict\n",
                "else:\n",
                "    print(\"there is a bug\")\n",
                "animal_count=0\n",
                "for this_dir,this_vr in dir_iterator:\n",
                "    if Path(this_dir).is_dir()==False:\n",
                "        #print(f'no such a dir exist {this_dir}')\n",
                "        continue\n",
                "    locust_pattern = f\"VR{this_vr}*XY.h5\"\n",
                "    found_result = find_file(Path(this_dir), locust_pattern)        \n",
                "    print(found_result)\n",
                "    #if str(found_result).endswith('VR2_2024-10-14_134515_XY.h5'):\n",
                "    if str(found_result).endswith('VR4_2024-10-13_184515_XY.h5'):\n",
                "        print('use this animal as example')\n",
                "        dfxy = pd.read_hdf(found_result)\n",
                "        dfxy['VR'] = np.tile(f\"VR{this_vr}\", (len(dfxy), 1))\n",
                "        dfxy['VR'] =dfxy[\"VR\"]+\"_\"+dfxy[\"fname\"]\n",
                "        summary_pattern = f\"VR{this_vr}*score.h5\"\n",
                "        found_result = find_file(Path(this_dir), summary_pattern)        \n",
                "        df = pd.read_hdf(found_result)\n",
                "        df['VR'] = np.tile(f\"VR{this_vr}\", (len(df), 1))\n",
                "        df['VR'] =df[\"VR\"]+\"_\"+df[\"fname\"]\n",
                "        if analysis_methods.get(\"experiment_name\")==\"choice\":\n",
                "            stim_or_isi=dfxy['radial_distance']\n",
                "        elif analysis_methods.get(\"experiment_name\")==\"swarm\" or analysis_methods.get(\"experiment_name\")==\"band\":\n",
                "            stim_or_isi=dfxy['density']\n",
                "        df_stim=dfxy.loc[(dfxy['VR'].isin(df['VR'])) & (stim_or_isi>0)]\n",
                "        for key, grp in df_stim.groupby(parameter_name):\n",
                "            print(f\"kappa:{key},animal_id:{animal_count}\")\n",
                "            plot_sercantrajec(grp,analysis_methods,key,parameter_name,300)\n",
                "        df_isi=dfxy.loc[(dfxy['VR'].isin(df['VR'])) & (stim_or_isi==0)]\n",
                "        for key, grp in df_isi.groupby(parameter_name):\n",
                "            print(f\"kappa:{key}\")\n",
                "            plot_sercantrajec(grp,analysis_methods,key,parameter_name,300)\n",
                "        animal_count=animal_count+1\n",
                "    else:\n",
                "        animal_count=animal_count+1\n",
                "        continue"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#this is used to define active animals \n",
                "travel_distance_across_animals=np.ones(len(df_all))\n",
                "for id in np.arange(len(df_all)):\n",
                "    this_df=df_all[id]\n",
                "    travel_distance_across_animals[id]=this_df[this_df['loss']< 0.05]['distTotal'].sum()\n",
                "plt.hist(travel_distance_across_animals,bins=30)\n",
                "plt.show()\n",
                "## if an animal dont move at all, default analysis pipeline will out put 3 body length (12 cm) per trial, hence the minimum travel distance for an experiment is 12*(trial+ISI number)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#note PI and OI during ISI does not make sense \n",
                "##next step, check animals' response across stim type, across trials\n",
                "save_output= analysis_methods.get(\"save_output\")\n",
                "num_example_animal=22\n",
                "all_OIs=np.ones((2,len(dfxy_all)))\n",
                "all_PIs=np.ones((2,len(dfxy_all)))\n",
                "all_PIs_follow_only=np.ones((2,len(dfxy_all)))\n",
                "all_tortuosity=np.ones((4,len(dfxy_all)))## return NaN, if animals make one or less than one move; and if inactive animals are excluded from analysis\n",
                "# if analysis_methods.get(\"experiment_name\")==\"choice\":\n",
                "#     stim_or_isi=dfxy_con['radial_distance']\n",
                "# elif analysis_methods.get(\"experiment_name\")==\"swarm\" or analysis_methods.get(\"experiment_name\")==\"band\":\n",
                "#     stim_or_isi=dfxy_con['density']\n",
                "active_animal_threshold=2500\n",
                "animal_count=0\n",
                "for id in np.arange(len(dfxy_all)):\n",
                "    if analysis_methods.get(\"active_animals_only\",False):\n",
                "        this_animal=df_all[id]\n",
                "        if this_animal[this_animal['loss']< 0.05]['distTotal'].sum()>active_animal_threshold:\n",
                "            pass\n",
                "        else:\n",
                "            all_OIs[:,animal_count]=np.nan\n",
                "            all_PIs[:,animal_count]=np.nan\n",
                "            all_tortuosity[:,animal_count]=np.nan\n",
                "            animal_count=animal_count+1\n",
                "            continue\n",
                "    else:\n",
                "        pass\n",
                "    optomotor_stim=[]\n",
                "    preference_stim=[]\n",
                "    labels_stim=[]\n",
                "    optomotor_isi=[]\n",
                "    preference_isi=[]\n",
                "    labels_isi=[]\n",
                "    tortuosity_stim=[]\n",
                "    tortuosity_isi=[]\n",
                "    preference_stim_follow_of=[]\n",
                "    preference_isi_follow_of=[]\n",
                "    trial_id=0\n",
                "    for key, grp in dfxy_all[id].groupby('fname'):\n",
                "        if grp['density'][0]>0 or trial_id==0:## during trial or during pre-stim background, use default mu\n",
                "            this_mu=grp['mu'].unique()[0]\n",
                "        else:## during ISI, continue to use mu from previous trial to check how long navigation direction persist \n",
                "            pass\n",
                "        this_hdf_file=dfxy_all[id].iloc[0]['VR']\n",
                "        #generate labels of classification, index for that trials\n",
                "        l,oi,pi,pi_follow_of_only,_=classify_heading_direction(grp['heading'].values,this_mu)\n",
                "        #calculate tortuosity\n",
                "        arc=np.sqrt(np.square(np.diff(grp['X'].values)) + np.square(np.diff(grp['Y'].values)))\n",
                "        chord=np.sqrt(np.square(grp['X'].values[-1]-grp['X'].values[0])+np.square(grp['Y'].values[-1]-grp['Y'].values[0]))\n",
                "        if chord>0:\n",
                "            this_tortuosity=np.sum(arc)/chord\n",
                "        else:\n",
                "            this_tortuosity=np.nan\n",
                "        if grp['density'][0]>0:\n",
                "            optomotor_stim.append(oi)\n",
                "            preference_stim.append(pi)\n",
                "            preference_stim_follow_of.append(pi_follow_of_only)\n",
                "            tortuosity_stim.append((np.sum(arc),chord))\n",
                "            labels_stim.append(l)\n",
                "            fig_title=f'{this_hdf_file}_trial{trial_id}_stim_{this_mu}'\n",
                "        else:\n",
                "            optomotor_isi.append(oi)\n",
                "            preference_isi.append(pi)\n",
                "            preference_isi_follow_of.append(pi_follow_of_only)\n",
                "            tortuosity_isi.append((np.sum(arc),chord))\n",
                "            labels_isi.append(l)\n",
                "            fig_title=f'{this_hdf_file}_trial{trial_id}_isi_{this_mu}'\n",
                "        if analysis_methods.get(\"plotting_trajectory\",False) and animal_count==num_example_animal:\n",
                "            print(dfxy_all[id].iloc[0]['VR'],this_mu)\n",
                "            if grp['heading'].shape[0]>1:\n",
                "                ax = plt.subplot(111, polar=True)\n",
                "                ax.hist(grp['heading'].values, bins=24, alpha=0.75)\n",
                "                fig2, ax2 = plt.subplots(\n",
                "                nrows=1, ncols=1, figsize=(18, 6), tight_layout=True\n",
                "            )\n",
                "                xy=np.column_stack((grp[\"X\"].values,grp[\"Y\"].values))\n",
                "                seg_no=1\n",
                "                for start, stop in zip(xy[:-1], xy[1:]):\n",
                "                    x, y = zip(start, stop)\n",
                "                    if l[seg_no]=='for_of':\n",
                "                        this_color='b'\n",
                "                    elif l[seg_no]==\"target_ob\":\n",
                "                        this_color='r'\n",
                "                    elif l[seg_no]==\"against_of\":\n",
                "                        this_color='c'\n",
                "                    else:\n",
                "                        this_color='k'\n",
                "                    ax2.plot(x, y, color=this_color,linewidth=1)\n",
                "                    ax2.set(xlim=(-250,250),ylim=(-250,250),aspect=('equal'))\n",
                "                    seg_no=seg_no+1\n",
                "                fig2.suptitle(fig_title)\n",
                "                fig2_name=fig_title+'.png'\n",
                "                if save_output:\n",
                "                    fig2.savefig(fig2_name)\n",
                "                plt.show()\n",
                "\n",
                "        trial_id=trial_id+1\n",
                "\n",
                "    if analysis_methods.get(\"plotting_trajectory\",False) and animal_count==num_example_animal:\n",
                "        decision_count = np.array([these_labels.size for these_labels in labels_stim])\n",
                "        alpha_values=np.ones(decision_count.size)\n",
                "        alpha_values[(decision_count < 10)] = 0.2\n",
                "        alpha_values[(decision_count >= 10) & (decision_count < 20)] = 0.6\n",
                "        alpha_values[(decision_count >= 20) & (decision_count < 30)] = 0.8\n",
                "        alpha_values[(decision_count >= 30)] = 1\n",
                "        fig1, axes = plt.subplots(\n",
                "            nrows=4, ncols=3, figsize=(12, 9), tight_layout=True\n",
                "        )\n",
                "        ax1,ax2,ax3,ax4,ax5,ax6,ax7,ax8,ax9,ax10,ax11,ax12= axes.flatten()\n",
                "        ax1.hist(optomotor_stim,color='k')\n",
                "        ax1.hist(optomotor_isi,alpha = 0.05,color='k',ls='dashed',lw=3)\n",
                "        ax2.hist(preference_stim_follow_of,color='k')\n",
                "        ax2.hist(preference_isi_follow_of,alpha = 0.05,color='k',ls='dashed',lw=3)\n",
                "        ax3.hist(preference_stim,color='k')\n",
                "        ax3.hist(preference_isi,alpha = 0.05,color='k',ls='dashed',lw=3)\n",
                "        ax4.scatter(np.array(optomotor_isi),np.array(optomotor_stim),color='k',alpha=alpha_values)\n",
                "        ax5.scatter(np.array(preference_isi_follow_of),np.array(preference_stim_follow_of),color='k',alpha=alpha_values)\n",
                "        ax6.scatter(np.array(preference_isi),np.array(preference_stim),color='k',alpha=alpha_values)\n",
                "        ax7.scatter(np.array(optomotor_stim)[::2],np.array(optomotor_stim)[1::2],color='k',alpha=alpha_values[1::2])\n",
                "        ax8.scatter(np.array(preference_stim_follow_of)[::2],np.array(preference_stim_follow_of)[1::2],color='k',alpha=alpha_values[1::2])\n",
                "        ax9.scatter(np.array(preference_stim)[::2],np.array(preference_stim)[1::2],color='k',alpha=alpha_values[1::2])\n",
                "        ax10.scatter(np.array(optomotor_stim)[1:-1:2],np.array(optomotor_stim)[3::2],color='k',alpha=alpha_values[1:-1:2])\n",
                "        ax11.scatter(np.array(preference_stim_follow_of)[1:-1:2],np.array(preference_stim_follow_of)[3::2],color='k',alpha=alpha_values[1:-1:2])\n",
                "        ax12.scatter(np.array(preference_stim)[1:-1:2],np.array(preference_stim)[3::2],color='k',alpha=alpha_values[1:-1:2])\n",
                "        ax1.set(\n",
                "        xlim=(-1.2,1.2),\n",
                "        xlabel='optomotor index',\n",
                "        ylabel='count of decision')\n",
                "        ax2.set(\n",
                "        xlim=(-1.2,1.2),\n",
                "        xlabel='preference index (follow of vs. target ob)',\n",
                "        ylabel='count of decision')\n",
                "        ax3.set(\n",
                "        xlim=(-1.2,1.2),\n",
                "        xlabel='preference index',\n",
                "        ylabel='count of decision')\n",
                "        ax4.set(\n",
                "        xlabel='optomotor index ISI',\n",
                "        ylabel='optomotor index following Stim',\n",
                "        xlim=(-1.2,1.2),\n",
                "        ylim=(-1.2,1.2),\n",
                "        yticks=([-1, 0, 1]),\n",
                "        xticks=([-1, 0, 1]),\n",
                "        aspect=('equal'))\n",
                "        ax5.set(\n",
                "        xlabel='preference index (follow of vs. target ob) ISI',\n",
                "        ylabel='preference index (follow of vs. target ob) following Stim',\n",
                "        xlim=(-1.2,1.2),\n",
                "        ylim=(-1.2,1.2),\n",
                "        yticks=([-1, 0, 1]),\n",
                "        xticks=([-1, 0, 1]),\n",
                "        aspect=('equal'))\n",
                "        ax6.set(\n",
                "        xlabel='preference index ISI',\n",
                "        ylabel='preference index following Stim',\n",
                "        xlim=(-1.2,1.2),\n",
                "        ylim=(-1.2,1.2),\n",
                "        yticks=([-1, 0, 1]),\n",
                "        xticks=([-1, 0, 1]),\n",
                "        aspect=('equal'))\n",
                "        ax7.set(\n",
                "        xlabel='optomotor index Stim n',\n",
                "        ylabel='optomotor index Stim n+1',\n",
                "        xlim=(-1.2,1.2),\n",
                "        ylim=(-1.2,1.2),\n",
                "        yticks=([-1, 0, 1]),\n",
                "        xticks=([-1, 0, 1]),\n",
                "        aspect=('equal'))\n",
                "        ax8.set(\n",
                "        xlabel='preference index (follow of vs. target ob) Stim n',\n",
                "        ylabel='preference index (follow of vs. target ob) Stim n+1',\n",
                "        xlim=(-1.2,1.2),\n",
                "        ylim=(-1.2,1.2),\n",
                "        yticks=([-1, 0, 1]),\n",
                "        xticks=([-1, 0, 1]),\n",
                "        aspect=('equal'))\n",
                "        ax9.set(\n",
                "        xlabel='preference index Stim n',\n",
                "        ylabel='preference index Stim n+1',\n",
                "        xlim=(-1.2,1.2),\n",
                "        ylim=(-1.2,1.2),\n",
                "        yticks=([-1, 0, 1]),\n",
                "        xticks=([-1, 0, 1]),\n",
                "        aspect=('equal'))\n",
                "        ax10.set(\n",
                "        xlabel='optomotor index Stim n',\n",
                "        ylabel='optomotor index following ISI',\n",
                "        xlim=(-1.2,1.2),\n",
                "        ylim=(-1.2,1.2),\n",
                "        yticks=([-1, 0, 1]),\n",
                "        xticks=([-1, 0, 1]),\n",
                "        aspect=('equal'))\n",
                "        ax11.set(\n",
                "        xlabel='preference index (follow of vs. target ob) Stim n',\n",
                "        ylabel='preference index (follow of vs. target ob) following ISI',\n",
                "        xlim=(-1.2,1.2),\n",
                "        ylim=(-1.2,1.2),\n",
                "        yticks=([-1, 0, 1]),\n",
                "        xticks=([-1, 0, 1]),\n",
                "        aspect=('equal'))\n",
                "        ax12.set(\n",
                "        xlabel='preference index Stim n',\n",
                "        ylabel='preference index following ISI',\n",
                "        xlim=(-1.2,1.2),\n",
                "        ylim=(-1.2,1.2),\n",
                "        yticks=([-1, 0, 1]),\n",
                "        xticks=([-1, 0, 1]),\n",
                "        aspect=('equal'))\n",
                "        #fig1_title=f'animal_no{animal_count}'\n",
                "        #fig1.suptitle(fig1_title)\n",
                "        fig1_name=f'{this_hdf_file}_tbt_index_hist.svg'\n",
                "        if save_output:\n",
                "            fig1.savefig(fig1_name)\n",
                "        plt.show()\n",
                "    ## The OI and PI here are calculated based on responses pooled from every movement across trials\n",
                "    labels_across_trials=np.concat(labels_stim)\n",
                "    arc_chord_aba=np.concat(tortuosity_stim)\n",
                "    all_tortuosity[0,animal_count]=np.nanmean(arc_chord_aba[::2]/arc_chord_aba[1::2])\n",
                "    all_tortuosity[1,animal_count]=np.nanstd(arc_chord_aba[::2]/arc_chord_aba[1::2])/np.sqrt(np.count_nonzero(arc_chord_aba[1::2]!=0))\n",
                "    of_responses=sum(labels_across_trials==\"for_of\")+sum(labels_across_trials==\"against_of\")\n",
                "    all_OIs[0,animal_count]=(sum(labels_across_trials==\"for_of\")-sum(labels_across_trials==\"against_of\"))/of_responses\n",
                "    all_PIs[0,animal_count]=(of_responses-sum(labels_across_trials==\"target_ob\"))/(of_responses+sum(labels_across_trials==\"target_ob\"))\n",
                "    all_PIs_follow_only[0,animal_count]=(sum(labels_across_trials==\"for_of\")-sum(labels_across_trials==\"target_ob\"))/(sum(labels_across_trials==\"for_of\")+sum(labels_across_trials==\"target_ob\"))\n",
                "    labels_across_trials=np.concat(labels_isi)\n",
                "    arc_chord_aba=np.concat(tortuosity_isi)\n",
                "    all_tortuosity[2,animal_count]=np.nanmean(arc_chord_aba[::2]/arc_chord_aba[1::2])\n",
                "    all_tortuosity[3,animal_count]=np.nanstd(arc_chord_aba[::2]/arc_chord_aba[1::2])/np.sqrt(np.count_nonzero(arc_chord_aba[1::2]!=0))\n",
                "    of_responses=sum(labels_across_trials==\"for_of\")+sum(labels_across_trials==\"against_of\")\n",
                "    all_OIs[1,animal_count]=(sum(labels_across_trials==\"for_of\")-sum(labels_across_trials==\"against_of\"))/of_responses\n",
                "    all_PIs[1,animal_count]=(of_responses-sum(labels_across_trials==\"target_ob\"))/(of_responses+sum(labels_across_trials==\"target_ob\"))\n",
                "    all_PIs_follow_only[1,animal_count]=(sum(labels_across_trials==\"for_of\")-sum(labels_across_trials==\"target_ob\"))/(sum(labels_across_trials==\"for_of\")+sum(labels_across_trials==\"target_ob\"))\n",
                "    animal_count=animal_count+1"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plot_pi_oi_comparison(all_PIs,all_OIs,all_tortuosity,all_PIs_follow_only,analysis_methods,travel_distance_across_animals)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### (deprecated) Session 2.3.6: plot individual animal's kernel density estimation plot"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dir_iterator=[]\n",
                "if len(vr_no)>0:\n",
                "    print(\"i am using list\")\n",
                "    dir_iterator=zip(dir_list,vr_no)\n",
                "elif type(dir_list)==dict:\n",
                "    print(\"i am using dictionary\")\n",
                "    dir_iterator=dir_dict\n",
                "else:\n",
                "    print(\"there is a bug\")\n",
                "\n",
                "for this_dir,this_vr in dir_iterator:\n",
                "    if Path(this_dir).is_dir()==False:\n",
                "        print(f'no such a dir exist {this_dir}')\n",
                "        continue\n",
                "    locust_pattern = f\"VR{this_vr}*score.h5\"\n",
                "    found_result = find_file(Path(this_dir), locust_pattern)        \n",
                "    df = pd.read_hdf(found_result)\n",
                "    if analysis_methods.get(\"experiment_name\")==\"choice\":\n",
                "        stim_or_isi=df['radial_distance']\n",
                "    elif analysis_methods.get(\"experiment_name\")==\"swarm\" or analysis_methods.get(\"experiment_name\")==\"band\":\n",
                "        stim_or_isi=df['density']\n",
                "    df_stim=df[stim_or_isi>0]\n",
                "    for key, grp in df_stim.groupby(variable_name):\n",
                "        print(f\"{variable_name}:{key}\")\n",
                "        plot_sercansincos(grp,analysis_methods,key,parameter_name)\n",
                "    df_isi=df[stim_or_isi==0]\n",
                "    for key, grp in df_isi.groupby(parameter_name):\n",
                "        print(f\"{parameter_name}:{key}\")\n",
                "        plot_sercansincos(grp,analysis_methods,key,parameter_name)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### [Optional] Run preprocess_matrex_data with multi-engines"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "##this cell start the multi-engines. Make sure to run only once\n",
                "import time\n",
                "import ipyparallel as ipp\n",
                "def show_clusters():\n",
                "    clusters = ipp.ClusterManager().load_clusters() \n",
                "    print(\"{:15} {:^10} {}\".format(\"cluster_id\", \"state\", \"cluster_file\")) \n",
                "    for c in clusters:\n",
                "        cd = clusters[c].to_dict()\n",
                "        cluster_id = cd['cluster']['cluster_id']\n",
                "        controller_state = cd['controller']['state']['state']\n",
                "        cluster_file = getattr(clusters[c], '_trait_values')['cluster_file']\n",
                "        print(\"{:15} {:^10} {}\".format(cluster_id, controller_state, cluster_file))\n",
                "    return cluster_id\n",
                "\n",
                "cluster = ipp.Cluster(n=6)\n",
                "await cluster.start_cluster()\n",
                "cluster_neuropc=show_clusters()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "##input cluster_id from previous cell\n",
                "rc = ipp.Client(cluster_id=cluster_neuropc)\n",
                "\n",
                "# Create a DirectView for parallel execution\n",
                "dview = rc.direct_view()\n",
                "\n",
                "# Define a function for parallel processing\n",
                "def process_directory(this_dir, analysis_methods):\n",
                "    from pathlib import Path\n",
                "    import sys\n",
                "    current_working_directory = Path.cwd()\n",
                "    parent_dir = current_working_directory.resolve().parents[0]\n",
                "    sys.path.insert(0, str(parent_dir) + \"\\\\utilities\")\n",
                "    from locustvr_converter import preprocess_matrex_data\n",
                "    preprocess_matrex_data(this_dir,analysis_methods)\n",
                "\n",
                "# Define analysis_methods\n",
                "\n",
                "# Use parallel execution to process directories\n",
                "dview.map_sync(process_directory, dir_list, [analysis_methods] * len(dir_list))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "rc.shutdown()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "unity_analysis",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
