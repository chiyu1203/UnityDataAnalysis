{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session 0.0: introduce libraries, database path and main independent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "'''\n",
    "if autoreload does not work, try import the python file as a module and then reload the file and the module\n",
    "import plotting_follow_analysis\n",
    "import importlib\n",
    "importlib.reload(plotting_follow_analysis)\n",
    "from plotting_follow_analysis import plot_follow_response_distribution'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## a useful function to generate a data list for further analysis\n",
    "import os,json,sys,pickle\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import circmean\n",
    "from sorting_time_series_analysis import follow_behaviour_analysis,calculate_speed,diff_angular_degree,sort_raster_fictrac\n",
    "from preference_analysis import *\n",
    "from time_series_analysis import *\n",
    "from plotting_follow_analysis import plot_follow_response_distribution\n",
    "##need to add this additional cell because useful tools are in another folder. Need to integrate these two folders one day\n",
    "current_working_directory = Path.cwd()\n",
    "parent_dir = current_working_directory.resolve().parents[0]\n",
    "sys.path.insert(0, str(parent_dir) + \"\\\\utilities\")\n",
    "from useful_tools import select_animals_gpt,find_file,get_fill_between_range,read_seq_config\n",
    "from data_cleaning import findLongestConseqSubseq,interp_fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = \"./analysis_methods_dictionary.json\"\n",
    "with open(json_file, \"r\") as f:\n",
    "    analysis_methods = json.loads(f.read())\n",
    "    \n",
    "#Put the folder of your Unity folder below\n",
    "#thisDataset =\"D:/MatrexVR_Swarm_Data/RunData\"\n",
    "#thisDataset =\"D:/MatrexVR_blackbackground_Data/RunData\"\n",
    "#thisDataset =\"D:/MatrexVR_grass1_Data/RunData\"\n",
    "thisDataset =\"D:/MatrexVR_2024_Data/RunData\"\n",
    "#parameter name means independent variable in the experiment\n",
    "#variable_name='mu'\n",
    "variable_name='location'\n",
    "#variable_name='agent_speed'\n",
    "#check trace in trial 115 from VR1_2024-11-16_155242_score_full, maybe there is a jump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def slices_lists(list1, list2,number,list3=[]):\n",
    "#     list1=list1[:number]\n",
    "#     list2=list2[:number]\n",
    "#     list3=list3[:number]\n",
    "#     return list1, list2, list3\n",
    "# dir_list,vr_no,no_food=slices_lists(dir_list, vr_no, 26, no_food)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session 1.0: select animals based on condition and return which a directory list and a list of vr rig number to specify which animal to analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to your Excel file\n",
    "variable_name2=\"marching_band_black_vs_leader_locust_constant_speed&distance\"\n",
    "#variable_name2=\"bifuration_vr_locust_sta_black_locust\"\n",
    "dir_list = []\n",
    "file_type=\".h5\"\n",
    "using_google_sheet=True\n",
    "sheet_name = \"Unity_MatrexVR\"\n",
    "experiment_name=analysis_methods.get(\"experiment_name\")\n",
    "if analysis_methods.get(\"load_individual_data\") == True:\n",
    "    if using_google_sheet==True:\n",
    "        database_id = \"1UL4eEUrQMapx9xz11-IyOSlPBcep1I9vBJ2uGgVudb8\"\n",
    "        url = f\"https://docs.google.com/spreadsheets/d/{database_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}\"\n",
    "        df = pd.read_csv(url)\n",
    "    else:\n",
    "        excel_file_path = \"Z:/DATA/experiment_trackball_Optomotor/Locusts Management.xlsx\"\n",
    "        print(f\"using a database {excel_file_path} from the server but this file might be outdated\")\n",
    "        with pd.ExcelFile(excel_file_path) as xls:\n",
    "            df = pd.read_excel(xls, sheet_name)\n",
    "        ##list up the conditions and answers as strings for input argument to select animal. One condition must pair with one answer\n",
    "    if analysis_methods.get(\"select_animals_by_condition\") == True:\n",
    "       #animal_of_interest=select_animals_gpt(df,\"Independent variable (list up all of them in the experiment)\",\"gregarious_leader_grass\",\"Excluding this animal from analysis (Usually when animals die or molt, T/F)\",\"F\")\n",
    "        #animal_of_interest=select_animals_gpt(df,\"Independent variable (list up all of them in the experiment)\",\"gregarious_leader_black\",\"Excluding this animal from analysis (Usually when animals die or molt, T/F)\",\"F\")\n",
    "        #animal_of_interest=select_animals_gpt(df,\"Independent variable (list up all of them in the experiment)\",variable_name)\n",
    "        animal_of_interest=select_animals_gpt(df,\"Independent variable1\",variable_name,\"Independent variable2\",variable_name2,\"Excluding this animal from analysis (Usually when animals die or molt, T/F)\",\"F\")\n",
    "    else:\n",
    "        animal_of_interest=df\n",
    "    folder_name=animal_of_interest[\"folder name\"].values\n",
    "    dir_tile=np.tile(thisDataset, (len(folder_name), 1))\n",
    "    vr_no=animal_of_interest[\"VR number\"].values\n",
    "    vr_no = vr_no.astype('int')\n",
    "    no_food=animal_of_interest[\"Food retriction (-1 or the number of hours)\"].values\n",
    "    no_food =no_food.astype('int')\n",
    "    dir_list = [''.join([x[0], '/', y]) for x,y in zip(dir_tile,folder_name)]\n",
    "    #dir_dict = itertools.zip_longest(dir_list, vr_no.tolist())\n",
    "    dir_dict = zip(dir_list, vr_no.tolist())\n",
    "else:\n",
    "    for root, dirs, files in os.walk(thisDataset):\n",
    "        for folder in dirs:\n",
    "            folder_path=os.path.join(root,folder)\n",
    "            if any(name.endswith(file_type) for name in os.listdir(folder_path)):\n",
    "                dir_list.append(folder_path.replace(\"\\\\\", \"/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_list[:26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_list=dir_list[60:]\n",
    "vr_no=vr_no[60:] \n",
    "no_food=no_food[60:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_list=dir_list[:26]\n",
    "vr_no=vr_no[:26] \n",
    "no_food=no_food[:26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_list=dir_list[26:60]\n",
    "vr_no=vr_no[26:60] \n",
    "no_food=no_food[26:60]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Session 1.1: introduce helper functions to make plot and calculate speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_methods.update({\"plotting_trajectory\": False})\n",
    "analysis_methods.update({\"save_output\":False})\n",
    "analysis_methods.update({\"analysis_window\":[-5,5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_pos_all_animals=[]\n",
    "simulated_relative_pos_all_animals=[]\n",
    "trial_evaluation_across_animals=[]\n",
    "raster_across_animals_unity=[]\n",
    "raster_across_animals_fictrac=[]\n",
    "seq_config_all_animals=[]\n",
    "animal_id=0\n",
    "read_fictrac_data_only=False\n",
    "time_series_analysis = analysis_methods.get(\"time_series_analysis\")\n",
    "file_suffix = \"_full\" if time_series_analysis else \"\"\n",
    "for this_dir,this_vr,this_no_food in zip(dir_list,vr_no,no_food):\n",
    "    if Path(this_dir).is_dir()==False:\n",
    "        continue\n",
    "    # if this_vr==4:\n",
    "    #     continue\n",
    "    if read_fictrac_data_only==False:\n",
    "        agent_pattern = f\"VR{this_vr}*agent{file_suffix}.h5\"\n",
    "        xy_pattern = f\"VR{this_vr}*XY{file_suffix}.h5\"\n",
    "        summary_pattern = f\"VR{this_vr}*score{file_suffix}.h5\"\n",
    "        agent_file = find_file(Path(this_dir), agent_pattern)\n",
    "        focal_animal_file = find_file(Path(this_dir), xy_pattern)\n",
    "        summary_file = find_file(Path(this_dir), summary_pattern)\n",
    "        relative_pos,trial_evaluation_list,raster_unity,num_unfilled_gap,_=follow_behaviour_analysis(summary_file,focal_animal_file,agent_file,analysis_methods)\n",
    "        if animal_id==0:\n",
    "            largest_unfilled_gap=num_unfilled_gap\n",
    "        elif num_unfilled_gap>largest_unfilled_gap:\n",
    "            largest_unfilled_gap=num_unfilled_gap\n",
    "        else:\n",
    "            pass\n",
    "        relative_pos_all_animals.append(relative_pos)\n",
    "        trial_evaluation=pd.concat(trial_evaluation_list)\n",
    "        trial_evaluation.insert(0, 'VR',np.repeat(this_vr,trial_evaluation.shape[0]))\n",
    "        trial_evaluation.insert(0, 'minimum_starvation_time',np.repeat(this_no_food,trial_evaluation.shape[0]))\n",
    "        trial_evaluation.insert(0, 'animal_id',np.repeat(animal_id,trial_evaluation.shape[0]))\n",
    "        trial_evaluation_across_animals.append(trial_evaluation)\n",
    "        if \"raster_unity\" in locals():\n",
    "            raster_unity.insert(0, 'animal_id', np.repeat(animal_id,raster_unity.shape[0]))\n",
    "            raster_across_animals_unity.append(raster_unity)\n",
    "    seq_config_pattern=f\"*sequenceConfig.json\"\n",
    "    seq_config_file=find_file(Path(this_dir), seq_config_pattern)\n",
    "    seq_config_pd=read_seq_config(seq_config_file)\n",
    "    seq_config_pd.insert(0, 'step_id',np.arange(seq_config_pd.shape[0]))\n",
    "    seq_config_pd.insert(0, 'animal_id',np.repeat(animal_id,seq_config_pd.shape[0]))\n",
    "    seq_config_all_animals.append(seq_config_pd)\n",
    "    pa_pattern=f\"VR{this_vr}*motion{file_suffix}.parquet\"\n",
    "    pa_file=find_file(Path(this_dir), pa_pattern)\n",
    "    raster=pd.read_parquet(pa_file, engine='pyarrow')\n",
    "    raster.insert(0, 'animal_id', np.repeat(animal_id,raster.shape[0]))\n",
    "    raster_across_animals_fictrac.append(raster)\n",
    "    animal_id=animal_id+1\n",
    "if \"largest_unfilled_gap\" in locals():\n",
    "    analysis_methods['largest_unfilled_gap']= largest_unfilled_gap\n",
    "elif len(raster_across_animals_fictrac)==0:\n",
    "    print(\"'largest_unfilled_gap' is not defined and fictrac files are collected. Probably because the wrong folder of database is selected or portable USB is not inserted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session 2.0: quantify relative preference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Session 2.1 calculate relative distance to narrow down the definition of follow choices in this assay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculating the relative distance between the focal animal and other agents in every frame\n",
    "relative_pos_all_pd=pd.concat(relative_pos_all_animals,ignore_index=True)\n",
    "relative_pos_all_pd['distance']=relative_pos_all_pd.apply(lambda row:np.sqrt(np.square(row['x']) + np.square(row['y'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get trial type and sort them by the length of the name and then by alphabet. In this case, homogeneous trial should usually be the first twos\n",
    "trial_type_list=sorted(relative_pos_all_pd['type'].unique(), key=len)\n",
    "trial_type_list[2:]=sorted(trial_type_list[2:], key=str,reverse=True)\n",
    "trial_type_list[:2]=sorted(trial_type_list[:2], key=str,reverse=True)\n",
    "print(trial_type_list)\n",
    "'''When a trial type contains _x_ in between the two object types, that means this is an heterogeneous trial.\n",
    "Then the first one is the one listed in the first item in the json file. So far, 20250514, that means the right object, and agent ID 0 in the scene'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trial_type_of_interest=[trial_type_list[0]]\n",
    "trial_type_of_interest=[trial_type_list[1]]\n",
    "#trial_type_of_interest=[trial_type_list[2]]\n",
    "#trial_type_of_interest=[trial_type_list[3]]\n",
    "#trial_type_of_interest=[trial_type_list[2],trial_type_list[3]]\n",
    "#trial_type_of_interest=[trial_type_list[0],trial_type_list[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trial_type_of_interest)\n",
    "for distance_threshold_for_plotting in range(5,30,10):\n",
    "    print(f\"distance threshold for plotting 2D histogram: {distance_threshold_for_plotting} cm\")\n",
    "    if len(trial_type_of_interest)==1:\n",
    "        relative_pos_of_interest=[relative_pos_all_pd[(relative_pos_all_pd['type']==trial_type_of_interest[0]) & (relative_pos_all_pd['distance']<distance_threshold_for_plotting)]]\n",
    "    elif len(trial_type_of_interest)==2:\n",
    "        relative_pos_of_interest=[relative_pos_all_pd[(relative_pos_all_pd['type']==trial_type_of_interest[0]) & (relative_pos_all_pd['distance']<distance_threshold_for_plotting)],relative_pos_all_pd[(relative_pos_all_pd['type']==trial_type_of_interest[1]) & (relative_pos_all_pd['distance']<distance_threshold_for_plotting)]]\n",
    "    plot_relative_pos_distribution(relative_pos_of_interest,trial_type_of_interest,distance_threshold_for_plotting,analysis_methods)\n",
    "### in the agent preference plot, one of the heteogeneous trials is flipped into left (positive value in y axis): black and right (negative value in y axis): gregarious."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Session 2.2 calculate preference index based on the narrower definition of follow choices and plot the index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Session 2.2.1: analyse heterogenous trial type to get preference index under simultaneous testing framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_methods.update({\"frequency_based_preference_index\":False})\n",
    "analysis_methods.update({\"exclude_extreme_index\":False})\n",
    "#trial_type_of_interest=[trial_type_list[2],trial_type_list[3]]\n",
    "trial_type_of_interest=[trial_type_list[0],trial_type_list[1]]\n",
    "left_right_preference_across_animals,exp_con_preference_across_animals,_,_,_,_=calculate_preference_index(relative_pos_all_animals,trial_type_of_interest,analysis_methods,thresholds=[4,4.5,5,6,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_preference_index(left_right_preference_across_animals,exp_con_preference_across_animals,trial_type_of_interest,analysis_methods,thresholds=[4,4.5,5,6,8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Session 2.2.2: analyse homogenous trial type to get preference index under sequential testing framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## firstly, turn exclude_extreme_index to false, so that we get epochs of all animals\n",
    "analysis_methods.update({\"exclude_extreme_index\":False})\n",
    "trial_type_of_interest=[trial_type_list[0]]\n",
    "print(trial_type_of_interest)\n",
    "_,_,_,_,l0_all,r0_all=calculate_preference_index(relative_pos_all_animals,trial_type_of_interest,analysis_methods,thresholds=[4,4.5,5,6,8])\n",
    "trial_type_of_interest=[trial_type_list[1]]\n",
    "print(trial_type_of_interest)\n",
    "_,_,_,_,l1_all,r1_all=calculate_preference_index(relative_pos_all_animals,trial_type_of_interest,analysis_methods,thresholds=[4,4.5,5,6,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## After adding epochs across trial type, it is fine to turn exclude_extreme_index to True again to remove animal with no epochs in one of the trial type. It is also fine to keep it False\n",
    "analysis_methods.update({\"exclude_extreme_index\":True})\n",
    "exclude_extreme_index=analysis_methods.get(\"exclude_extreme_index\")\n",
    "follow_epochs0_across_animals=r0_all+l0_all\n",
    "follow_epochs1_across_animals=r1_all+l1_all\n",
    "follow_epochsL_across_animals=l0_all+l1_all\n",
    "follow_epochsR_across_animals=r0_all+r1_all\n",
    "if exclude_extreme_index==True:\n",
    "    animal_no_extreme=(follow_epochs1_across_animals==0) | (follow_epochs0_across_animals==0)\n",
    "    follow_epochs0_across_animals[animal_no_extreme]=np.nan\n",
    "    follow_epochs1_across_animals[animal_no_extreme]=np.nan\n",
    "    animal_no_extreme=(follow_epochsL_across_animals==0) | (follow_epochsR_across_animals==0)\n",
    "    follow_epochsL_across_animals[animal_no_extreme]=np.nan\n",
    "    follow_epochsR_across_animals[animal_no_extreme]=np.nan\n",
    "fig_name=f\"epochs_homogenous_trials_multiple_condition_con_{trial_type_list[0]}_exp_{trial_type_list[1]}\"\n",
    "plot_epochs_time(follow_epochs1_across_animals,follow_epochs0_across_animals,follow_epochsL_across_animals,follow_epochsR_across_animals,analysis_methods,fig_name,data_color='k',thresholds=[4,4.5,5,6,8],this_vr='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot the preference index across homogeneous trials\n",
    "trial_type_of_interest=[trial_type_list[0],trial_type_list[1]]\n",
    "exp_con_preference_across_animals_seq=(follow_epochs1_across_animals-follow_epochs0_across_animals)/(follow_epochs1_across_animals+follow_epochs0_across_animals)\n",
    "left_right_preference_across_animals_seq=(follow_epochsL_across_animals-follow_epochsR_across_animals)/(follow_epochsL_across_animals+follow_epochsR_across_animals)\n",
    "plot_preference_index(left_right_preference_across_animals_seq,exp_con_preference_across_animals_seq,trial_type_of_interest,analysis_methods,thresholds=[4,4.5,5,6,8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Session 2.3 plot relative position and calculate preference index VR rig by VR rig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the preference index for each VR number\n",
    "#trial_type_of_interest=[trial_type_list[0],trial_type_list[1]]\n",
    "plot_relative_position_groupby_vr=True\n",
    "for this_vr in np.unique(vr_no):\n",
    "    print(f\"VR number {this_vr} is used in the experiment\")\n",
    "    ### next time, finish this function to plot relative position distribution for each VR number\n",
    "    if plot_relative_position_groupby_vr==True:\n",
    "        relative_pos_subgroups=[relative_pos_all_animals[x] for x in np.where(vr_no==this_vr)[0]]\n",
    "        relative_pos_sub_pd=pd.concat(relative_pos_subgroups,ignore_index=True)\n",
    "        relative_pos_sub_pd['distance']=relative_pos_sub_pd.apply(lambda row:np.sqrt(np.square(row['x']) + np.square(row['y'])), axis=1)\n",
    "        for distance_threshold_for_plotting in range(5,30,10):\n",
    "            print(f\"distance threshold for plotting 2D histogram: {distance_threshold_for_plotting} cm\")\n",
    "            if len(trial_type_of_interest)==1:\n",
    "                relative_pos_of_interest=[relative_pos_sub_pd[(relative_pos_sub_pd['type']==trial_type_of_interest[0]) & (relative_pos_sub_pd['distance']<distance_threshold_for_plotting)]]\n",
    "            elif len(trial_type_of_interest)==2:\n",
    "                relative_pos_of_interest=[relative_pos_sub_pd[(relative_pos_sub_pd['type']==trial_type_of_interest[0]) & (relative_pos_sub_pd['distance']<distance_threshold_for_plotting)],relative_pos_sub_pd[(relative_pos_sub_pd['type']==trial_type_of_interest[1]) & (relative_pos_sub_pd['distance']<distance_threshold_for_plotting)]]\n",
    "            plot_relative_pos_distribution(relative_pos_of_interest,trial_type_of_interest,distance_threshold_for_plotting,analysis_methods,this_vr=f\"VR{this_vr}\")\n",
    "    if \"left_right_preference_across_animals\" in locals():\n",
    "        plot_preference_index(left_right_preference_across_animals[:,vr_no==this_vr],exp_con_preference_across_animals[:,vr_no==this_vr],trial_type_of_interest,analysis_methods,thresholds=[4,5,6,7,8],this_vr=f\"VR{this_vr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##do some correlation analysis to see if there is any correlation between the preference index and the travel distance or turning angles\n",
    "##whether opened wing makes a difference in the travel distance\n",
    "##analyse velocity and follow duration after an animal start to follow the target (distance < 5 cm), a velocity map that Ashrit has done\n",
    "##histogram of follow epochs animals by animal and tbt\n",
    "##output velocity and turning angle in every frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Session 2.4: Plot temporal distribution of follow epoch throughout the trial course\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this is the same as the one above, so we can skip this part if distance in relative_pos_all_pd is calculated and type in relative_pos_pd is sorted already\n",
    "relative_pos_all_pd=pd.concat(relative_pos_all_animals,ignore_index=True)\n",
    "relative_pos_all_pd['distance']=relative_pos_all_pd.apply(lambda row:np.sqrt(np.square(row['x']) + np.square(row['y'])), axis=1)\n",
    "trial_type_list=sorted(relative_pos_all_pd['type'].unique(), key=len)\n",
    "trial_type_list[2:]=sorted(trial_type_list[2:], key=str,reverse=True)\n",
    "trial_type_list[:2]=sorted(trial_type_list[:2], key=str,reverse=True)\n",
    "print(trial_type_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trial_type_of_interest=[trial_type_list[0],trial_type_list[1]]\n",
    "trial_type_of_interest=[trial_type_list[2],trial_type_list[3]]\n",
    "object_of_interest=trial_type_of_interest[0].split(\"_x_\")\n",
    "hetero_pattern='_x_'\n",
    "distance_threshold_for_plotting=5\n",
    "follow_epochs_temporal_con=[]\n",
    "follow_epochs_temporal_exp=[]\n",
    "follow_epochs_temporal_L=[]\n",
    "follow_epochs_temporal_R=[]\n",
    "relative_pos_of_interest=relative_pos_all_pd[relative_pos_all_pd['distance']<distance_threshold_for_plotting]\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=1, ncols=2, figsize=(9,5), tight_layout=True\n",
    ")\n",
    "ax, ax2 = axes.flatten()\n",
    "for keys, grp in relative_pos_of_interest.groupby(['type']):\n",
    "    print(keys)\n",
    "    if hetero_pattern in keys[0]:\n",
    "        print(\"sorting out heterogenous trials\")\n",
    "        if keys[0]==trial_type_of_interest[0]:     \n",
    "            follow_epochs_temporal_con.append(grp['ts'][grp['agent_id']==0].values)\n",
    "            follow_epochs_temporal_exp.append(grp['ts'][grp['agent_id']==1].values)\n",
    "            print(f\"the control object is {object_of_interest[0]} and the experimental object is {object_of_interest[1]}\")\n",
    "        else:\n",
    "            follow_epochs_temporal_con.append(grp['ts'][grp['agent_id']==1].values)\n",
    "            follow_epochs_temporal_exp.append(grp['ts'][grp['agent_id']==0].values)\n",
    "    else:\n",
    "        print(\"plotting homogenous trials\")\n",
    "        if keys[0]=='InanimatedLeaderLocust_black':\n",
    "            this_colour='k'\n",
    "        else:\n",
    "            this_colour='r'   \n",
    "        ax.hist(grp['ts'].values,bins=100,density=False,color=this_colour,alpha=0.5)\n",
    "        ax2.hist(grp['ts'].values,bins=100,density=True,color=this_colour,histtype=\"step\",cumulative=True,label=\"Cumulative histogram\")\n",
    "ax.set(xticks=[0,30,60],xlim=(0,60),ylim=(0,400),yticks=[0,200,400],xlabel=\"Time (sec)\",ylabel=\"Count\")\n",
    "ax2.set(\n",
    "    xticks=[0,30,60],\n",
    "    xlabel=\"Time (sec)\",\n",
    "    xlim=(0,60)\n",
    ")\n",
    "        ### this plot shows the temporal distribution of follow epochs in homogenous trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(\n",
    "    nrows=1, ncols=2, figsize=(9,5), tight_layout=True\n",
    ")\n",
    "ax, ax2 = axes.flatten()\n",
    "ax.hist(np.hstack(follow_epochs_temporal_con),bins=100,density=False,color='r',alpha=0.5)\n",
    "ax.hist(np.hstack(follow_epochs_temporal_exp),bins=100,density=False,color='k',alpha=0.5)\n",
    "ax2.hist(np.hstack(follow_epochs_temporal_con),bins=100,density=True,color='r',histtype=\"step\",cumulative=True,label=\"Cumulative histogram\")\n",
    "ax2.hist(np.hstack(follow_epochs_temporal_exp),bins=100,density=True,color='k',histtype=\"step\",cumulative=True,label=\"Cumulative histogram\")\n",
    "ax.set(xticks=[0,30,60],xlim=(0,60),ylim=(0,400),yticks=[0,200,400],xlabel=\"Time (sec)\",ylabel=\"Count\")\n",
    "ax2.set(\n",
    "    xticks=[0,30,60],\n",
    "    xlabel=\"Time (sec)\",\n",
    "    xlim=(0,60)\n",
    ")\n",
    "### this plot shows the temporal distribution of follow epochs in heterogenous trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session 3.0: Calculate other metrics to look for any confounding factors in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Session 3.1: plot distribution trial by trial with seaborn and pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the data type from list into a big concatenated pandas dataframe\n",
    "all_evaluation=pd.concat(trial_evaluation_across_animals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "follow_time_aba,follow_time_tbt,follow_walk_ratio_aba,follow_walk_ratio_tbt=plot_follow_response_distribution(all_evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## optinal, to get more information about experience-dependant responses\n",
    "#follow_time_tbt=all_evaluation['num_follow_epochs']/all_evaluation['number_frames']\n",
    "all_evaluation[\"follow_ratio_previous_trial\"]=pd.concat([pd.Series(np.nan),follow_time_tbt[:-1]],ignore_index=True).to_list()\n",
    "all_evaluation[\"follow_ratio_next_trial\"]=pd.concat([follow_time_tbt[1:],pd.Series(np.nan)],ignore_index=True).to_list()\n",
    "all_evaluation[\"follow_ratio_this_trial\"]=follow_time_tbt\n",
    "all_evaluation.reset_index(drop=True, inplace=True)\n",
    "all_evaluation.loc[all_evaluation.index[all_evaluation['trial_id']==0].tolist(),'follow_ratio_previous_trial']=np.nan\n",
    "all_evaluation.loc[all_evaluation.index[all_evaluation['trial_id']==all_evaluation['trial_id'].max()].tolist(),'follow_ratio_next_trial']=np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Session 3.2: plot distribution animal by animal with seaborn and pandas agg function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the analysis you want to do to summarise individual animal's data is some simple operation like sum or mean, \n",
    "# Then you can use agg function of pandas to do the same thing as above\n",
    "# The benefit of this way is that the end product is still a pandas dataframe so it is easy to make plots and do further analysis\n",
    "#turning metrics of interest into boolian values so that we can use them to filter or group the data\n",
    "all_evaluation['longer_than_30']=all_evaluation['minimum_starvation_time']>30\n",
    "#use cut function to chop the data into 3 groups based on the order of the animal ID so that we can group the data by day\n",
    "all_evaluation['day_group'] = pd.cut(all_evaluation['animal_id'], bins=3, labels=['Day1', 'Day2', 'Day3'])\n",
    "all_evaluation_aba = all_evaluation.groupby('animal_id').agg(\n",
    "    travel_distance=('travel_distance', 'sum'),\n",
    "    gross_turning=('gross_turning', 'sum'),\n",
    "    total_turning=('total_turning', 'sum'),\n",
    "    travel_distance_ISI=('travel_distance_ISI', 'sum'),\n",
    "    gross_turning_ISI=('gross_turning_ISI', 'sum'),\n",
    "    num_follow_epochs=('num_follow_epochs', 'sum'),\n",
    "    num_walk_epochs=('num_walk_epochs', 'sum'),\n",
    "    number_frames=('number_frames','sum'),\n",
    "    minimum_starvation_time=('minimum_starvation_time', 'first'),\n",
    "    day_group=('day_group', 'first'),\n",
    "    longer_than_30=('longer_than_30','first'),\n",
    "    vr_no=('VR', 'first'),\n",
    ")\n",
    "print(all_evaluation_aba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(data=all_evaluation, x=\"travel_distance_ISI\", y=\"num_follow_epochs\", hue=\"longer_than_30\")\n",
    "#sns.jointplot(data=all_evaluation, x=\"travel_distance\", y=\"minimum_starvation_time\")\n",
    "#sns.regplot(data=all_evaluation, x='minimum_starvation_time', y='travel_distance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for degree 45 dataset\n",
    "all_evaluation_aba.loc[7, 'day_group']='Day2'\n",
    "all_evaluation_aba.loc[8, 'day_group']='Day2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if previous pd.cut function split the data correctly. If not, we can use the following code to assign the day_group manually\n",
    "#for degree 60 dataset\n",
    "all_evaluation_aba.loc[11, 'day_group']='Day2'\n",
    "all_evaluation_aba.loc[22, 'day_group']='Day3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plotting tips: If the number of data to plot is smaller, try revealing the real distribution of the data and avoiding kde plot. In this case, instead of using jointplot function, use JoinGrid for the sake of flexibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=sns.jointplot(data=all_evaluation_aba, x=\"travel_distance_ISI\", y=\"num_follow_epochs\", hue=\"longer_than_30\")\n",
    "## add an additional marginal plot to show the distribution of the data\n",
    "a.plot_marginals(sns.rugplot, height=0.15, clip_on=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating an empty JoinGrid object gives you flexibility of every plots\n",
    "b=sns.JointGrid()\n",
    "x, y,h = all_evaluation_aba[\"travel_distance_ISI\"], all_evaluation_aba[\"num_follow_epochs\"], all_evaluation_aba[\"day_group\"]\n",
    "sns.scatterplot(x=x,y=y,hue=h,ax=b.ax_joint)\n",
    "sns.stripplot(x=x,hue=h,ax=b.ax_marg_x,dodge=True,legend=False,jitter=False)\n",
    "sns.histplot(y=y,hue=h,ax=b.ax_marg_y,legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If an non-empty JoinGrid object is created, plot function can give you concise of the code (but only default parameters)\n",
    "c = sns.JointGrid(data=all_evaluation_aba, x=\"travel_distance_ISI\", y=\"gross_turning_ISI\",hue='vr_no')\n",
    "c.plot(sns.scatterplot, sns.histplot)\n",
    "c.refline(y=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session 4: time series analysis of follow choices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Session 4.1: using data from fictrac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_methods.update({\"analysis_window\":[0,60]})\n",
    "var1='mu'\n",
    "var2=None\n",
    "step_interest=np.arange(1, seq_config_all_animals[0].shape[0], 2)\n",
    "export_to_matlab_list=[]\n",
    "step_interest=np.arange(1, seq_config_all_animals[0].shape[0], 2)\n",
    "print(step_interest)\n",
    "## to avoid memory crushed, analyse each animal one by one. In this case we need to comment out the line 85-88 in sorting time series analysis\n",
    "for animal_interest in range(len(seq_config_all_animals)):\n",
    "    ready_to_plot=sort_raster_fictrac(raster_across_animals_fictrac,[animal_interest],step_interest,analysis_methods,all_evaluation,var1,var2)\n",
    "    export_to_matlab_list.append(ready_to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##this can select follower of interest\n",
    "use_aba_threshold=False\n",
    "threshold=0.25\n",
    "based_on_follow_walk_ratio=False\n",
    "if based_on_follow_walk_ratio:\n",
    "    denominator='num_walk_epochs'\n",
    "else:\n",
    "    denominator='number_frames'\n",
    "if use_aba_threshold:\n",
    "    animal_interest=all_evaluation_aba[all_evaluation_aba['num_follow_epochs']/all_evaluation_aba[denominator]>threshold].index\n",
    "    step_interest=np.arange(1, 2*len(all_evaluation['trial_id'].unique()), 2)\n",
    "else:\n",
    "    ##this can select follow trials of interest and convert that into step_id\n",
    "    animal_interest=all_evaluation[all_evaluation['num_follow_epochs']/all_evaluation[denominator]>threshold]['animal_id']\n",
    "    step_interest=all_evaluation[all_evaluation['num_follow_epochs']/all_evaluation[denominator]>threshold]['trial_id']*2+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var1='polar_angle'\n",
    "var2='object'\n",
    "analysis_methods.update({\"analysis_window\":[0,5]})\n",
    "analysis_methods.update({\"split_stationary_moving_ISI\":False})\n",
    "analysis_window=analysis_methods.get(\"analysis_window\")\n",
    "monitor_fps=analysis_methods.get(\"monitor_fps\")\n",
    "n_datapoints=(analysis_window[1]-analysis_window[0])*monitor_fps\n",
    "ready_to_plot=sort_raster_fictrac(raster_across_animals_fictrac,all_evaluation,animal_interest,step_interest,var1,var2,analysis_methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=1, ncols=1, figsize=(9,5), tight_layout=True\n",
    ")\n",
    "    #arg=lambda x: (x.min(), x.max())\n",
    "sns.lineplot(x=\"frame_count\", y=\"heading\",estimator='median',\n",
    "            #errorbar=arg,\n",
    "            data=ready_to_plot,ax=axes)\n",
    "axes.set(\n",
    "    xlabel=\"Time (s)\",\n",
    "    xticks=[0,abs(analysis_window[0]*monitor_fps)-1,n_datapoints-1],\n",
    "    xticklabels=([str(analysis_window[0]),'0', str(analysis_window[1])]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(\n",
    "    nrows=1, ncols=1, figsize=(9,18), tight_layout=True\n",
    ")\n",
    "#p1=np.reshape(this_data['instant_speed'].to_numpy(),(n_datapoints,-1))\n",
    "p1=np.reshape(ready_to_plot['heading'].to_numpy(),(-1,n_datapoints))\n",
    "\n",
    "axes.plot(np.transpose(p1),linewidth=0.1)\n",
    "#mean_p1=np.median(p1,axis=0)\n",
    "mean_p1=circmean(p1,high=180,low=-180,axis=0)\n",
    "axes.plot(mean_p1,'k',linewidth=1)\n",
    "dif_y1,dif_y2=get_fill_between_range(p1,False,True)\n",
    "axes.fill_between(np.arange(n_datapoints),dif_y1,dif_y2, alpha=0.4,color='k')\n",
    "axes.set_ylim([-90,90])\n",
    "axes.set(\n",
    "    xlabel=\"Time (s)\",\n",
    "    xticks=[0,abs(analysis_window[0]*monitor_fps)-1,n_datapoints-1],\n",
    "    xticklabels=([str(analysis_window[0]),'0', str(analysis_window[1])]),\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Session 4.2: using data from unity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if type(raster_across_animals_unity)==list:\n",
    "    all_trials=pd.concat(raster_across_animals_unity)\n",
    "    all_trials=fix_data_type(all_trials)\n",
    "else:\n",
    "    all_trials=fix_data_type(raster_across_animals_unity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for simplicity, classifying trial only based on stationary and walk trails\n",
    "classify_trials=False\n",
    "trial_classifier='velocity'#'velocity' or 'omega'\n",
    "metrics_name='omega'#'velocity' or 'omega'\n",
    "check_baseline_distribution(all_trials,analysis_methods,metrics_name,duration_for_baseline=1)\n",
    "_,these_metrics,these_normalised_metrics=split_trials(analysis_methods,all_trials,metrics_name,'normalised_omega',1)#1 degree or 0.0002 rad\n",
    "_,these_Xs,_=split_trials(analysis_methods,all_trials,\"X\")\n",
    "_,these_Ys,_=split_trials(analysis_methods,all_trials,\"Y\")\n",
    "if classify_trials:\n",
    "    movement_trial_boolean,_,_=split_trials(analysis_methods,all_trials,trial_classifier)\n",
    "else:\n",
    "    movement_trial_boolean=[True]*len(these_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#threshold is around 0.5 to 1 \n",
    "duration_for_baseline=3\n",
    "metrics_name='omega'\n",
    "metrics_name2='normalised_omega'\n",
    "walk_threshold=1\n",
    "monitor_fps=analysis_methods.get(\"monitor_fps\")\n",
    "movement_trial_boolean=[]\n",
    "these_metrics=[]\n",
    "these_normalised_metrics=[]\n",
    "for keys, this_data in all_trials.groupby(['animal_id','id']):\n",
    "    this_metrics=this_data[metrics_name].values\n",
    "    baseline_metrics=np.nanmean(this_metrics[:duration_for_baseline*monitor_fps])\n",
    "    #baseline_metrics=np.cumsum(this_metrics[:duration_for_baseline*monitor_fps])\n",
    "    movement_trial_boolean.append(abs(baseline_metrics)>walk_threshold)\n",
    "    these_metrics.append(this_metrics)\n",
    "    these_normalised_metrics.append(this_data[metrics_name2].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "after_movement_ith_trial,after_no_movement_ith_trial=extract_trial_index(movement_trial_boolean,len(all_trials['animal_id'].unique()),analysis_methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_animal_or_trial_to_analyse(all_evaluation,use_aba_threshold,based_on_follow_walk_ratio,threshold_value=0.25,trial_type_interest=''):\n",
    "    if trial_type_interest=='':\n",
    "        split_trial_type=False\n",
    "    else:\n",
    "        split_trial_type=True\n",
    "    \n",
    "    if based_on_follow_walk_ratio:\n",
    "        denominator='num_walk_epochs'\n",
    "    else:\n",
    "        denominator='number_frames'\n",
    "    if use_aba_threshold==True:\n",
    "        p_follow=all_evaluation.groupby(['animal_id'])['num_follow_epochs'].sum()/all_evaluation.groupby(['animal_id'])[denominator].sum()\n",
    "        #follower_of_interest=(p_follow>fair_follower_threshold) & (p_follow<good_follower_threshold)\n",
    "        #data_of_interest=p_follow>0.14 ### this data of interest means subjects of interest\n",
    "        data_of_interest=p_follow>threshold_value\n",
    "        #rows_of_follower=follower_of_interest.repeat(int(all_evaluation.shape[0]/follower_of_interest.shape[0]))\n",
    "    elif split_trial_type:\n",
    "        data_of_interest=(all_evaluation['num_follow_epochs']/all_evaluation[denominator]>threshold_value)&(all_evaluation['object']==trial_type_interest)\n",
    "    else:\n",
    "        data_of_interest=all_evaluation['num_follow_epochs']/all_evaluation[denominator]>threshold_value\n",
    "        #data_of_interest=(all_evaluation['num_follow_epochs']/all_evaluation[denominator]<threshold_value)&(all_evaluation['num_follow_epochs']/all_evaluation[denominator]>0.1)\n",
    "    return data_of_interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_aba_threshold=False\n",
    "based_on_follow_walk_ratio=False\n",
    "data_of_interest=select_animal_or_trial_to_analyse(all_evaluation,use_aba_threshold,based_on_follow_walk_ratio)\n",
    "row_of_interest=(data_of_interest.reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot the trajectory density map trial type by trial type\n",
    "hetero_x=[]\n",
    "hetero_y=[]\n",
    "hetero_y_flipped=[]\n",
    "homo_x=[]\n",
    "homo_y=[]\n",
    "hetero_pattern='_x_'\n",
    "for this_trial_type in all_evaluation['object'].unique():\n",
    "    print(this_trial_type)\n",
    "    data_of_interest=select_animal_or_trial_to_analyse(all_evaluation,use_aba_threshold,based_on_follow_walk_ratio,threshold_value=0.25,trial_type_interest=this_trial_type)\n",
    "    row_of_interest=(data_of_interest.reset_index(drop=True))\n",
    "    p3,p5,p4,p6=plot_visual_evoked_behaviour(these_Xs,these_Ys,after_movement_ith_trial,after_no_movement_ith_trial,analysis_methods,metrics_name='xy',row_of_interest=row_of_interest)\n",
    "    if hetero_pattern in this_trial_type:\n",
    "        object_of_interest=this_trial_type.split(hetero_pattern)\n",
    "        if object_of_interest[0]=='InanimatedLeaderLocust_black':\n",
    "            p6_flipped= p6*-1\n",
    "        else:\n",
    "            p6_flipped= p6\n",
    "        hetero_x.append(p4)\n",
    "        hetero_y.append(p6)\n",
    "        hetero_y_flipped.append(p6_flipped)\n",
    "    else:\n",
    "        homo_x.append(p4)\n",
    "        homo_y.append(p6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot the trajectory density map from selected heterogeneous trials\n",
    "hetero_x_arr=np.hstack(hetero_x)\n",
    "hetero_y_arr=np.hstack(hetero_y)\n",
    "hetero_y_flipped_arr=np.hstack(hetero_y_flipped)\n",
    "fig, (ax,ax2) = plt.subplots(\n",
    "    nrows=2, ncols=1, figsize=(10,10), tight_layout=True,sharex=True\n",
    ")\n",
    "ax.hist2d(hetero_x_arr[~np.isnan(hetero_x_arr)],hetero_y_arr[~np.isnan(hetero_y_arr)],bins=50)\n",
    "ax.set_ylim([-10,10])\n",
    "ax.set_xlim([0,50])\n",
    "ax2.hist2d(hetero_x_arr[~np.isnan(hetero_x_arr)],hetero_y_flipped_arr[~np.isnan(hetero_y_flipped_arr)],bins=50)\n",
    "ax2.set_ylim([-10,10])\n",
    "ax2.set_xlim([0,50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot the trajectory density map from selected homogeneous trials\n",
    "homo_x_arr=np.hstack(homo_x)\n",
    "homo_y_arr=np.hstack(homo_y)\n",
    "fig, ax = plt.subplots(\n",
    "    nrows=1, ncols=1, figsize=(10,5), tight_layout=True\n",
    ")\n",
    "ax.hist2d(homo_x_arr[~np.isnan(homo_x_arr)],homo_y_arr[~np.isnan(homo_y_arr)],bins=50)\n",
    "ax.set_ylim([-10,10])\n",
    "ax.set_xlim([0,50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_visual_evoked_behaviour(these_metrics,these_normalised_metrics,after_movement_ith_trial,after_no_movement_ith_trial,analysis_methods,metrics_name,row_of_interest=row_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_aba_threshold=False\n",
    "based_on_follow_walk_ratio=False\n",
    "data_of_interest=select_animal_or_trial_to_analyse(all_evaluation,use_aba_threshold,based_on_follow_walk_ratio,threshold_value=0.05)\n",
    "row_of_interest=(data_of_interest.reset_index(drop=True))\n",
    "_,_,_,_=plot_visual_evoked_behaviour(these_Xs,these_Ys,after_movement_ith_trial,after_no_movement_ith_trial,analysis_methods,metrics_name='xy',row_of_interest=row_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "align_with_isi_onset=analysis_methods.get(\"align_with_isi_onset\",False)\n",
    "tmp=np.vstack(these_Xs)\n",
    "tmp2=np.vstack(these_Ys)\n",
    "if align_with_isi_onset:\n",
    "    trials_of_Xs=tmp[::2]\n",
    "    trials_of_Ys=tmp2[::2]\n",
    "else:\n",
    "    trials_of_Xs=tmp[1::2]\n",
    "    trials_of_Ys=tmp2[1::2]\n",
    "theseIndex=[]\n",
    "for this_index in np.where(row_of_interest)[0].tolist():\n",
    "    theseIndex.append(this_index)\n",
    "plot_theseXs=trials_of_Xs[theseIndex,:]\n",
    "plot_theseYs=trials_of_Ys[theseIndex,:]\n",
    "for i in range(len(theseIndex)):\n",
    "    plt.plot(plot_theseXs[i,:],plot_theseYs[i,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session 5.0: Parallel processing and save temporary data when using bands in the follow preference assay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deprecated!!!\n",
    "##this cell start the multi-engines. Make sure to run only once\n",
    "import time\n",
    "import ipyparallel as ipp\n",
    "def show_clusters():\n",
    "    clusters = ipp.ClusterManager().load_clusters() \n",
    "    print(\"{:15} {:^10} {}\".format(\"cluster_id\", \"state\", \"cluster_file\")) \n",
    "    for c in clusters:\n",
    "        cd = clusters[c].to_dict()\n",
    "        cluster_id = cd['cluster']['cluster_id']\n",
    "        controller_state = cd['controller']['state']['state']\n",
    "        cluster_file = getattr(clusters[c], '_trait_values')['cluster_file']\n",
    "        print(\"{:15} {:^10} {}\".format(cluster_id, controller_state, cluster_file))\n",
    "    return cluster_id\n",
    "\n",
    "cluster = ipp.Cluster(n=6)\n",
    "await cluster.start_cluster()\n",
    "cluster_neuropc=show_clusters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Session 5.1: start the multi-engines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##this cell start the multi-engines. Make sure to run only once\n",
    "import ipyparallel as ipp\n",
    "def show_clusters():\n",
    "    clusters = ipp.ClusterManager().load_clusters() \n",
    "    print(\"{:15} {:^10} {}\".format(\"cluster_id\", \"state\", \"cluster_file\")) \n",
    "    for c in clusters:\n",
    "        cd = clusters[c].to_dict()\n",
    "        cluster_id = cd['cluster']['cluster_id']\n",
    "        last_cluster_id = cluster_id  # update for returning later\n",
    "\n",
    "        # Use .get() safely in case 'controller' or 'state' keys are missing\n",
    "        controller_info = cd.get('controller', {}).get('state', {})\n",
    "        controller_state = controller_info.get('state', 'unknown')\n",
    "\n",
    "        cluster_file = getattr(clusters[c], '_trait_values').get('cluster_file', 'N/A')\n",
    "        print(\"{:15} {:^10} {}\".format(cluster_id, controller_state, cluster_file))\n",
    "    \n",
    "    return last_cluster_id  # Return the last cluster_id (or None if no clusters)\n",
    "\n",
    "cluster = ipp.Cluster(n=6)\n",
    "await cluster.start_cluster()\n",
    "cluster_neuropc=show_clusters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Session 5.2: register a function to be used in the parallel computing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##input cluster_id from previous cell\n",
    "rc = ipp.Client(cluster_id=cluster_neuropc)\n",
    "\n",
    "# Create a DirectView for parallel execution\n",
    "dview = rc.direct_view()\n",
    "\n",
    "# Define a function for parallel processing (on NeuroPC, this speed up 3x the analysis)\n",
    "def process_directory(this_dir,this_vr,analysis_methods):\n",
    "    import sys\n",
    "    from pathlib import Path\n",
    "    from sorting_time_series_analysis import follow_behaviour_analysis\n",
    "    current_working_directory = Path.cwd()\n",
    "    parent_dir = current_working_directory.resolve().parents[0]\n",
    "    sys.path.insert(0, str(parent_dir) + \"\\\\utilities\")\n",
    "    from useful_tools import find_file\n",
    "    time_series_analysis = analysis_methods.get(\"time_series_analysis\")\n",
    "    file_suffix = \"_full\" if time_series_analysis else \"\"\n",
    "    agent_pattern = f\"VR{this_vr}*agent{file_suffix}.h5\"\n",
    "    xy_pattern = f\"VR{this_vr}*XY{file_suffix}.h5\"\n",
    "    summary_pattern = f\"VR{this_vr}*score{file_suffix}.h5\"\n",
    "    agent_file = find_file(Path(this_dir), agent_pattern)\n",
    "    focal_animal_file = find_file(Path(this_dir), xy_pattern)\n",
    "    summary_file = find_file(Path(this_dir), summary_pattern)\n",
    "    relative_pos,_,_,_,_=follow_behaviour_analysis(summary_file,focal_animal_file,agent_file,analysis_methods)\n",
    "    return relative_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Session 5.3: update analysis methods and start analysing the registered function via parallel computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update analysis_methods\n",
    "analysis_methods.update({\"plotting_trajectory\": False})\n",
    "analysis_methods.update({\"save_output\":False})\n",
    "analysis_methods.update({\"analysis_window\":[-5,5]})\n",
    "# Use parallel execution to process the data\n",
    "relative_pos_all_animals = dview.map_sync(process_directory, dir_list,vr_no, [analysis_methods] * len(dir_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Session 5.4: save the list asa temporary pickle file to avoid process the same data again and again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the relative position dataframes as a pickle file for later use. \n",
    "# This is necessary for the band assay because it takes time to process follow preference for agents in the band\n",
    "tmp_file_name=f\"{variable_name}_{variable_name2}.pkl\"\n",
    "# Save\n",
    "with open(tmp_file_name, 'wb') as f:\n",
    "    pickle.dump(relative_pos_all_animals, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Session 5.5: turn off the parallel engine. This step seems to help the computer to manager how many engine to be used at once. Therefore, ensure to turn off the engine at the end of the day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Session 5.6: follow the same procedure to calculate follow preference and plot the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## firstly, load the list from the hard drive if it is not available in the local workplace yet \n",
    "if len(relative_pos_all_animals)==0 or \"relative_pos_all_animals\" not in locals():\n",
    "    with open(tmp_file_name, 'rb') as f:\n",
    "        relative_pos_all_animals = pickle.load(f)\n",
    "relative_pos_all_pd=pd.concat(relative_pos_all_animals,ignore_index=True)\n",
    "## get trial type and sort them by the length of the name and then by alphabet. In this case, homogeneous trial should usually be the first duos\n",
    "trial_type_list=sorted(relative_pos_all_pd['type'].unique(), key=len)\n",
    "trial_type_list[2:]=sorted(trial_type_list[2:], key=str,reverse=True)\n",
    "trial_type_list[:2]=sorted(trial_type_list[:2], key=str,reverse=True)\n",
    "print(trial_type_list)\n",
    "'''When a trial type contains _x_ in between the two object types, that means this is an heterogeneous trial.\n",
    "Then the first one is the one listed in the first item in the json file. So far, 20250523, that means the right object, and agent ID 0 in the scene'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_methods.update({\"frequency_based_preference_index\":False})\n",
    "analysis_methods.update({\"exclude_extreme_index\":False})\n",
    "trial_type_of_interest=[trial_type_list[2],trial_type_list[3]]\n",
    "#trial_type_of_interest=[trial_type_list[0],trial_type_list[1]]\n",
    "left_right_preference_across_animals,exp_con_preference_across_animals,_,_,_,_=calculate_preference_index(relative_pos_all_animals,trial_type_of_interest,analysis_methods,thresholds=[4,4.5,5,6,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_preference_index(left_right_preference_across_animals,exp_con_preference_across_animals,trial_type_of_interest,analysis_methods,thresholds=[4,4.5,5,6,8])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "matrexvr_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
