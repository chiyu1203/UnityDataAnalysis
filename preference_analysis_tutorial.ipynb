{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session 0.0: introduce libraries, database path and main independent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "'''\n",
    "if autoreload does not work, try import the python file as a module and then reload the file and the module\n",
    "import plotting_follow_analysis\n",
    "import importlib\n",
    "importlib.reload(plotting_follow_analysis)\n",
    "from plotting_follow_analysis import plot_follow_response_distribution'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## a useful function to generate a data list for further analysis\n",
    "import os,json,sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import circmean\n",
    "from sorting_time_series_analysis import follow_behaviour_analysis,calculate_speed,diff_angular_degree,sort_raster_fictrac\n",
    "from preference_analysis import *\n",
    "from time_series_analysis import *\n",
    "from plotting_follow_analysis import plot_follow_response_distribution\n",
    "##need to add this additional cell because useful tools are in another folder. Need to integrate these two folders one day\n",
    "current_working_directory = Path.cwd()\n",
    "parent_dir = current_working_directory.resolve().parents[0]\n",
    "sys.path.insert(0, str(parent_dir) + \"\\\\utilities\")\n",
    "from useful_tools import select_animals_gpt,find_file,get_fill_between_range\n",
    "from data_cleaning import findLongestConseqSubseq,interp_fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = \"./analysis_methods_dictionary.json\"\n",
    "with open(json_file, \"r\") as f:\n",
    "    analysis_methods = json.loads(f.read())\n",
    "    \n",
    "#Put the folder of your Unity folder below\n",
    "#thisDataset =\"D:/MatrexVR_Swarm_Data/RunData\"\n",
    "#thisDataset =\"D:/MatrexVR_blackbackground_Data/RunData\"\n",
    "#thisDataset =\"D:/MatrexVR_grass1_Data/RunData\"\n",
    "thisDataset =\"D:/MatrexVR_2024_Data/RunData\"\n",
    "#parameter name means independent variable in the experiment\n",
    "#variable_name='mu'\n",
    "variable_name='location'\n",
    "#variable_name='agent_speed'\n",
    "#check trace in trial 115 from VR1_2024-11-16_155242_score_full, maybe there is a jump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def slices_lists(list1, list2,number,list3=[]):\n",
    "#     list1=list1[:number]\n",
    "#     list2=list2[:number]\n",
    "#     list3=list3[:number]\n",
    "#     return list1, list2, list3\n",
    "# dir_list,vr_no,no_food=slices_lists(dir_list, vr_no, 26, no_food)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session 1.0: select animals based on condition and return which a directory list and a list of vr rig number to specify which animal to analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to your Excel file\n",
    "dir_list = []\n",
    "file_type=\".h5\"\n",
    "using_google_sheet=True\n",
    "sheet_name = \"Unity_MatrexVR\"\n",
    "experiment_name=analysis_methods.get(\"experiment_name\")\n",
    "# if type(thisDataset) == str:\n",
    "#     thisDataset = Path(thisDataset)\n",
    "if analysis_methods.get(\"load_individual_data\") == True:\n",
    "    if using_google_sheet==True:\n",
    "        # database_id = \"1UL4eEUrQMapx9xz11-IyOSlPBcep3I9vBJ2uGgVudb8\"\n",
    "        #         #https://docs.google.com/spreadsheets/d/1UL4eEUrQMapx9xz11-IyOSlPBcep3I9vBJ2uGgVudb8/edit?usp=sharing\n",
    "        # url = f\"https://docs.google.com/spreadsheets/d/{database_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}\"\n",
    "        database_id = \"1UL4eEUrQMapx9xz11-IyOSlPBcep1I9vBJ2uGgVudb8\"\n",
    "                #https://docs.google.com/spreadsheets/d/1UL4eEUrQMapx9xz11-IyOSlPBcep1I9vBJ2uGgVudb8/edit?usp=sharing\n",
    "        url = f\"https://docs.google.com/spreadsheets/d/{database_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}\"\n",
    "        #df = pd.read_excel(url, engine='openpyxl')## use this function if the file is not google sheet but uploaded excel file\n",
    "        df = pd.read_csv(url)\n",
    "    else:\n",
    "        excel_file_path = \"Z:/DATA/experiment_trackball_Optomotor/Locusts Management.xlsx\"\n",
    "        print(f\"using a database {excel_file_path} from the server but this file might be outdated\")\n",
    "        # Create a 'with' statement to open and read the Excel file\n",
    "        with pd.ExcelFile(excel_file_path) as xls:\n",
    "            # Read the Excel sheet into a DataFrame with the sheet name (folder name)\n",
    "            df = pd.read_excel(xls, sheet_name)\n",
    "        ##list up the conditions and answers as strings for input argument to select animal. One condition must pair with one answer\n",
    "    if analysis_methods.get(\"select_animals_by_condition\") == True:\n",
    "       #animal_of_interest=select_animals_gpt(df,\"Independent variable (list up all of them in the experiment)\",\"gregarious_leader_grass\",\"Excluding this animal from analysis (Usually when animals die or molt, T/F)\",\"F\")\n",
    "        #animal_of_interest=select_animals_gpt(df,\"Independent variable (list up all of them in the experiment)\",\"gregarious_leader_black\",\"Excluding this animal from analysis (Usually when animals die or molt, T/F)\",\"F\")\n",
    "        #animal_of_interest=select_animals_gpt(df,\"Independent variable (list up all of them in the experiment)\",variable_name)\n",
    "        animal_of_interest=select_animals_gpt(df,\"Independent variable1\",variable_name,\"Independent variable2\",\"bifuration_vr_locust_sta_black_locust\",\"Excluding this animal from analysis (Usually when animals die or molt, T/F)\",\"F\")\n",
    "        #animal_of_interest=select_animals_gpt(df,\"Independent variable1\",variable_name,\"Excluding this animal from analysis (Usually when animals die or molt, T/F)\",\"F\")\n",
    "    else:\n",
    "        animal_of_interest=df\n",
    "    folder_name=animal_of_interest[\"folder name\"].values\n",
    "    dir_tile=np.tile(thisDataset, (len(folder_name), 1))\n",
    "    vr_no=animal_of_interest[\"VR number\"].values\n",
    "    vr_no = vr_no.astype('int')\n",
    "    no_food=animal_of_interest[\"Food retriction (-1 or the number of hours)\"].values\n",
    "    no_food =no_food.astype('int')\n",
    "    dir_list = [''.join([x[0], '/', y]) for x,y in zip(dir_tile,folder_name)]\n",
    "    #dir_dict = itertools.zip_longest(dir_list, vr_no.tolist())\n",
    "    dir_dict = zip(dir_list, vr_no.tolist())\n",
    "else:\n",
    "    for root, dirs, files in os.walk(thisDataset):\n",
    "        for folder in dirs:\n",
    "            folder_path=os.path.join(root,folder)\n",
    "            if any(name.endswith(file_type) for name in os.listdir(folder_path)):\n",
    "                dir_list.append(folder_path.replace(\"\\\\\", \"/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_list=dir_list[:26]\n",
    "vr_no=vr_no[:26] \n",
    "no_food=no_food[:26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_list=dir_list[26:]\n",
    "vr_no=vr_no[26:] \n",
    "no_food=no_food[26:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Session 1.1: introduce helper functions to make plot and calculate speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_methods.update({\"plotting_trajectory\": False})\n",
    "analysis_methods.update({\"save_output\":False})\n",
    "analysis_methods.update({\"analysis_window\":[-20,20]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_pos_all_animals=[]\n",
    "trial_evaluation_across_animals=[]\n",
    "raster_across_animals_unity=[]\n",
    "raster_across_animals_fictrac=[]\n",
    "animal_id=0\n",
    "for this_dir,this_vr,this_no_food in zip(dir_list,vr_no,no_food):\n",
    "    if Path(this_dir).is_dir()==False:\n",
    "        continue\n",
    "    agent_pattern = f\"VR{this_vr}*agent_full.h5\"\n",
    "    xy_pattern = f\"VR{this_vr}*XY_full.h5\"\n",
    "    summary_pattern = f\"VR{this_vr}*score_full.h5\"\n",
    "    pa_pattern=f\"VR{this_vr}*motion.parquet\"\n",
    "    agent_file = find_file(Path(this_dir), agent_pattern)\n",
    "    pa_file=find_file(Path(this_dir), pa_pattern)\n",
    "    focal_animal_file = find_file(Path(this_dir), xy_pattern)\n",
    "    summary_file = find_file(Path(this_dir), summary_pattern)\n",
    "    relative_pos,trial_evaluation_list,raster_unity,num_unfilled_gap,_=follow_behaviour_analysis(summary_file,focal_animal_file,agent_file,analysis_methods)\n",
    "    raster=pd.read_parquet(pa_file, engine='pyarrow')\n",
    "    if animal_id==0:\n",
    "        largest_unfilled_gap=num_unfilled_gap\n",
    "    elif num_unfilled_gap>largest_unfilled_gap:\n",
    "        largest_unfilled_gap=num_unfilled_gap\n",
    "    else:\n",
    "        pass\n",
    "    relative_pos_all_animals.append(relative_pos)\n",
    "    trial_evaluation=pd.concat(trial_evaluation_list)\n",
    "    trial_evaluation.insert(0, 'VR',np.repeat(this_vr,trial_evaluation.shape[0]))\n",
    "    trial_evaluation.insert(0, 'minimum_starvation_time',np.repeat(this_no_food,trial_evaluation.shape[0]))\n",
    "    trial_evaluation.insert(0, 'animal_id',np.repeat(animal_id,trial_evaluation.shape[0]))\n",
    "    trial_evaluation_across_animals.append(trial_evaluation)\n",
    "    raster.insert(0, 'animal_id', np.repeat(animal_id,raster.shape[0]))\n",
    "    raster_across_animals_fictrac.append(raster)\n",
    "    if \"raster_unity\" in locals():\n",
    "        raster_unity.insert(0, 'animal_id', np.repeat(animal_id,raster_unity.shape[0]))\n",
    "        raster_across_animals_unity.append(raster_unity)\n",
    "    animal_id=animal_id+1\n",
    "if \"largest_unfilled_gap\" in locals():\n",
    "    analysis_methods['largest_unfilled_gap']= largest_unfilled_gap\n",
    "else:\n",
    "    print(\"'largest_unfilled_gap' is not defined. Probably because the wrong folder of database is selected or portable USB is not inserted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session 2.0: quantify relative preference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Session 2.1 calculate relative distance to narrow down the definition of follow choices in this assay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculating the relative distance between the focal animal and other agents in every frame\n",
    "relative_pos_all_pd=pd.concat(relative_pos_all_animals,ignore_index=True)\n",
    "relative_pos_all_pd['distance']=relative_pos_all_pd.apply(lambda row:np.sqrt(np.square(row['x']) + np.square(row['y'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get trial type and sort them by the length of the name and then by alphabet. In this case, homogeneous trial should usually be the first twos\n",
    "trial_type_list=sorted(relative_pos_all_pd['type'].unique(), key=len)\n",
    "trial_type_list[2:]=sorted(trial_type_list[2:], key=str,reverse=True)\n",
    "trial_type_list[:2]=sorted(trial_type_list[:2], key=str,reverse=True)\n",
    "print(trial_type_list)\n",
    "# trial_type_of_interest=[trial_type_list[0]]\n",
    "# trial_type_of_interest=[trial_type_list[1]]\n",
    "# trial_type_of_interest=[trial_type_list[2]]\n",
    "# trial_type_of_interest=[trial_type_list[3]]\n",
    "trial_type_of_interest=[trial_type_list[2],trial_type_list[3]]\n",
    "#trial_type_of_interest=[trial_type_list[0],trial_type_list[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for distance_threshold_for_plotting in range(5,30,10):\n",
    "    print(f\"distance threshold for plotting 2D histogram: {distance_threshold_for_plotting} cm\")\n",
    "    if len(trial_type_of_interest)==1:\n",
    "        relative_pos_of_interest=[relative_pos_all_pd[(relative_pos_all_pd['type']==trial_type_of_interest[0]) & (relative_pos_all_pd['distance']<distance_threshold_for_plotting)]]\n",
    "    elif len(trial_type_of_interest)==2:\n",
    "        relative_pos_of_interest=[relative_pos_all_pd[(relative_pos_all_pd['type']==trial_type_of_interest[0]) & (relative_pos_all_pd['distance']<distance_threshold_for_plotting)],relative_pos_all_pd[(relative_pos_all_pd['type']==trial_type_of_interest[1]) & (relative_pos_all_pd['distance']<distance_threshold_for_plotting)]]\n",
    "    plot_relative_pos_distribution(relative_pos_of_interest,trial_type_of_interest,distance_threshold_for_plotting,analysis_methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Session 2.2 calculate preference index based on the narrower definition of follow choices and plot the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_type_of_interest=[trial_type_list[2],trial_type_list[3]]\n",
    "#trial_type_of_interest=[trial_type_list[0],trial_type_list[1]]\n",
    "left_right_preference_across_animals,exp_con_preference_across_animals,_,_=calculate_preference_index(relative_pos_all_animals,trial_type_of_interest,analysis_methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_preference_index(left_right_preference_across_animals,exp_con_preference_across_animals,trial_type_of_interest,analysis_methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Session 2.3 plot relative position and calculate preference index VR rig by VR rig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the preference index for each VR number\n",
    "#trial_type_of_interest=[trial_type_list[0],trial_type_list[1]]\n",
    "plot_relative_position_groupby_vr=True\n",
    "for this_vr in np.unique(vr_no):\n",
    "    print(f\"VR number {this_vr} is used in the experiment\")\n",
    "    ### next time, finish this function to plot relative position distribution for each VR number\n",
    "    if plot_relative_position_groupby_vr==True:\n",
    "        relative_pos_subgroups=[relative_pos_all_animals[x] for x in np.where(vr_no==this_vr)[0]]\n",
    "        relative_pos_sub_pd=pd.concat(relative_pos_subgroups,ignore_index=True)\n",
    "        relative_pos_sub_pd['distance']=relative_pos_sub_pd.apply(lambda row:np.sqrt(np.square(row['x']) + np.square(row['y'])), axis=1)\n",
    "        for distance_threshold_for_plotting in range(5,30,10):\n",
    "            print(f\"distance threshold for plotting 2D histogram: {distance_threshold_for_plotting} cm\")\n",
    "            if len(trial_type_of_interest)==1:\n",
    "                relative_pos_of_interest=[relative_pos_sub_pd[(relative_pos_sub_pd['type']==trial_type_of_interest[0]) & (relative_pos_sub_pd['distance']<distance_threshold_for_plotting)]]\n",
    "            elif len(trial_type_of_interest)==2:\n",
    "                relative_pos_of_interest=[relative_pos_sub_pd[(relative_pos_sub_pd['type']==trial_type_of_interest[0]) & (relative_pos_sub_pd['distance']<distance_threshold_for_plotting)],relative_pos_sub_pd[(relative_pos_sub_pd['type']==trial_type_of_interest[1]) & (relative_pos_sub_pd['distance']<distance_threshold_for_plotting)]]\n",
    "            plot_relative_pos_distribution(relative_pos_of_interest,trial_type_of_interest,distance_threshold_for_plotting,analysis_methods,this_vr=f\"VR{this_vr}\")\n",
    "    if \"left_right_preference_across_animals\" in locals():\n",
    "        plot_preference_index(left_right_preference_across_animals[:,vr_no==this_vr],exp_con_preference_across_animals[:,vr_no==this_vr],trial_type_of_interest,analysis_methods,thresholds=[4,5,6,7,8],this_vr=f\"VR{this_vr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##do some correlation analysis to see if there is any correlation between the preference index and the travel distance or turning angles\n",
    "##whether opened wing makes a difference in the travel distance\n",
    "##analyse speed and follow duration after an animal start to follow the target (distance < 4 cm)\n",
    "##histogram of follow epochs animals by animal and tbt\n",
    "##output velocity and turning angle in every frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session 3.0: Calculate other metrics to look for any confounding factors in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Session 3.1: plot distribution trial by trial with seaborn and pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the data type from list into a big concatenated pandas dataframe\n",
    "all_evaluation=pd.concat(trial_evaluation_across_animals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "follow_time_aba,follow_time_tbt,follow_walk_ratio_aba,follow_walk_ratio_tbt=plot_follow_response_distribution(all_evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## optinal, to get more information about experience-dependant responses\n",
    "#follow_time_tbt=all_evaluation['num_follow_epochs']/all_evaluation['number_frames']\n",
    "all_evaluation[\"follow_ratio_previous_trial\"]=pd.concat([pd.Series(np.nan),follow_time_tbt[:-1]],ignore_index=True).to_list()\n",
    "all_evaluation[\"follow_ratio_next_trial\"]=pd.concat([follow_time_tbt[1:],pd.Series(np.nan)],ignore_index=True).to_list()\n",
    "all_evaluation[\"follow_ratio_this_trial\"]=follow_time_tbt\n",
    "all_evaluation.reset_index(drop=True, inplace=True)\n",
    "all_evaluation.loc[all_evaluation.index[all_evaluation['trial_id']==0].tolist(),'follow_ratio_previous_trial']=np.nan\n",
    "all_evaluation.loc[all_evaluation.index[all_evaluation['trial_id']==all_evaluation['trial_id'].max()].tolist(),'follow_ratio_next_trial']=np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Session 3.2: plot distribution animal by animal with seaborn and pandas agg function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_evaluation.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the analysis you want to do to summarise individual animal's data is some simple operation like sum or mean, \n",
    "# Then you can use agg function of pandas to do the same thing as above\n",
    "# The benefit of this way is that the end product is still a pandas dataframe so it is easy to make plots and do further analysis\n",
    "#turning metrics of interest into boolian values so that we can use them to filter or group the data\n",
    "all_evaluation['longer_than_30']=all_evaluation['minimum_starvation_time']>30\n",
    "#use cut function to chop the data into 3 groups based on the order of the animal ID so that we can group the data by day\n",
    "all_evaluation['day_group'] = pd.cut(all_evaluation['animal_id'], bins=3, labels=['Day1', 'Day2', 'Day3'])\n",
    "all_evaluation_aba = all_evaluation.groupby('animal_id').agg(\n",
    "    travel_distance=('travel_distance', 'sum'),\n",
    "    gross_turning=('gross_turning', 'sum'),\n",
    "    total_turning=('total_turning', 'sum'),\n",
    "    travel_distance_ISI=('travel_distance_ISI', 'sum'),\n",
    "    gross_turning_ISI=('gross_turning_ISI', 'sum'),\n",
    "    num_follow_epochs=('num_follow_epochs', 'sum'),\n",
    "    num_walk_epochs=('num_walk_epochs', 'sum'),\n",
    "    number_frames=('number_frames','sum'),\n",
    "    minimum_starvation_time=('minimum_starvation_time', 'first'),\n",
    "    day_group=('day_group', 'first'),\n",
    "    longer_than_30=('longer_than_30','first'),\n",
    "    vr_no=('VR', 'first'),\n",
    ")\n",
    "print(all_evaluation_aba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(data=all_evaluation, x=\"travel_distance_ISI\", y=\"num_follow_epochs\", hue=\"longer_than_30\")\n",
    "#sns.jointplot(data=all_evaluation, x=\"travel_distance\", y=\"minimum_starvation_time\")\n",
    "#sns.regplot(data=all_evaluation, x='minimum_starvation_time', y='travel_distance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for degree 45 dataset\n",
    "all_evaluation_aba.loc[7, 'day_group']='Day2'\n",
    "all_evaluation_aba.loc[8, 'day_group']='Day2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if previous pd.cut function split the data correctly. If not, we can use the following code to assign the day_group manually\n",
    "#for degree 60 dataset\n",
    "all_evaluation_aba.loc[11, 'day_group']='Day2'\n",
    "all_evaluation_aba.loc[22, 'day_group']='Day3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plotting tips: If the number of data to plot is smaller, try revealing the real distribution of the data and avoiding kde plot. In this case, instead of using jointplot function, use JoinGrid for the sake of flexibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=sns.jointplot(data=all_evaluation_aba, x=\"travel_distance_ISI\", y=\"num_follow_epochs\", hue=\"longer_than_30\")\n",
    "## add an additional marginal plot to show the distribution of the data\n",
    "a.plot_marginals(sns.rugplot, height=0.15, clip_on=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating an empty JoinGrid object gives you flexibility of every plots\n",
    "b=sns.JointGrid()\n",
    "x, y,h = all_evaluation_aba[\"travel_distance_ISI\"], all_evaluation_aba[\"num_follow_epochs\"], all_evaluation_aba[\"day_group\"]\n",
    "sns.scatterplot(x=x,y=y,hue=h,ax=b.ax_joint)\n",
    "sns.stripplot(x=x,hue=h,ax=b.ax_marg_x,dodge=True,legend=False,jitter=False)\n",
    "sns.histplot(y=y,hue=h,ax=b.ax_marg_y,legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If an non-empty JoinGrid object is created, plot function can give you concise of the code (but only default parameters)\n",
    "c = sns.JointGrid(data=all_evaluation_aba, x=\"travel_distance_ISI\", y=\"gross_turning_ISI\",hue='vr_no')\n",
    "c.plot(sns.scatterplot, sns.histplot)\n",
    "c.refline(y=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session 4: time series analysis of follow choices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Session 4.1: using data from fictrac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##this can select follower of interest\n",
    "use_aba_threshold=False\n",
    "threshold=0.25\n",
    "based_on_follow_walk_ratio=False\n",
    "if based_on_follow_walk_ratio:\n",
    "    denominator='num_walk_epochs'\n",
    "else:\n",
    "    denominator='number_frames'\n",
    "if use_aba_threshold:\n",
    "    animal_interest=all_evaluation_aba[all_evaluation_aba['num_follow_epochs']/all_evaluation_aba[denominator]>threshold].index\n",
    "    step_interest=np.arange(1, 2*len(all_evaluation['trial_id'].unique()), 2)\n",
    "else:\n",
    "    ##this can select follow trials of interest and convert that into step_id\n",
    "    animal_interest=all_evaluation[all_evaluation['num_follow_epochs']/all_evaluation[denominator]>threshold]['animal_id']\n",
    "    step_interest=all_evaluation[all_evaluation['num_follow_epochs']/all_evaluation[denominator]>threshold]['trial_id']*2+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var1='polar_angle'\n",
    "var2='object'\n",
    "analysis_methods.update({\"analysis_window\":[0,5]})\n",
    "analysis_methods.update({\"split_stationary_moving_ISI\":False})\n",
    "analysis_window=analysis_methods.get(\"analysis_window\")\n",
    "monitor_fps=analysis_methods.get(\"monitor_fps\")\n",
    "n_datapoints=(analysis_window[1]-analysis_window[0])*monitor_fps\n",
    "ready_to_plot=sort_raster_fictrac(raster_across_animals_fictrac,all_evaluation,animal_interest,step_interest,var1,var2,analysis_methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=1, ncols=1, figsize=(9,5), tight_layout=True\n",
    ")\n",
    "    #arg=lambda x: (x.min(), x.max())\n",
    "sns.lineplot(x=\"frame_count\", y=\"heading\",estimator='median',\n",
    "            #errorbar=arg,\n",
    "            data=ready_to_plot,ax=axes)\n",
    "axes.set(\n",
    "    xlabel=\"Time (s)\",\n",
    "    xticks=[0,abs(analysis_window[0]*monitor_fps)-1,n_datapoints-1],\n",
    "    xticklabels=([str(analysis_window[0]),'0', str(analysis_window[1])]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(\n",
    "    nrows=1, ncols=1, figsize=(9,18), tight_layout=True\n",
    ")\n",
    "#p1=np.reshape(this_data['instant_speed'].to_numpy(),(n_datapoints,-1))\n",
    "p1=np.reshape(ready_to_plot['heading'].to_numpy(),(-1,n_datapoints))\n",
    "\n",
    "axes.plot(np.transpose(p1),linewidth=0.1)\n",
    "#mean_p1=np.median(p1,axis=0)\n",
    "mean_p1=circmean(p1,high=180,low=-180,axis=0)\n",
    "axes.plot(mean_p1,'k',linewidth=1)\n",
    "dif_y1,dif_y2=get_fill_between_range(p1,False,True)\n",
    "axes.fill_between(np.arange(n_datapoints),dif_y1,dif_y2, alpha=0.4,color='k')\n",
    "axes.set_ylim([-90,90])\n",
    "axes.set(\n",
    "    xlabel=\"Time (s)\",\n",
    "    xticks=[0,abs(analysis_window[0]*monitor_fps)-1,n_datapoints-1],\n",
    "    xticklabels=([str(analysis_window[0]),'0', str(analysis_window[1])]),\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Session 4.2: using data from unity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if type(raster_across_animals_unity)==list:\n",
    "    all_trials=pd.concat(raster_across_animals_unity)\n",
    "    all_trials=fix_data_type(all_trials)\n",
    "else:\n",
    "    all_trials=fix_data_type(raster_across_animals_unity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for simplicity, classifying trial only based on stationary and walk trails\n",
    "classify_trials=True\n",
    "trial_classifier='velocity'#'velocity' or 'omega'\n",
    "metrics_name='omega'#'velocity' or 'omega'\n",
    "check_baseline_distribution(all_trials,analysis_methods,metrics_name,duration_for_baseline=1)\n",
    "_,these_metrics,these_normalised_metrics=split_trials(analysis_methods,all_trials,metrics_name,'normalised_omega',1)#1 degree or 0.0002 rad\n",
    "_,these_Xs,_=split_trials(analysis_methods,all_trials,\"X\")\n",
    "_,these_Ys,_=split_trials(analysis_methods,all_trials,\"Y\")\n",
    "if classify_trials:\n",
    "    movement_trial_boolean,_,_=split_trials(analysis_methods,all_trials,trial_classifier)\n",
    "else:\n",
    "    movement_trial_boolean=[True]*len(these_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#threshold is around 0.5 to 1 \n",
    "duration_for_baseline=3\n",
    "metrics_name='omega'\n",
    "metrics_name2='normalised_omega'\n",
    "walk_threshold=1\n",
    "monitor_fps=analysis_methods.get(\"monitor_fps\")\n",
    "movement_trial_boolean=[]\n",
    "these_metrics=[]\n",
    "these_normalised_metrics=[]\n",
    "for keys, this_data in all_trials.groupby(['animal_id','id']):\n",
    "    this_metrics=this_data[metrics_name].values\n",
    "    baseline_metrics=np.nanmean(this_metrics[:duration_for_baseline*monitor_fps])\n",
    "    #baseline_metrics=np.cumsum(this_metrics[:duration_for_baseline*monitor_fps])\n",
    "    movement_trial_boolean.append(abs(baseline_metrics)>walk_threshold)\n",
    "    these_metrics.append(this_metrics)\n",
    "    these_normalised_metrics.append(this_data[metrics_name2].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "after_movement_ith_trial,after_no_movement_ith_trial=extract_trial_index(movement_trial_boolean,len(all_trials['animal_id'].unique()),analysis_methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_animal_or_trial_to_analyse(all_evaluation,use_aba_threshold,based_on_follow_walk_ratio,threshold_value=0.25):\n",
    "    if based_on_follow_walk_ratio:\n",
    "        denominator='num_walk_epochs'\n",
    "    else:\n",
    "        denominator='number_frames'\n",
    "    if use_aba_threshold==True:\n",
    "        p_follow=all_evaluation.groupby(['animal_id'])['num_follow_epochs'].sum()/all_evaluation.groupby(['animal_id'])[denominator].sum()\n",
    "        #follower_of_interest=(p_follow>fair_follower_threshold) & (p_follow<good_follower_threshold)\n",
    "        #data_of_interest=p_follow>0.14 ### this data of interest means subjects of interest\n",
    "        data_of_interest=p_follow>threshold_value\n",
    "        #rows_of_follower=follower_of_interest.repeat(int(all_evaluation.shape[0]/follower_of_interest.shape[0]))\n",
    "    else:\n",
    "        data_of_interest=all_evaluation['num_follow_epochs']/all_evaluation[denominator]>threshold_value\n",
    "        #data_of_interest=(all_evaluation['num_follow_epochs']/all_evaluation[denominator]<threshold_value)&(all_evaluation['num_follow_epochs']/all_evaluation[denominator]>0.1)\n",
    "    return data_of_interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_aba_threshold=False\n",
    "based_on_follow_walk_ratio=False\n",
    "data_of_interest=select_animal_or_trial_to_analyse(all_evaluation,use_aba_threshold,based_on_follow_walk_ratio)\n",
    "row_of_interest=(data_of_interest.reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_visual_evoked_behaviour(these_metrics,these_normalised_metrics,after_movement_ith_trial,after_no_movement_ith_trial,analysis_methods,metrics_name,row_of_interest=row_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_methods.update({\"save_output\":False})\n",
    "plot_visual_evoked_behaviour(these_Xs,these_Ys,after_movement_ith_trial,after_no_movement_ith_trial,analysis_methods,metrics_name='xy',row_of_interest=row_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "align_with_isi_onset=analysis_methods.get(\"align_with_isi_onset\",False)\n",
    "tmp=np.vstack(these_Xs)\n",
    "tmp2=np.vstack(these_Ys)\n",
    "if align_with_isi_onset:\n",
    "    trials_of_Xs=tmp[::2]\n",
    "    trials_of_Ys=tmp2[::2]\n",
    "else:\n",
    "    trials_of_Xs=tmp[1::2]\n",
    "    trials_of_Ys=tmp2[1::2]\n",
    "theseIndex=[]\n",
    "for this_index in np.where(row_of_interest)[0].tolist():\n",
    "    theseIndex.append(this_index)\n",
    "plot_theseXs=trials_of_Xs[theseIndex,:]\n",
    "plot_theseYs=trials_of_Ys[theseIndex,:]\n",
    "for i in range(len(theseIndex)):\n",
    "    plt.plot(plot_theseXs[i,:],plot_theseYs[i,:])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "matrexvr_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
