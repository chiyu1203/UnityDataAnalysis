{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## a useful function to generate a data list for further analysis\n",
    "import os,json,sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from numpy import linalg as LA\n",
    "from scipy import stats\n",
    "from locustvr_converter import preprocess_matrex_data\n",
    "\n",
    "##need to add this additional cell because useful tools are in another folder. Need to integrate these two folders one day\n",
    "current_working_directory = Path.cwd()\n",
    "parent_dir = current_working_directory.resolve().parents[0]\n",
    "sys.path.insert(0, str(parent_dir) + \"\\\\utilities\")\n",
    "from useful_tools import select_animals_gpt,find_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/40642061/how-to-set-axis-ticks-in-multiples-of-pi-python-matplotlib\n",
    "def multiple_formatter(denominator=2, number=np.pi, latex='\\pi'):\n",
    "    def gcd(a, b):\n",
    "        while b:\n",
    "            a, b = b, a%b\n",
    "        return a\n",
    "    def _multiple_formatter(x, pos):\n",
    "        den = denominator\n",
    "        num = int(np.rint(den*x/number))\n",
    "        com = gcd(num,den)\n",
    "        (num,den) = (int(num/com),int(den/com))\n",
    "        if den==1:\n",
    "            if num==0:\n",
    "                return r'$0$'\n",
    "            if num==1:\n",
    "                return r'$%s$'%latex\n",
    "            elif num==-1:\n",
    "                return r'$-%s$'%latex\n",
    "            else:\n",
    "                return r'$%s%s$'%(num,latex)\n",
    "        else:\n",
    "            if num==1:\n",
    "                return r'$\\frac{%s}{%s}$'%(latex,den)\n",
    "            elif num==-1:\n",
    "                return r'$\\frac{-%s}{%s}$'%(latex,den)\n",
    "            else:\n",
    "                return r'$\\frac{%s%s}{%s}$'%(num,latex,den)\n",
    "    return _multiple_formatter\n",
    "\n",
    "class Multiple:\n",
    "    def __init__(self, denominator=2, number=np.pi, latex='\\pi'):\n",
    "        self.denominator = denominator\n",
    "        self.number = number\n",
    "        self.latex = latex\n",
    "    def locator(self):\n",
    "        return plt.MultipleLocator(self.number / self.denominator)\n",
    "    def formatter(self):\n",
    "        return plt.FuncFormatter(multiple_formatter(self.denominator, self.number, self.latex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "from matplotlib import cm\n",
    "class MplColorHelper:\n",
    "    def __init__(self, cmap_name, start_val, stop_val):\n",
    "        self.cmap_name = cmap_name\n",
    "        self.cmap = plt.get_cmap(cmap_name)\n",
    "        self.norm = mpl.colors.Normalize(vmin=start_val, vmax=stop_val)\n",
    "        self.scalarMap = cm.ScalarMappable(norm=self.norm, cmap=self.cmap)\n",
    "\n",
    "    def get_rgb(self, val):\n",
    "        return self.scalarMap.to_rgba(val)\n",
    "colormap_name = \"coolwarm\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Session 0.1: Load analysis methods in python dictionary form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = \"./analysis_methods_dictionary.json\"\n",
    "with open(json_file, \"r\") as f:\n",
    "    analysis_methods = json.loads(f.read())\n",
    "    \n",
    "\n",
    "#Put the folder of your Unity experiment below\n",
    "#thisDataset =\"D:/MatrexVR_Swarm_Data/RunData\"\n",
    "#thisDataset =\"D:/MatrexVR_blackbackground_Data/RunData\"\n",
    "thisDataset =\"D:/MatrexVR_grass1_Data/RunData\"\n",
    "#parameter name means independent variable in the experiment\n",
    "#parameter_name='kappa' \n",
    "parameter_name='mu'\n",
    "#parameter_name='agent_speed'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Session 2.1: select animal based on condition and return which a directory list and a list of vr rig number to specify which animal to analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to your Excel file\n",
    "dir_list = []\n",
    "file_type=\".h5\"\n",
    "using_google_sheet=True\n",
    "sheet_name = \"Unity_MatrexVR\"\n",
    "experiment_name=analysis_methods.get(\"experiment_name\")\n",
    "# if type(thisDataset) == str:\n",
    "#     thisDataset = Path(thisDataset)\n",
    "if analysis_methods.get(\"load_individual_data\") == True:\n",
    "    if using_google_sheet==True:\n",
    "        database_id = \"1UL4eEUrQMapx9xz11-IyOSlPBcep1I9vBJ2uGgVudb8\"\n",
    "                #https://docs.google.com/spreadsheets/d/1UL4eEUrQMapx9xz11-IyOSlPBcep1I9vBJ2uGgVudb8/edit?usp=sharing\n",
    "        url = f\"https://docs.google.com/spreadsheets/d/{database_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}\"\n",
    "        #df = pd.read_excel(url, engine='openpyxl')## use this function if the file is not google sheet but uploaded excel file\n",
    "        df = pd.read_csv(url)\n",
    "    else:\n",
    "        excel_file_path = \"Z:/DATA/experiment_trackball_Optomotor/Locusts Management.xlsx\"\n",
    "        print(f\"using a database {excel_file_path} from the server but this file might be outdated\")\n",
    "        # Create a 'with' statement to open and read the Excel file\n",
    "        with pd.ExcelFile(excel_file_path) as xls:\n",
    "            # Read the Excel sheet into a DataFrame with the sheet name (folder name)\n",
    "            df = pd.read_excel(xls, sheet_name)\n",
    "        ##list up the conditions and answers as strings for input argument to select animal. One condition must pair with one answer\n",
    "    if analysis_methods.get(\"select_animals_by_condition\") == True:\n",
    "       #animal_of_interest=select_animals_gpt(df,\"Independent variable (list up all of them in the experiment)\",\"gregarious_leader_grass\",\"Excluding this animal from analysis (Usually when animals die or molt, T/F)\",\"F\")\n",
    "        #animal_of_interest=select_animals_gpt(df,\"Independent variable (list up all of them in the experiment)\",\"gregarious_leader_black\",\"Excluding this animal from analysis (Usually when animals die or molt, T/F)\",\"F\")\n",
    "        #animal_of_interest=select_animals_gpt(df,\"Independent variable (list up all of them in the experiment)\",parameter_name)\n",
    "        animal_of_interest=select_animals_gpt(df,\"Independent variable (list up all of them in the experiment)\",parameter_name,\"Excluding this animal from analysis (Usually when animals die or molt, T/F)\",\"F\")\n",
    "    else:\n",
    "        animal_of_interest=df\n",
    "    folder_name=animal_of_interest[\"folder name\"].values\n",
    "\n",
    "    dir_tile=np.tile(thisDataset, (len(folder_name), 1))\n",
    "    vr_no=animal_of_interest[\"VR number\"].values\n",
    "    dir_list = [''.join([x[0], '/', y]) for x,y in zip(dir_tile,folder_name)]\n",
    "    #dir_dict = itertools.zip_longest(dir_list, vr_no.tolist())\n",
    "    dir_dict = zip(dir_list, vr_no.tolist())\n",
    "else:\n",
    "    for root, dirs, files in os.walk(thisDataset):\n",
    "        for folder in dirs:\n",
    "            folder_path=os.path.join(root,folder)\n",
    "            if any(name.endswith(file_type) for name in os.listdir(folder_path)):\n",
    "                dir_list.append(folder_path.replace(\"\\\\\", \"/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trajectory_analysis(df_XY):\n",
    "    trajec_lim=150\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=2, ncols=2, figsize=(18, 14), tight_layout=True\n",
    "    )\n",
    "    plt.rcParams.update(plt.rcParamsDefault)\n",
    "    plt.rcParams.update({'font.size': 8})\n",
    "    # Set the axis line width to 2\n",
    "    plt.rcParams['ytick.major.width'] = 2\n",
    "    plt.rcParams['xtick.major.width'] = 2\n",
    "    plt.rcParams['axes.linewidth'] = 2\n",
    "    #plt.rcParams['font.family'] = 'Helvetica'\n",
    "    cmap = plt.get_cmap('viridis')\n",
    "    ax1, ax2, ax3, ax4 = axes.flatten()\n",
    "    ax1.set(\n",
    "        xlim=(-1*trajec_lim, trajec_lim),\n",
    "        ylim=(-1*trajec_lim, trajec_lim),\n",
    "        yticks=([-1*trajec_lim, 0, trajec_lim]),\n",
    "        xticks=([-1*trajec_lim, 0, trajec_lim]),\n",
    "        aspect=('equal'),\n",
    "        title='ISI'\n",
    "    )\n",
    "    ax2.set(\n",
    "        xlim=(-1*trajec_lim, trajec_lim),\n",
    "        ylim=(-1*trajec_lim, trajec_lim),\n",
    "        yticks=([-1*trajec_lim, 0, trajec_lim]),\n",
    "        xticks=([-1*trajec_lim, 0, trajec_lim]),\n",
    "        aspect=('equal'),\n",
    "        title='Direction 0'\n",
    "    )\n",
    "    ax3.set(\n",
    "        xlim=(-1*trajec_lim, trajec_lim),\n",
    "        ylim=(-1*trajec_lim, trajec_lim),\n",
    "        yticks=([-1*trajec_lim, 0, trajec_lim]),\n",
    "        xticks=([-1*trajec_lim, 0, trajec_lim]),\n",
    "        aspect=('equal'),\n",
    "        title='Direction 45'\n",
    "    )\n",
    "    ax4.set(\n",
    "        xlim=(-1*trajec_lim, trajec_lim),\n",
    "        ylim=(-1*trajec_lim, trajec_lim),\n",
    "        yticks=([-1*trajec_lim, 0, trajec_lim]),\n",
    "        xticks=([-1*trajec_lim, 0, trajec_lim]),\n",
    "        aspect=('equal'),\n",
    "        title='Direction 315'\n",
    "    )      \n",
    "    for key, grp in df_XY.groupby('fname'):\n",
    "        if grp['type'][0]=='empty_trial':\n",
    "            ax1.scatter(grp[\"X\"].values,grp[\"Y\"].values, c=np.arange(grp.shape[0]), marker=\".\", alpha=0.5)\n",
    "        else:\n",
    "            if grp['mu'][0]==0:\n",
    "                ax2.scatter(grp[\"X\"].values,grp[\"Y\"].values, c=np.arange(grp.shape[0]), marker=\".\", alpha=0.5)\n",
    "            elif grp['mu'][0]==45:\n",
    "                ax3.scatter(grp[\"X\"].values,grp[\"Y\"].values, c=np.arange(grp.shape[0]), marker=\".\", alpha=0.5)\n",
    "            elif grp['mu'][0]==315:\n",
    "                ax4.scatter(grp[\"X\"].values,grp[\"Y\"].values, c=np.arange(grp.shape[0]), marker=\".\", alpha=0.5)\n",
    "            else:\n",
    "                print(\"unexpected direction\")\n",
    "    ax2.plot(df_agent.loc[df_agent['mu'] == 0]['X'].values,df_agent.loc[df_agent['mu'] == 0]['Y'].values,color='k')\n",
    "    ax3.plot(df_agent.loc[df_agent['mu'] == 45]['X'].values,df_agent.loc[df_agent['mu'] == 45]['Y'].values,color='k')\n",
    "    ax4.plot(df_agent.loc[df_agent['mu'] == 315]['X'].values,df_agent.loc[df_agent['mu'] == 315]['Y'].values,color='k')\n",
    "\n",
    "    #plt.savefig(fig_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_speed(dif_x,dif_y,ts,number_frame_scene_changing=5):\n",
    "    focal_distance_fbf=np.sqrt(np.sum([dif_x**2,dif_y**2],axis=0))\n",
    "    focal_distance_fbf[0:number_frame_scene_changing]=np.nan\n",
    "    instant_speed=focal_distance_fbf/np.diff(ts)\n",
    "    return instant_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_window=analysis_methods.get(\"analysis_window\")\n",
    "monitor_fps=analysis_methods.get(\"monitor_fps\")\n",
    "analysis_window=[-30,30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2.0, analysis walking behavours before and after the presence of stimulus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajec_lim=150\n",
    "good_follower_only=True\n",
    "duration_for_baseline=3\n",
    "alignment_with_stim_onset=1\n",
    "number_frame_scene_changing=5\n",
    "dif_across_animals=[]\n",
    "animal_id=0\n",
    "for this_dir,this_vr in zip(dir_list,vr_no):\n",
    "    if Path(this_dir).is_dir()==False:\n",
    "        continue\n",
    "    if good_follower_only:\n",
    "        if (follow_proportion_across_animals[animal_id]>0.4) and (follow_proportion_across_animals[animal_id]<0.2):\n",
    "        #if follow_proportion_across_animals[animal_id]<0.4:\n",
    "            animal_id+=1\n",
    "            continue\n",
    "\n",
    "    agent_pattern = f\"VR{this_vr}*agent_full.h5\"\n",
    "    found_result = find_file(Path(this_dir), agent_pattern)\n",
    "    if found_result is not None:\n",
    "        df_agent = pd.read_hdf(found_result)\n",
    "    xy_pattern = f\"VR{this_vr}*XY_full.h5\"\n",
    "    found_result = find_file(Path(this_dir), xy_pattern)\n",
    "    if found_result is None:\n",
    "        continue\n",
    "    df_XY = pd.read_hdf(found_result)\n",
    "    df_XY['this_vr']=this_vr\n",
    "    df_XY['fname']=df_XY['fname'].astype(str) + '_' + df_XY['this_vr'].astype(str)\n",
    "    #trajectory_analysis(df_XY)\n",
    "    dif_across_trials=[]\n",
    "    if 'basedline_v' in locals():\n",
    "        del basedline_v\n",
    "    trial_id=0\n",
    "    for key, grp in df_XY.groupby('fname'):\n",
    "        focal_xy=np.vstack((grp[\"X\"].to_numpy(),grp[\"Y\"].to_numpy()))\n",
    "        distance_from_centre=np.sqrt(np.sum([focal_xy[0]**2,focal_xy[1]**2],axis=0))\n",
    "        ts=grp[\"ts\"].to_numpy()\n",
    "        dif_x=np.diff(focal_xy[0])\n",
    "        dif_y=np.diff(focal_xy[1])\n",
    "        instant_speed=cal_speed(dif_x,dif_y,ts)\n",
    "        angles = np.degrees(np.arctan2(dif_y, dif_x)) ## return angles in degree, between -180 and 180\n",
    "        angles[0:number_frame_scene_changing]=np.nan\n",
    "        angular_speed=angles/np.diff(ts)\n",
    "        #time_series_plot(distance_from_centre,instant_speed,angular_speed,frame_range)\n",
    "        if 'type' in df_XY.columns:\n",
    "            if alignment_with_stim_onset:\n",
    "                if grp['type'][0]=='empty_trial':\n",
    "                    print('ISI now')\n",
    "                    frame_range=analysis_window[0]*monitor_fps\n",
    "                    d_of_interest=distance_from_centre[frame_range:]\n",
    "                    v_of_interest=instant_speed[frame_range:]\n",
    "                    w_of_interest=angular_speed[frame_range:]\n",
    "                    basedline_v=np.mean(v_of_interest[-duration_for_baseline*monitor_fps:])\n",
    "                    normalised_v=np.repeat(np.nan,v_of_interest.shape[0])\n",
    "\n",
    "                else:\n",
    "                    print('stim now')\n",
    "                    frame_range=analysis_window[1]*monitor_fps\n",
    "                    d_of_interest=distance_from_centre[:frame_range]\n",
    "                    v_of_interest=instant_speed[:frame_range]\n",
    "                    w_of_interest=angular_speed[:frame_range]\n",
    "                    if 'basedline_v' in locals():\n",
    "                    #if trial_id%96 != 0 and 'basedline_v' in locals():\n",
    "                        normalised_v=v_of_interest/basedline_v\n",
    "                    else:\n",
    "                        normalised_v=np.repeat(np.nan,v_of_interest.shape[0])\n",
    "            else:\n",
    "                if grp['type'][0]=='empty_trial':\n",
    "                    frame_range=analysis_window[1]*monitor_fps\n",
    "                    d_of_interest=distance_from_centre[:frame_range]\n",
    "                    v_of_interest=instant_speed[:frame_range]\n",
    "                    w_of_interest=angular_speed[:frame_range]\n",
    "                else:\n",
    "                    frame_range=analysis_window[0]*monitor_fps\n",
    "                    d_of_interest=distance_from_centre[frame_range:]\n",
    "                    v_of_interest=instant_speed[frame_range:]\n",
    "                    w_of_interest=angular_speed[frame_range:]\n",
    "        else:\n",
    "            if alignment_with_stim_onset:\n",
    "                if grp['density'][0]==0.0:\n",
    "                    print('ISI now')\n",
    "                    frame_range=analysis_window[0]*monitor_fps\n",
    "                    d_of_interest=distance_from_centre[frame_range:]\n",
    "                    v_of_interest=instant_speed[frame_range:]\n",
    "                    w_of_interest=angular_speed[frame_range:]\n",
    "\n",
    "                else:\n",
    "                    print('Stim now')\n",
    "                    frame_range=analysis_window[1]*monitor_fps\n",
    "                    d_of_interest=distance_from_centre[:frame_range]\n",
    "                    v_of_interest=instant_speed[:frame_range]\n",
    "                    w_of_interest=angular_speed[:frame_range]\n",
    "            else:\n",
    "                if grp['density'][0]==0.0:\n",
    "                    frame_range=analysis_window[1]*monitor_fps\n",
    "                    d_of_interest=distance_from_centre[:frame_range]\n",
    "                    v_of_interest=instant_speed[:frame_range]\n",
    "                    w_of_interest=angular_speed[:frame_range]\n",
    "                    if 'basedline_v' in locals():\n",
    "                    #if trial_id%96 != 0 and 'basedline_v' in locals():\n",
    "                        normalised_v=v_of_interest/basedline_v\n",
    "                    else:\n",
    "                        normalised_v=np.repeat(np.nan,v_of_interest.shape[0])\n",
    "                else:\n",
    "                    frame_range=analysis_window[0]*monitor_fps\n",
    "                    d_of_interest=distance_from_centre[frame_range:]\n",
    "                    v_of_interest=instant_speed[frame_range:]\n",
    "                    w_of_interest=angular_speed[frame_range:]\n",
    "                    basedline_v=np.mean(v_of_interest[-duration_for_baseline*monitor_fps:])\n",
    "                    normalised_v=np.repeat(np.nan,v_of_interest.shape[0])\n",
    "\n",
    "        if 'type' in df_XY.columns:\n",
    "            con_matrex=(d_of_interest,v_of_interest,w_of_interest,normalised_v,np.repeat(trial_id,v_of_interest.shape[0]),np.repeat(grp['mu'][0],v_of_interest.shape[0]),np.repeat(grp['type'][0],v_of_interest.shape[0]))\n",
    "        else:\n",
    "            con_matrex=(d_of_interest,v_of_interest,w_of_interest,normalised_v,np.repeat(trial_id,v_of_interest.shape[0]),np.repeat(grp['mu'][0],v_of_interest.shape[0]),np.repeat(grp['density'][0],v_of_interest.shape[0]))\n",
    "        raw_data=np.vstack(con_matrex)\n",
    "        dif_across_trials.append(pd.DataFrame(np.transpose(raw_data)))\n",
    "        trial_id += 1\n",
    "    tmp=pd.concat(dif_across_trials)\n",
    "    if 'type' in df_XY.columns:\n",
    "        tmp.columns = ['distance_from_centre', 'velocity','omega','normalised_v','id','mu','object']\n",
    "    else:\n",
    "        tmp.columns = ['distance_from_centre', 'velocity','omega','normalised_v','id','mu','density']\n",
    "    tmp.insert(0, 'animal_id', np.repeat(animal_id,tmp.shape[0]))\n",
    "    dif_across_animals.append(tmp)\n",
    "    animal_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_format(all_trials):\n",
    "\n",
    "    all_trials['id'] = all_trials['id'].astype(int)\n",
    "    all_trials['mu'] = all_trials['mu'].astype(int)\n",
    "    all_trials['velocity'] = all_trials['velocity'].astype(float)\n",
    "    all_trials['normalised_v'] = all_trials['normalised_v'].astype(float)\n",
    "    if 'density' in all_trials.columns:\n",
    "        all_trials['density'] = all_trials['density'].astype(int)\n",
    "    return all_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "if type(dif_across_animals)==list:\n",
    "    all_trials=pd.concat(dif_across_animals)\n",
    "    all_trials=fix_format(all_trials)\n",
    "else:\n",
    "    all_trials=fix_format(dif_across_animals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "these_baselines=[]\n",
    "for keys, this_data in all_trials.groupby(['animal_id','id']):\n",
    "    if alignment_with_stim_onset:\n",
    "        if keys[1]%2==0:#to only use stim trials\n",
    "            this_speed=this_data['velocity'].values\n",
    "            #print(this_speed)\n",
    "            these_baselines.append(np.mean(this_speed[-duration_for_baseline*monitor_fps:]))\n",
    "    \n",
    "    else:\n",
    "        if keys[1]%2!=0:#to only use ISI trials\n",
    "            this_speed=this_data['velocity'].values\n",
    "            these_baselines.append(np.mean(this_speed[-duration_for_baseline*monitor_fps:]))\n",
    "plt.hist(np.vstack(these_baselines),bins=100)\n",
    "plt.minorticks_on()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_threshold=1\n",
    "walk_trials_boo=[]\n",
    "these_speed=[]\n",
    "these_normalised_speed=[]\n",
    "for keys, this_data in all_trials.groupby(['animal_id','id']):\n",
    "    this_speed=this_data['velocity'].values\n",
    "    baseline_speed=np.mean(this_speed[-duration_for_baseline*monitor_fps:])\n",
    "    walk_trials_boo.append(baseline_speed>walk_threshold)\n",
    "    these_speed.append(this_speed)\n",
    "    these_normalised_speed.append(this_data['normalised_v'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "if alignment_with_stim_onset:\n",
    "    after_walk_ith_trial=[i+1 for i, x in enumerate(walk_trials_boo[::2]) if x and i % int((trial_id)/2) != (trial_id)/2-1]\n",
    "    after_stationary_ith_trial=[i+1 for i, x in enumerate(walk_trials_boo[::2]) if x==False and i % int((trial_id)/2) != (trial_id)/2-1]\n",
    "    # if walk_trials_boo[1]==False:## not sure why this is not working\n",
    "    #     after_stationary_ith_trial.insert(1)\n",
    "else:\n",
    "    after_walk_ith_trial=[i+1 for i, x in enumerate(walk_trials_boo[1::2]) if x and i % int((trial_id)/2) != (trial_id)/2-1]\n",
    "    if walk_trials_boo[1]==True:\n",
    "        after_walk_ith_trial.insert(1)\n",
    "# if walk_trials_boo[1]==False:\n",
    "#     after_walk_ith_trial.insert(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp=np.vstack(these_speed)\n",
    "isi_speed=tmp[::2]\n",
    "stim_speed=tmp[1::2]\n",
    "tmp=np.vstack(these_normalised_speed)\n",
    "isi_norm_speed=tmp[::2]\n",
    "stim_norm_speed=tmp[1::2]\n",
    "# monitor_fps=analysis_methods.get('monitor_fps')\n",
    "# prefered_fps=monitor_fps/2\n",
    "# x = np.linspace(0, isi_speed.shape[1]/monitor_fps, num=isi_speed.shape[1])\n",
    "# bin_mean_speed, bin_edges, binnumber = stats.binned_statistic(x, isi_speed[after_walk_ith_trial,:],\n",
    "#         statistic='mean', bins=prefered_fps)\n",
    "# bin_mean_normalised_speed, bin_edges, binnumber = stats.binned_statistic(x, isi_norm_speed[after_walk_ith_trial,:],\n",
    "#         statistic='mean', bins=prefered_fps)\n",
    "fig, axes = plt.subplots(\n",
    "        nrows=2, ncols=2, figsize=(9,10), tight_layout=True\n",
    "    )\n",
    "ax1, ax2, ax3, ax4 = axes.flatten()\n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "plt.rcParams.update({'font.size': 8})\n",
    "# Set the axis line width to 2\n",
    "plt.rcParams['ytick.major.width'] = 1\n",
    "plt.rcParams['xtick.major.width'] = 1\n",
    "plt.rcParams['axes.linewidth'] = 1\n",
    "cmap = plt.get_cmap('viridis')\n",
    "# ax1.set(\n",
    "#     # yticks=[0,90,180],\n",
    "#     #ylim=(-np.pi-0.1, np.pi+0.1),\n",
    "#     ylim=(0, 10),\n",
    "# )\n",
    "\n",
    "#ax1.plot(bin_edges[:-1],np.transpose(bin_mean_speed),linewidth=0.1)\n",
    "#ax1.scatter(np.tile(bin_edges[:-1],(bin_mean_speed.shape[0],1)),bin_mean_speed)\n",
    "# for i in range(bin_mean_speed.shape[0]):\n",
    "#     ax1.hlines(bin_mean_speed[i,:], bin_edges[:-1], bin_edges[1:],lw=2)\n",
    "# #ax2.plot(bin_edges[:-1],np.transpose(bin_mean_normalised_speed),linewidth=0.1)\n",
    "\n",
    "# ax1.plot(np.transpose(isi_speed[after_walk_ith_trial,:]),linewidth=0.1)\n",
    "# ax1.plot(np.mean(isi_speed[after_walk_ith_trial,:],axis=0),'k',linewidth=5)\n",
    "# ax2.plot(np.transpose(isi_norm_speed[after_walk_ith_trial,:]),linewidth=0.1)\n",
    "\n",
    "# ax2.plot(np.mean(isi_norm_speed[after_walk_ith_trial,:],axis=0),'k',linewidth=5)\n",
    "ax1.plot(np.transpose(stim_speed[after_stationary_ith_trial,:]),linewidth=0.1)\n",
    "ax1.plot(np.median(stim_speed[after_stationary_ith_trial,:],axis=0),'k',linewidth=1)\n",
    "ax2.plot(np.transpose(stim_norm_speed[after_stationary_ith_trial,:]),linewidth=0.1)\n",
    "\n",
    "ax2.plot(np.median(stim_norm_speed[after_stationary_ith_trial,:],axis=0),'k',linewidth=1)\n",
    "ax2.set_yscale('log')\n",
    "ax1.set(\n",
    "    ylabel=\"Speed (cm/s)\",\n",
    "    xlabel=\"frame\",\n",
    ")\n",
    "ax2.set(\n",
    "    ylabel=\"normalised speed (ratio)\",\n",
    "    xlabel=\"frame\",\n",
    ")\n",
    "ax3.plot(np.transpose(stim_speed[after_walk_ith_trial,:]),linewidth=0.1)\n",
    "ax3.plot(np.median(stim_speed[after_walk_ith_trial,:],axis=0),'k',linewidth=1)\n",
    "ax4.plot(np.transpose(stim_norm_speed[after_walk_ith_trial,:]),linewidth=0.1)\n",
    "\n",
    "ax4.plot(np.median(stim_norm_speed[after_walk_ith_trial,:],axis=0),'k',linewidth=1)\n",
    "ax4.set_yscale('log')\n",
    "ax3.set(\n",
    "    ylabel=\"Speed (cm/s)\",\n",
    "    xlabel=\"frame\",\n",
    ")\n",
    "ax4.set(\n",
    "    ylabel=\"normalised speed (ratio)\",\n",
    "    xlabel=\"frame\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1.1, analysis following behavours in response to receding stimuli from different direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_series_plot(target_distance,instant_speed,angles,analysis_window):\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=3, ncols=1, figsize=(9, 7), tight_layout=True\n",
    "    )\n",
    "    plt.rcParams.update(plt.rcParamsDefault)\n",
    "    plt.rcParams.update({'font.size': 8})\n",
    "    # Set the axis line width to 2\n",
    "    plt.rcParams['ytick.major.width'] = 2\n",
    "    plt.rcParams['xtick.major.width'] = 2\n",
    "    plt.rcParams['axes.linewidth'] = 2\n",
    "    cmap = plt.get_cmap('viridis')\n",
    "    ax1, ax2, ax3= axes.flatten()\n",
    "    ax1.set(\n",
    "        title='Distance'\n",
    "    )\n",
    "    ax2.set(\n",
    "        title='Instant Speed'\n",
    "    )\n",
    "    ax3.set(\n",
    "        # yticks=[0,90,180],\n",
    "        #ylim=(-np.pi-0.1, np.pi+0.1),\n",
    "        # ylim=(-5, 185),\n",
    "        title='angular deviation'\n",
    "    )\n",
    "    # ax3.yaxis.set_major_locator(plt.MultipleLocator(np.pi / 2))\n",
    "    # ax3.yaxis.set_minor_locator(plt.MultipleLocator(np.pi / 4))\n",
    "    # ax3.yaxis.set_major_formatter(plt.FuncFormatter(multiple_formatter()))\n",
    "    ax1.plot(np.arange(target_distance.shape[0]),target_distance)\n",
    "    ax2.plot(np.arange(instant_speed.shape[0]),instant_speed)\n",
    "    ax3.plot(np.arange(angles.shape[0]),angles)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pool animal's response together according to conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajec_lim=150\n",
    "max_target_distance=50\n",
    "number_frame_scene_changing=5\n",
    "dif_across_animals=[]\n",
    "raw_across_animals=[]\n",
    "follow_proportion_across_animals=[]\n",
    "animal_id=0\n",
    "for this_dir,this_vr in zip(dir_list,vr_no):\n",
    "    if Path(this_dir).is_dir()==False:\n",
    "        print(f'no such a dir exist {this_dir}')\n",
    "        continue\n",
    "    agent_pattern = f\"VR{this_vr}*agent_full.h5\"\n",
    "    xy_pattern = f\"VR{this_vr}*XY_full.h5\"\n",
    "    found_result = find_file(Path(this_dir), agent_pattern)\n",
    "    df_agent = pd.read_hdf(found_result)\n",
    "    found_result = find_file(Path(this_dir), xy_pattern)\n",
    "    df_XY = pd.read_hdf(found_result)\n",
    "    df_agent['this_vr']=this_vr\n",
    "    df_agent['fname']=df_agent['fname'].astype(str) + '_' + df_agent['this_vr'].astype(str)   \n",
    "    df_XY['this_vr']=this_vr\n",
    "    df_XY['fname']=df_XY['fname'].astype(str) + '_' + df_XY['this_vr'].astype(str)\n",
    "    trajectory_analysis(df_XY)\n",
    "    dif_across_trials=[]\n",
    "    follow_epochs_across_trials=np.ones((len(df_agent['fname'].unique()),1))\n",
    "    total_epochs_across_trials=np.ones((len(df_agent['fname'].unique()),1))\n",
    "    raw_data_list=[]\n",
    "    trial_id=0\n",
    "    for key, grp in df_XY.groupby('fname'):\n",
    "        if grp['type'][0]=='empty_trial':\n",
    "            continue\n",
    "        else:\n",
    "            #print(f\"stimulus degree: {grp['mu'][0]}\")\n",
    "            focal_xy=np.vstack((grp[\"X\"].to_numpy(),grp[\"Y\"].to_numpy()))\n",
    "            distance_from_centre=np.sqrt(np.sum([focal_xy[0]**2,focal_xy[1]**2],axis=0))\n",
    "            ts=grp[\"ts\"].to_numpy()\n",
    "            instant_speed= cal_speed(np.diff(focal_xy[0]),np.diff(focal_xy[1]),ts)\n",
    "            focal_distance_fbf=instant_speed*np.diff(ts)\n",
    "            agent_xy=np.vstack((df_agent[df_agent['fname']==key][\"X\"].to_numpy(),df_agent[df_agent['fname']==key][\"Y\"].to_numpy()))\n",
    "            agent_distance_fbf=np.sqrt(np.sum([np.diff(agent_xy)[0]**2,np.diff(agent_xy)[1]**2],axis=0))\n",
    "            vector_dif=agent_xy-focal_xy\n",
    "            theta = np.radians(grp['mu'][0]-360)  \n",
    "            rot_matrix = np.array([[np.cos(theta), -np.sin(theta)],\n",
    "                                [np.sin(theta), np.cos(theta)]])# calculate the rotation matrix to align the agent to move along the same direction\n",
    "            vector_dif_rotated=rot_matrix @ vector_dif\n",
    "            target_distance=LA.norm(vector_dif, axis=0)\n",
    "            dot_product=np.diag(np.matmul(np.transpose(np.diff(focal_xy)),np.diff(agent_xy)))\n",
    "            angles = np.arccos(dot_product/focal_distance_fbf/agent_distance_fbf)\n",
    "            angles_in_degree= angles*180/np.pi\n",
    "            time_series_plot(target_distance,instant_speed,angles_in_degree,analysis_window)\n",
    "            #epochs_of_interest=np.logical_and(target_distance[1:]<max_target_distance, instant_speed>1)#a condition before fixing angles\n",
    "            epochs_of_interest=np.ones((instant_speed.shape[0]))==1.0#created a all-true array\n",
    "            follow_sercan=np.logical_and(target_distance[1:]<max_target_distance, instant_speed>1,angles_in_degree<10)\n",
    "\n",
    "            vector_dif_rotated=vector_dif_rotated[:,1:]\n",
    "            degree_in_the_trial=np.repeat(grp['mu'][0],np.transpose(grp['ts'].values).shape[0])\n",
    "            degree_time=np.vstack((degree_in_the_trial,grp['ts'].values))\n",
    "            degree_time=degree_time[:,1:]\n",
    "            follow_wrap=np.concat((vector_dif_rotated[:,epochs_of_interest],degree_time[:,epochs_of_interest]))\n",
    "            dif_across_trials.append(pd.DataFrame(np.transpose(follow_wrap)))\n",
    "            ###wrap up some raw data\n",
    "            follow_epochs_across_trials[trial_id]=sum(follow_sercan)\n",
    "            total_epochs_across_trials[trial_id]=angles_in_degree.shape[0]\n",
    "            id_time=np.vstack((np.repeat(trial_id,np.transpose(grp['ts'].values).shape[0]),grp['ts'].values))\n",
    "            con_matrex=(focal_xy,agent_xy,id_time)\n",
    "            raw_data=np.concat(con_matrex)\n",
    "            raw_data_list.append(pd.DataFrame(np.transpose(raw_data)))\n",
    "            trial_id=trial_id+1\n",
    "    tmp=pd.concat(dif_across_trials)\n",
    "    if tmp.shape[1]==2:\n",
    "        tmp.columns = ['x', 'y']\n",
    "    elif tmp.shape[1]==4:\n",
    "        tmp.columns = ['x', 'y','degree','ts']\n",
    "    r_tmp=pd.concat(raw_data_list)\n",
    "    r_tmp.columns=['focal_x','focal_y','agent_x','agent_y','trial_id','ts']\n",
    "    r_tmp.insert(0, 'animal_id', np.repeat(animal_id,r_tmp.shape[0]))\n",
    "    #fig, ax = plt.subplots(dpi=300, figsize=(2,2))\n",
    "    #plt.hist2d(tmp['x'].values,tmp['y'].values)\n",
    "    #fig, ax = plt.subplots(dpi=300, figsize=(2,2))\n",
    "    #sns.histplot(tmp,x='x',y='y')\n",
    "    #plt.show()\n",
    "    follow_proportion_across_animals.append(sum(follow_epochs_across_trials)[0]/sum(total_epochs_across_trials)[0])\n",
    "    dif_across_animals.append(tmp)\n",
    "    raw_across_animals.append(r_tmp)\n",
    "    animal_id=animal_id+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using 1D histogram to plot proportion of time and 2D histogram to plot relative position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi=300, figsize=(2,2))\n",
    "ax.hist(np.vstack(follow_proportion_across_animals))\n",
    "#ax1.set(adjustable='box', aspect='equal')\n",
    "ax.set(xticks=[0,0.5,1],xlim=(0,1),yticks=[0,20],ylim=(0,20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials=pd.concat(dif_across_animals)\n",
    "fig, axes = plt.subplots(nrows=1, ncols=len(all_trials[\"degree\"].unique()),tight_layout=True,sharex=True, sharey=True)\n",
    "i=0\n",
    "for key, grp in all_trials.groupby('degree'):\n",
    "    print(f\"stimulus degree: {key}\")\n",
    "    axes[i].hist2d(grp['x'].values,grp['y'].values,bins=400)\n",
    "    axes[i].set(adjustable='box', aspect='equal')\n",
    "    axes[i].set(\n",
    "    yticks=[-40,0,40],\n",
    "    xticks=[-20,0,20,40],\n",
    "    xlim=(-20,100),ylim=(-45, 45))\n",
    "    i=i+1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##plot potential follow response in 2D histogram\n",
    "all_trials=pd.concat(dif_across_animals)\n",
    "fig, ax = plt.subplots(dpi=300, figsize=(2,2))\n",
    "plt.hist2d(all_trials['x'].values,all_trials['y'].values,bins=36)\n",
    "fig, ax = plt.subplots(dpi=300, figsize=(2,2))\n",
    "sns.histplot(all_trials,x='x',y='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##save the raw data into mat file for matlab\n",
    "from scipy.io import savemat\n",
    "all_raw=pd.concat(raw_across_animals)\n",
    "all_raw['trial_id']=all_raw['trial_id'].astype(int)\n",
    "data_dict = {name: col.values for name, col in all_raw.items()}\n",
    "summary_file_name = Path(thisDataset) /\"time_series_curated.mat\"\n",
    "savemat(summary_file_name, data_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "matrexvr_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
