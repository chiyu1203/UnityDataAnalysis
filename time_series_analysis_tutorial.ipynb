{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session 0.0: introduce libraries, database path and main independent variable"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T19:23:23.600323Z",
     "start_time": "2025-07-01T19:23:23.557428Z"
    }
   },
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T19:23:24.954107Z",
     "start_time": "2025-07-01T19:23:24.923958Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from Z_compatibility import access_utilities\n",
    "access_utilities()"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T19:23:26.979122Z",
     "start_time": "2025-07-01T19:23:26.853164Z"
    }
   },
   "source": [
    "## a useful function to generate a data list for further analysis\n",
    "import os,json,sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from sorting_time_series_analysis import follow_behaviour_analysis,generate_points_within_rectangles,calculate_speed,diff_angular_degree,sort_raster_fictrac\n",
    "from plotting_follow_analysis import *\n",
    "from time_series_analysis import *\n",
    "from scipy.stats import circmean\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.signal import medfilt\n",
    "import seaborn as sns\n",
    "##need to add this additional cell because useful tools are in another folder. Need to integrate these two folders one day\n",
    "current_working_directory = Path.cwd()\n",
    "parent_dir = current_working_directory.resolve().parents[0]\n",
    "sys.path.insert(0, str(parent_dir) + \"\\\\utilities\")\n",
    "from useful_tools import select_animals_gpt,find_file,column_name_list,get_fill_between_range,read_seq_config\n",
    "from data_cleaning import findLongestConseqSubseq,interp_fill"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Session 0.2: Load analysis methods in python dictionary form"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T19:25:44.569339Z",
     "start_time": "2025-07-01T19:25:44.510416Z"
    }
   },
   "source": [
    "json_file = \"./analysis_methods_dictionary.json\"\n",
    "with open(json_file, \"r\") as f:\n",
    "    analysis_methods = json.loads(f.read())\n",
    "    \n",
    "#Put the folder of your Unity folder below\n",
    "#thisDataset =\"D:/MatrexVR_Swarm_Data/RunData\"\n",
    "#thisDataset =\"D:/MatrexVR_blackbackground_Data/RunData\"\n",
    "#thisDataset =\"D:/MatrexVR_grass1_Data/RunData\"\n",
    "#thisDataset =\"D:/MatrexVR_2024_Data/RunData\"\n",
    "thisDataset =\"/Volumes/AG_Couzin-Fuchs/DATA/experiment_trackball_Optomotor/locustVR\"\n",
    "#thisDataset =r\"C:\\Users\\neuroLaptop\\Documents\\MatrexVR_2024_Data\\RunData\"\n",
    "#parameter name means independent variable in the experiment\n",
    "#variable_name='mu'\n",
    "variable_name='location'\n",
    "#variable_name='initial_position'\n",
    "#variable_name='agent_speed'\n",
    "#check trace in trial 115 from VR1_2024-11-16_155242_score_full, maybe there is a jump\n",
    "exp_name=analysis_methods.get(\"experiment_name\")"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Session 1.0: select animals based on condition and return which a directory list and a list of vr rig number to specify which animal to analyse"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T19:25:53.946414Z",
     "start_time": "2025-07-01T19:25:49.487267Z"
    }
   },
   "source": [
    "# Define the path to your Excel file\n",
    "dir_list = []\n",
    "file_type=\".h5\"\n",
    "using_google_sheet=True\n",
    "exp_name=analysis_methods.get(\"experiment_name\")\n",
    "if exp_name=='locustvr':\n",
    "    sheet_name = 'LocustVR'\n",
    "else:\n",
    "    sheet_name = \"Unity_MatrexVR\"\n",
    "\n",
    "# if type(thisDataset) == str:\n",
    "#     thisDataset = Path(thisDataset)\n",
    "if analysis_methods.get(\"load_individual_data\") == True:\n",
    "    if using_google_sheet==True:\n",
    "        # database_id = \"1UL4eEUrQMapx9xz11-IyOSlPBcep3I9vBJ2uGgVudb8\"\n",
    "        #         #https://docs.google.com/spreadsheets/d/1UL4eEUrQMapx9xz11-IyOSlPBcep3I9vBJ2uGgVudb8/edit?usp=sharing\n",
    "        # url = f\"https://docs.google.com/spreadsheets/d/{database_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}\"\n",
    "        database_id = \"1UL4eEUrQMapx9xz11-IyOSlPBcep1I9vBJ2uGgVudb8\"\n",
    "                #https://docs.google.com/spreadsheets/d/1UL4eEUrQMapx9xz11-IyOSlPBcep1I9vBJ2uGgVudb8/edit?usp=sharing\n",
    "        url = f\"https://docs.google.com/spreadsheets/d/{database_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}\"\n",
    "        #df = pd.read_excel(url, engine='openpyxl')## use this function if the file is not google sheet but uploaded excel file\n",
    "        df = pd.read_csv(url)\n",
    "    else:\n",
    "        excel_file_path = \"Z:/DATA/experiment_trackball_Optomotor/Locusts Management.xlsx\"\n",
    "        print(f\"using a database {excel_file_path} from the server but this file might be outdated\")\n",
    "        # Create a 'with' statement to open and read the Excel file\n",
    "        with pd.ExcelFile(excel_file_path) as xls:\n",
    "            # Read the Excel sheet into a DataFrame with the sheet name (folder name)\n",
    "            df = pd.read_excel(xls, sheet_name)\n",
    "        ##list up the conditions and answers as strings for input argument to select animal. One condition must pair with one answer\n",
    "    if analysis_methods.get(\"select_animals_by_condition\") == True:\n",
    "       #animal_of_interest=select_animals_gpt(df,\"Independent variable (list up all of them in the experiment)\",\"gregarious_leader_grass\",\"Excluding this animal from analysis (Usually when animals die or molt, T/F)\",\"F\")\n",
    "        #animal_of_interest=select_animals_gpt(df,\"Independent variable (list up all of them in the experiment)\",\"gregarious_leader_black\",\"Excluding this animal from analysis (Usually when animals die or molt, T/F)\",\"F\")\n",
    "        #animal_of_interest=select_animals_gpt(df,\"Independent variable1\",variable_name,\"Excluding this animal from analysis (Usually when animals die or molt, T/F)\",\"F\")\n",
    "        animal_of_interest=select_animals_gpt(df,\"Excluding this animal from analysis (Usually when animals die or molt, T/F)\",\"F\")\n",
    "        #animal_of_interest=select_animals_gpt(df,\"Independent variable1\",variable_name,\"Independent variable2\",\"bifuration_constant_speed_constant_distance\",\"Excluding this animal from analysis (Usually when animals die or molt, T/F)\",\"F\")\n",
    "        #animal_of_interest=select_animals_gpt(df,\"Independent variable1\",variable_name,\"Independent variable2\",\"choice_vr_locust_black_locust\",\"Excluding this animal from analysis (Usually when animals die or molt, T/F)\",\"F\")\n",
    "        #animal_of_interest=select_animals_gpt(df,\"Independent variable1\",variable_name,\"Independent variable2\",\"choice_vr_locust_sta_black_locust\",\"Background\",\"grass1\",\"Excluding this animal from analysis (Usually when animals die or molt, T/F)\",\"F\")\n",
    "        \n",
    "        #animal_of_interest=select_animals_gpt(df,\"Independent variable1\",variable_name,\"Independent variable2\",\"closed_loop_sta_black_locust_open_loop_sta_black_locust\",\"Excluding this animal from analysis (Usually when animals die or molt, T/F)\",\"F\")\n",
    "        #animal_of_interest=select_animals_gpt(df,\"Independent variable1\",variable_name,\"Independent variable2\",\"sta_black_locust_2dir_3_initial_position\",\"Excluding this animal from analysis (Usually when animals die or molt, T/F)\",\"F\")\n",
    "    else:\n",
    "        animal_of_interest=df\n",
    "\n",
    "    if exp_name=='locustvr':\n",
    "        ID_array=animal_of_interest[\"ID\"].values\n",
    "        print(f\"these are the ID of the animals {ID_array}\")\n",
    "        dir_list = [\n",
    "        root.replace(\"\\\\\", \"/\")\n",
    "        for root, _, files in os.walk(thisDataset)\n",
    "        if any(ID in root for ID in ID_array)\n",
    "        and any(file.endswith(file_type) for file in files)]\n",
    "    else:\n",
    "        folder_name=animal_of_interest[\"folder name\"].values\n",
    "        dir_tile=np.tile(thisDataset, (len(folder_name), 1))\n",
    "        vr_no=animal_of_interest[\"VR number\"].values\n",
    "        vr_no = vr_no.astype('int')\n",
    "        no_food=animal_of_interest[\"Food retriction (-1 or the number of hours)\"].values\n",
    "        no_food = no_food.astype('int')\n",
    "        dir_list = [''.join([x[0], '/', y]) for x,y in zip(dir_tile,folder_name)]\n",
    "        #dir_dict = itertools.zip_longest(dir_list, vr_no.tolist())\n",
    "        dir_dict = zip(dir_list, vr_no.tolist())\n",
    "else:\n",
    "    for root, dirs, files in os.walk(thisDataset):\n",
    "        for folder in dirs:\n",
    "            folder_path=os.path.join(root,folder)\n",
    "            if any(name.endswith(file_type) for name in os.listdir(folder_path)):\n",
    "                dir_list.append(folder_path.replace(\"\\\\\", \"/\"))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "these are the ID of the animals ['GN25001' 'GN25002' 'GN25003' 'GN25004' 'GN25006' 'GN25007' 'GN25008'\n",
      " 'GN25009' 'GN25011' 'GN25012' 'GN25013' 'GN25014' 'GN25015' 'GN25016'\n",
      " 'GN25017' 'GN25018']\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T19:25:54.007915Z",
     "start_time": "2025-07-01T19:25:53.973950Z"
    }
   },
   "cell_type": "code",
   "source": "dir_list",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Volumes/AG_Couzin-Fuchs/DATA/experiment_trackball_Optomotor/locustVR/GN25001/20250624/choices/session1',\n",
       " '/Volumes/AG_Couzin-Fuchs/DATA/experiment_trackball_Optomotor/locustVR/GN25002/20250624/choices/session1',\n",
       " '/Volumes/AG_Couzin-Fuchs/DATA/experiment_trackball_Optomotor/locustVR/GN25003/20250624/choices/session1',\n",
       " '/Volumes/AG_Couzin-Fuchs/DATA/experiment_trackball_Optomotor/locustVR/GN25004/20250624/choices/session1',\n",
       " '/Volumes/AG_Couzin-Fuchs/DATA/experiment_trackball_Optomotor/locustVR/GN25006/20250625/choices/session1',\n",
       " '/Volumes/AG_Couzin-Fuchs/DATA/experiment_trackball_Optomotor/locustVR/GN25007/20250625/choices/session1',\n",
       " '/Volumes/AG_Couzin-Fuchs/DATA/experiment_trackball_Optomotor/locustVR/GN25008/20250625/choices/session1',\n",
       " '/Volumes/AG_Couzin-Fuchs/DATA/experiment_trackball_Optomotor/locustVR/GN25009/20250625/choices/session1',\n",
       " '/Volumes/AG_Couzin-Fuchs/DATA/experiment_trackball_Optomotor/locustVR/GN25011/20250625/choices/session1',\n",
       " '/Volumes/AG_Couzin-Fuchs/DATA/experiment_trackball_Optomotor/locustVR/GN25012/20250626/choices/session1',\n",
       " '/Volumes/AG_Couzin-Fuchs/DATA/experiment_trackball_Optomotor/locustVR/GN25013/20250626/choices/session1',\n",
       " '/Volumes/AG_Couzin-Fuchs/DATA/experiment_trackball_Optomotor/locustVR/GN25014/20250626/choices/session1',\n",
       " '/Volumes/AG_Couzin-Fuchs/DATA/experiment_trackball_Optomotor/locustVR/GN25015/20250626/choices/session1',\n",
       " '/Volumes/AG_Couzin-Fuchs/DATA/experiment_trackball_Optomotor/locustVR/GN25016/20250626/choices/session1',\n",
       " '/Volumes/AG_Couzin-Fuchs/DATA/experiment_trackball_Optomotor/locustVR/GN25017/20250627/choices/session1',\n",
       " '/Volumes/AG_Couzin-Fuchs/DATA/experiment_trackball_Optomotor/locustVR/GN25018/20250627/choices/session1']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_list=dir_list[32:]\n",
    "vr_no=vr_no[32:]\n",
    "no_food=no_food[32:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_list=dir_list[:32]\n",
    "vr_no=vr_no[:32]\n",
    "no_food=no_food[:32]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.0: Pool animal's response together according to some criteria (from none criteria to criteria that can define the follow behaviour)\n",
    "Output1: a list 'follow_proportion_across_animals' showing the proportion of 'follow' time for each animal (across trials)\n",
    "\n",
    "Output2: a list 'relative_pos_all_animals' showing relative position between virtual and focal locusts across time. 1st and 2nd columns shown relative x and y, 3rd columns shown virtual animal's moving direction. 4th column shown the timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_methods.update({\"follow_locustVR_criteria\": True})\n",
    "analysis_methods.update({\"plotting_trajectory\": False})\n",
    "analysis_methods.update({\"analysis_window\":[-20,20]})\n",
    "analysis_methods.update({\"follow_within_distance\": 50})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_pos_all_animals=[]\n",
    "simulated_relative_pos_all_animals=[]\n",
    "trial_evaluation_across_animals=[]\n",
    "raster_across_animals_unity=[]\n",
    "raster_across_animals_fictrac=[]\n",
    "seq_config_all_animals=[]\n",
    "animal_id=0\n",
    "read_fictrac_data_only=analysis_methods.get(\"read_fictrac_data_only\")\n",
    "time_series_analysis = analysis_methods.get(\"time_series_analysis\")\n",
    "file_suffix = \"_full\" if time_series_analysis else \"\"\n",
    "for this_dir,this_vr,this_no_food in zip(dir_list,vr_no,no_food):\n",
    "    if Path(this_dir).is_dir()==False:\n",
    "        continue\n",
    "    # if this_vr==4:\n",
    "    #     continue\n",
    "    if read_fictrac_data_only==False:\n",
    "        agent_pattern = f\"VR{this_vr}*agent{file_suffix}.h5\"\n",
    "        xy_pattern = f\"VR{this_vr}*XY{file_suffix}.h5\"\n",
    "        summary_pattern = f\"VR{this_vr}*score{file_suffix}.h5\"\n",
    "        agent_file = find_file(Path(this_dir), agent_pattern)\n",
    "        focal_animal_file = find_file(Path(this_dir), xy_pattern)\n",
    "        summary_file = find_file(Path(this_dir), summary_pattern)\n",
    "        relative_pos,trial_evaluation_list,raster_unity,num_unfilled_gap,simulated_relative_pos=follow_behaviour_analysis(summary_file,focal_animal_file,agent_file,analysis_methods)\n",
    "        if animal_id==0:\n",
    "            largest_unfilled_gap=num_unfilled_gap\n",
    "        elif num_unfilled_gap>largest_unfilled_gap:\n",
    "            largest_unfilled_gap=num_unfilled_gap\n",
    "        else:\n",
    "            pass\n",
    "        relative_pos_all_animals.append(relative_pos)\n",
    "        if len(simulated_relative_pos)>0:\n",
    "            simulated_relative_pos_all_animals.append(simulated_relative_pos)\n",
    "        trial_evaluation=pd.concat(trial_evaluation_list)\n",
    "        trial_evaluation.insert(0, 'VR',np.repeat(this_vr,trial_evaluation.shape[0]))\n",
    "        trial_evaluation.insert(0, 'no_food_hour',np.repeat(this_no_food,trial_evaluation.shape[0]))\n",
    "        trial_evaluation.insert(0, 'animal_id',np.repeat(animal_id,trial_evaluation.shape[0]))\n",
    "        trial_evaluation_across_animals.append(trial_evaluation)\n",
    "        raster_unity.insert(0, 'animal_id', np.repeat(animal_id,raster_unity.shape[0]))\n",
    "        raster_across_animals_unity.append(raster_unity)\n",
    "    seq_config_pattern=f\"*sequenceConfig.json\"\n",
    "    seq_config_file=find_file(Path(this_dir), seq_config_pattern)\n",
    "    seq_config_pd=read_seq_config(seq_config_file)\n",
    "    seq_config_pd.insert(0, 'step_id',np.arange(seq_config_pd.shape[0]))\n",
    "    seq_config_pd.insert(0, 'animal_id',np.repeat(animal_id,seq_config_pd.shape[0]))\n",
    "    seq_config_all_animals.append(seq_config_pd)\n",
    "    pa_pattern=f\"VR{this_vr}*motion{file_suffix}.parquet\"\n",
    "    pa_file=find_file(Path(this_dir), pa_pattern)\n",
    "    raster=pd.read_parquet(pa_file, engine='pyarrow')\n",
    "    raster.insert(0, 'animal_id', np.repeat(animal_id,raster.shape[0]))\n",
    "    raster_across_animals_fictrac.append(raster)\n",
    "    animal_id=animal_id+1\n",
    "if \"largest_unfilled_gap\" in locals():\n",
    "    analysis_methods['largest_unfilled_gap']= largest_unfilled_gap\n",
    "elif len(raster_across_animals_fictrac)==0:\n",
    "    print(\"'largest_unfilled_gap' is not defined and fictrac files are collected. Probably because the wrong folder of database is selected or portable USB is not inserted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 2.1: convert the trial by trial analysis across animals into a panda dataframe and calculate some additional information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_evaluation=pd.concat(trial_evaluation_across_animals)\n",
    "follow_time_tbt=all_evaluation['num_follow_epochs']/all_evaluation['number_frames']\n",
    "all_evaluation[\"follow_ratio_previous_trial\"]=pd.concat([pd.Series(np.nan),follow_time_tbt[:-1]],ignore_index=True).to_list()\n",
    "all_evaluation[\"follow_ratio_next_trial\"]=pd.concat([follow_time_tbt[1:],pd.Series(np.nan)],ignore_index=True).to_list()\n",
    "all_evaluation[\"follow_ratio_this_trial\"]=follow_time_tbt\n",
    "all_evaluation.reset_index(drop=True, inplace=True)\n",
    "all_evaluation.loc[all_evaluation.index[all_evaluation['trial_id']==0].tolist(),'follow_ratio_previous_trial']=np.nan\n",
    "all_evaluation.loc[all_evaluation.index[all_evaluation['trial_id']==all_evaluation['trial_id'].max()].tolist(),'follow_ratio_next_trial']=np.nan\n",
    "#all_evaluation.to_csv(\"all_evaluation.csv\",index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 2.2: Analyse follow ratio in different situation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this cell analyses the follow ratio in different length of ISI\n",
    "graph_colour_code = analysis_methods.get(\"graph_colour_code\")\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10,5), tight_layout=True)\n",
    "ax1, ax2= axes.flatten()\n",
    "i=0\n",
    "for keys, grp in all_evaluation.groupby(['duration_ISI']):\n",
    "    print(keys)\n",
    "    this_color=graph_colour_code[i]\n",
    "    ax1.scatter(grp['follow_ratio_previous_trial'],grp['follow_ratio_this_trial'],c=this_color)\n",
    "    ax2.scatter(grp['follow_ratio_this_trial'],grp['follow_ratio_next_trial'],c=this_color)\n",
    "    i=i+1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "follow_time_aba,follow_time_tbt,_,_=plot_follow_response_distribution(all_evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_follow_response_distribution(all_evaluation)\n",
    "follow_time_aba,follow_time_tbt=plot_follow_response_distribution(all_evaluation[all_evaluation['speed']==2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##plot the relationship between travel distance and proportion of following time\n",
    "# print(\"first 1/3 best of followers:\", np.quantile(follow_time_aba, 0.66))\n",
    "# print(\"middle 1/3 best of followers:\", np.quantile(follow_time_aba, 0.33))\n",
    "camera_fps=analysis_methods.get(\"camera_fps\")\n",
    "fair_follower_threshold=np.quantile(follow_time_aba, 0.33)\n",
    "good_follower_threshold=np.quantile(follow_time_aba, 0.66)\n",
    "con_follow_time_list=[]\n",
    "con_travel_distance_list=[]\n",
    "exp_follow_time_list=[]\n",
    "exp_travel_distance_list=[]\n",
    "fig, axes = plt.subplots(\n",
    "        nrows=2, ncols=2, figsize=(9,10), tight_layout=True\n",
    "    )\n",
    "ax1, ax2, ax3, ax4 = axes.flatten()\n",
    "ax1.set(xticks=[0,0.25,0.5,0.75,1],xticklabels=(['0', '25', '50', '75', '100']),xlim=(0,0.5))\n",
    "ax2.set(xticks=[0,0.25,0.5,0.75,1],xticklabels=(['0', '25', '50', '75', '100']),xlim=(0,1))\n",
    "for keys, this_data in all_evaluation.groupby(['animal_id']):\n",
    "    p_follow=this_data['num_follow_epochs'].sum()/this_data['number_frames'].sum()\n",
    "    if p_follow>good_follower_threshold:\n",
    "        color='k'\n",
    "    elif (p_follow>fair_follower_threshold) and (p_follow<good_follower_threshold):\n",
    "        color='k'\n",
    "    else:\n",
    "        color='k'\n",
    "    ax1.scatter(this_data['num_follow_epochs'].sum()/this_data['number_frames'].sum(),this_data['travel_distance'].sum(),c=color,s=8)\n",
    "    ax3.scatter(this_data['num_follow_epochs'].sum()/this_data['number_frames'].sum(),this_data['total_turning'].sum(),c=color,s=8)\n",
    "    # if p_follow>good_follower_threshold:\n",
    "    #     pass\n",
    "    # elif (p_follow>fair_follower_threshold) and (p_follow<good_follower_threshold):\n",
    "    #     pass\n",
    "    # else:\n",
    "    #     continue\n",
    "    for i,this_object in enumerate(sorted(this_data['object'].unique(), key=len)):\n",
    "        these_num_follow_epochs=this_data['num_follow_epochs'][this_data['object']==this_object]\n",
    "        these_num_frames=this_data['number_frames'][this_data['object']==this_object]\n",
    "        these_travel_distance=this_data['travel_distance'][this_data['object']==this_object]\n",
    "        these_total_turning=this_data['total_turning'][this_data['object']==this_object]\n",
    "        if this_object=='mov_glocust' or this_object== \"LeaderLocust\":\n",
    "            # ax2.scatter(these_num_follow_epochs/these_num_frames,these_travel_distance,c=color,s=8)\n",
    "            # ax4.scatter(these_num_follow_epochs/these_num_frames,these_total_turning,c=color,s=8)\n",
    "            ax2.scatter(these_num_follow_epochs/these_num_frames,these_travel_distance,c='b',s=8)\n",
    "            ax4.scatter(these_num_follow_epochs/these_num_frames,these_total_turning,c='b',s=8)\n",
    "            follow_time_ratio_tbt=these_num_follow_epochs/these_num_frames\n",
    "            con_follow_time_list.append(follow_time_ratio_tbt.values)\n",
    "            con_travel_distance_list.append(these_travel_distance.values)\n",
    "        else:\n",
    "            # ax2.scatter(these_num_follow_epochs/these_num_frames,these_travel_distance,edgecolors=color,marker='o', facecolors='none',s=8)\n",
    "            # ax4.scatter(these_num_follow_epochs/these_num_frames,these_total_turning,edgecolors=color,marker='o', facecolors='none',s=8)\n",
    "            ax2.scatter(these_num_follow_epochs/these_num_frames,these_travel_distance,c='r',s=8)\n",
    "            ax4.scatter(these_num_follow_epochs/these_num_frames,these_total_turning,c='r',s=8)\n",
    "            follow_time_ratio_tbt=these_num_follow_epochs/these_num_frames\n",
    "            exp_follow_time_list.append(follow_time_ratio_tbt.values)\n",
    "            exp_travel_distance_list.append(these_travel_distance.values)\n",
    "ax3.set(xticks=[0,0.25,0.5,0.75,1],xticklabels=(['0', '25', '50', '75', '100']),xlim=(0,0.5))\n",
    "ax4.set(xticks=[0,0.25,0.5,0.75,1],xticklabels=(['0', '25', '50', '75', '100']),xlim=(0,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_follow_time_arr=np.hstack(con_follow_time_list)\n",
    "con_travel_distance_arr=np.hstack(con_travel_distance_list)\n",
    "exp_follow_time_arr=np.hstack(exp_follow_time_list)\n",
    "exp_travel_distance_arr=np.hstack(exp_travel_distance_list)\n",
    "mean_con_follow_time=np.nanmean(con_follow_time_arr)\n",
    "sem_con_follow_time=np.nanstd(con_follow_time_arr, ddof=1) / np.sqrt(con_follow_time_arr.shape[0])\n",
    "mean_con_travel_distance=np.nanmean(con_travel_distance_arr)\n",
    "sem_con_travel_distance=np.nanstd(con_travel_distance_arr, ddof=1) / np.sqrt(con_travel_distance_arr.shape[0])\n",
    "mean_exp_follow_time=np.nanmean(exp_follow_time_arr)\n",
    "sem_exp_follow_time=np.nanstd(exp_follow_time_arr, ddof=1) / np.sqrt(exp_follow_time_arr.shape[0])\n",
    "mean_exp_travel_distance=np.nanmean(exp_travel_distance_arr)\n",
    "sem_exp_travel_distance=np.nanstd(exp_travel_distance_arr, ddof=1) / np.sqrt(exp_travel_distance_arr.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, ax = plt.subplots(figsize=(3,3), dpi=300)\n",
    "save_output=True\n",
    "palette = {\n",
    "    'InanimatedLeaderLocust_black': 'tab:blue',\n",
    "    'LeaderLocust': 'tab:red',\n",
    "}\n",
    "svg_name = f\"follow_time_vs_travel_distance.svg\"\n",
    "png_name = f\"follow_time_vs_travel_distance.png\"\n",
    "sns.jointplot(data=all_evaluation, x=\"follow_ratio_this_trial\", y=\"travel_distance\", hue=\"object\",palette=palette,marginal_ticks=True)\n",
    "#sns.kdeplot(con_follow_time_arr, cut=0, color=\"b\", fill=True, alpha=0.7)\n",
    "plt.xlim(0, 1)\n",
    "plt.xticks([0, 0.5])\n",
    "plt.ylim(0,700)\n",
    "plt.yticks([0,600])\n",
    "if save_output==True:    \n",
    "    plt.savefig(svg_name)\n",
    "    plt.savefig(png_name)\n",
    "# sns.pairplot(\n",
    "#     all_evaluation,\n",
    "#     x_vars=[\"follow_ratio_this_trial\", \"travel_distance\",\"total_turning\"],\n",
    "#     y_vars=[\"follow_ratio_this_trial\", \"travel_distance\",\"total_turning\"],hue=\"object\",palette=palette,corner=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort data based on when the experiment is done\n",
    "all_evaluation['batchs'] = pd.cut(all_evaluation['animal_id'], bins=3, labels=['1st', '2nd', '3rd'])\n",
    "graph_colour_code =analysis_methods.get(\"graph_colour_code\")\n",
    "camera_fps=analysis_methods.get(\"camera_fps\")\n",
    "fig, axes = plt.subplots(\n",
    "        nrows=1, ncols=2, figsize=(9,10), tight_layout=True\n",
    "    )\n",
    "ax1, ax2 = axes.flatten()\n",
    "for keys, grp in all_evaluation.groupby(['animal_id']):\n",
    "    if grp['batchs'].values[0]=='1st':\n",
    "        this_color=graph_colour_code[0]\n",
    "    elif grp['batchs'].values[0]=='2nd':\n",
    "        this_color=graph_colour_code[1]\n",
    "    else:\n",
    "        this_color=graph_colour_code[2]\n",
    "    travel_distance=grp['travel_distance'].sum()/camera_fps\n",
    "    total_turning=grp['total_turning'].sum()/camera_fps\n",
    "    num_follow_epochs=grp['num_follow_epochs'].sum()/grp['number_frames'].sum()\n",
    "    ax1.scatter(grp['num_follow_epochs'].sum()/grp['number_frames'].sum(),grp['travel_distance'].sum()/camera_fps,c=this_color,s=8)\n",
    "    ax2.scatter(grp['num_follow_epochs'].sum()/grp['number_frames'].sum(),grp['total_turning'].sum()/camera_fps,c=this_color,s=8)\n",
    "for keys, grp in all_evaluation.groupby(['batchs']):\n",
    "    if grp['batchs'].values[0]=='1st':\n",
    "        this_color=graph_colour_code[0]\n",
    "    elif grp['batchs'].values[0]=='2nd':\n",
    "        this_color=graph_colour_code[1]\n",
    "    else:\n",
    "        this_color=graph_colour_code[2]\n",
    "    ax1.scatter(grp['num_follow_epochs'].sum()/grp['number_frames'].sum(),grp['travel_distance'].sum()/camera_fps/grp['animal_id'].unique().shape[0],edgecolors=this_color,s=20,facecolors='none')\n",
    "    ax2.scatter(grp['num_follow_epochs'].sum()/grp['number_frames'].sum(),grp['total_turning'].sum()/camera_fps/grp['animal_id'].unique().shape[0],edgecolors=this_color,s=20,facecolors='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chop the data into 3 groups depends on time. Then we can analyse the 1st, 2nd and 3rd of the data\n",
    "all_evaluation['time_group'] = pd.cut(all_evaluation['trial_id'], bins=3, labels=['1st', '2nd', '3rd'])\n",
    "num_follow_list=[]\n",
    "travel_distance_list=[]\n",
    "for keys, grp in all_evaluation.groupby(['animal_id','time_group']):\n",
    "    num_follow_list.append(grp[\"num_follow_epochs\"].sum())\n",
    "    travel_distance_list.append(grp[\"travel_distance\"].sum())\n",
    "num_follow_arr=np.array(num_follow_list).reshape(-1,3)\n",
    "travel_distance_arr=np.array(travel_distance_list).reshape(-1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(\n",
    "        nrows=1, ncols=2, figsize=(9,10), tight_layout=True\n",
    "    )\n",
    "ax1, ax2 = axes.flatten()\n",
    "ax1.plot(np.transpose(num_follow_arr), 'o-')\n",
    "ax1.plot(np.mean(num_follow_arr,axis=0),'k',linewidth=5)\n",
    "ax1.plot(np.median(num_follow_arr,axis=0),'k',linewidth=5,alpha=0.6)\n",
    "ax2.plot(np.transpose(travel_distance_arr), 'o-')\n",
    "ax2.plot(np.mean(travel_distance_arr,axis=0),'k',linewidth=5)\n",
    "ax2.plot(np.median(travel_distance_arr,axis=0),'k',linewidth=5,alpha=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 2.3: Using 1D histogram to plot proportion of time and 2D histogram to plot relative position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trials=pd.concat(relative_pos_all_animals)\n",
    "if len(simulated_relative_pos_all_animals)>0:\n",
    "    all_simulated_trials=pd.concat(simulated_relative_pos_all_animals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_follow_epoches=analysis_methods.get(\"extract_follow_epoches\",True)\n",
    "distribution_with_entire_body=analysis_methods.get(\"distribution_with_entire_body\",False)\n",
    "fig, axes = plt.subplots(nrows=1, ncols=len(all_trials[\"type\"].unique())*len(all_trials[\"degree\"].unique()),figsize=(18, 6),tight_layout=True,sharex=True, sharey=True)\n",
    "i=0\n",
    "if extract_follow_epoches:\n",
    "    xlimit=(-5,40)\n",
    "    ylimit=(-15,15)\n",
    "else:\n",
    "    xlimit=(-20,100)\n",
    "    ylimit=(-45,45)\n",
    "for keys, grp in all_trials.groupby(['type','degree']):\n",
    "        print(keys)\n",
    "        if distribution_with_entire_body:\n",
    "            body_points=generate_points_within_rectangles(grp['x'].values,grp['y'].values,1,4,2,21)\n",
    "            axes[i].hist2d(body_points[:,0],body_points[:,1],bins=1000)\n",
    "        else:\n",
    "            axes[i].hist2d(grp['x'].values,grp['y'].values,bins=400)\n",
    "        axes[i].set(\n",
    "        yticks=[ylimit[0],0,ylimit[1]],\n",
    "        xticks=[-5,0,4,20,40],\n",
    "        xlim=xlimit,ylim=ylimit,title=f'agent:{keys[0]},deg:{int(keys[1])}',adjustable='box', aspect='equal')\n",
    "        #rect = patches.Rectangle((0,-1), 6, 2, linewidth=1, edgecolor='red',linestyle=\"--\",facecolor='none')\n",
    "        #cir1 = patches.Circle((4,0), radius=0.5, linewidth=0.5, edgecolor='yellow')\n",
    "        cir2 = patches.Circle((0,0), radius=0.4, linewidth=0.4, edgecolor='red',facecolor='red')\n",
    "        #axes[i].add_patch(cir1)\n",
    "        axes[i].add_patch(cir2)\n",
    "        i=i+1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_follow_epoches=analysis_methods.get(\"extract_follow_epoches\",True)\n",
    "distribution_with_entire_body=analysis_methods.get(\"distribution_with_entire_body\",True)\n",
    "fig, axes = plt.subplots(nrows=1, ncols=len(all_trials[\"type\"].unique())*len(all_trials[\"degree\"].unique()),figsize=(18, 6),tight_layout=True,sharex=True, sharey=True)\n",
    "i=0\n",
    "if extract_follow_epoches:\n",
    "    xlimit=(-5,40)\n",
    "    ylimit=(-15,15)\n",
    "else:\n",
    "    xlimit=(-20,100)\n",
    "    ylimit=(-45,45)\n",
    "for keys, grp in all_trials.groupby('degree'):\n",
    "        print(keys)\n",
    "        if distribution_with_entire_body:\n",
    "            body_points=generate_points_within_rectangles(grp['x'].values,grp['y'].values,1,4,2,21)\n",
    "            axes[i].hist2d(body_points[:,0],body_points[:,1],bins=1000)\n",
    "        else:\n",
    "            axes[i].hist2d(grp['x'].values,grp['y'].values,bins=400)\n",
    "        axes[i].set(\n",
    "        yticks=[ylimit[0],0,ylimit[1]],\n",
    "        xticks=[-5,0,4,20,40],\n",
    "        xlim=xlimit,ylim=ylimit,title=f'deg:{int(keys)}',adjustable='box', aspect='equal')\n",
    "        #rect = patches.Rectangle((0,-1), 6, 2, linewidth=1, edgecolor='red',linestyle=\"--\",facecolor='none')\n",
    "        #cir1 = patches.Circle((4,0), radius=0.5, linewidth=0.5, edgecolor='yellow')\n",
    "        cir2 = patches.Circle((0,0), radius=0.4, linewidth=0.4, edgecolor='red',facecolor='red')\n",
    "        #axes[i].add_patch(cir1)\n",
    "        axes[i].add_patch(cir2)\n",
    "        i=i+1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=len(all_simulated_trials[\"type\"].unique())*len(all_simulated_trials[\"degree\"].unique()),figsize=(18, 6),tight_layout=True,sharex=True, sharey=True)\n",
    "i=0\n",
    "if extract_follow_epoches:\n",
    "    xlimit=(-5,40)\n",
    "    ylimit=(-15,15)\n",
    "else:\n",
    "    xlimit=(-20,100)\n",
    "    ylimit=(-45,45)\n",
    "for keys, grp in all_simulated_trials.groupby(['type','degree']):\n",
    "        if distribution_with_entire_body:\n",
    "            body_points=generate_points_within_rectangles(grp['x'].values,grp['y'].values,1,4,2,21)\n",
    "            axes[i].hist2d(body_points[:,0],body_points[:,1],bins=1000)\n",
    "        else:\n",
    "            axes[i].hist2d(grp['x'].values,grp['y'].values,bins=400)\n",
    "        axes[i].set(\n",
    "        yticks=[ylimit[0],0,ylimit[1]],\n",
    "        xticks=[-5,0,4,20,40],\n",
    "        xlim=xlimit,ylim=ylimit,title=f'agent:{keys[0]},deg:{int(keys[1])}',adjustable='box', aspect='equal')\n",
    "        #rect = patches.Rectangle((0,-1), 6, 2, linewidth=1, edgecolor='red',linestyle=\"--\",facecolor='none')\n",
    "        #cir1 = patches.Circle((4,0), radius=0.5, linewidth=0.5, edgecolor='yellow')\n",
    "        cir2 = patches.Circle((0,0), radius=0.4, linewidth=0.4, edgecolor='red',facecolor='red')\n",
    "        #axes[i].add_patch(cir1)\n",
    "        axes[i].add_patch(cir2)\n",
    "        i=i+1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##plot the distribution of follow epochs in a trial\n",
    "##In the future, will use agent based model to show the temporal distribution\n",
    "for keys, grp in all_trials.groupby(['type','degree']):\n",
    "    sim_grp=all_simulated_trials[(all_simulated_trials['type']==keys[0])&(all_simulated_trials['degree']==keys[1])]\n",
    "    print(keys)\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=1, ncols=2, figsize=(9,5), tight_layout=True\n",
    "    )\n",
    "    ax, ax2 = axes.flatten()\n",
    "    ax.hist(grp['ts'].values,bins=100,density=False,color='r')\n",
    "    ax.hist(sim_grp['ts'].values,bins=100,density=False,color='tab:gray',alpha=0.3)\n",
    "    ax2.hist(grp['ts'].values,bins=100,color='r',density=True,histtype=\"step\",cumulative=True,label=\"Cumulative histogram\")\n",
    "    ax2.hist(sim_grp['ts'].values,bins=100,color='tab:gray',alpha=0.3,density=True,histtype=\"step\",cumulative=True,label=\"Cumulative histogram\")\n",
    "    ax.set(xlim=(0,60),title=f'agent:{keys[0]},deg:{int(keys[1])}')\n",
    "    ax.set(ylim=(0,2600))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_methods.update({\"distribution_with_entire_body\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "#https://stackoverflow.com/questions/78384537/fitting-2d-histograms-with-2d-gaussians\n",
    "def twoD_Gaussian(xy, amplitude, xo, yo, sigma_x, sigma_y, rho):\n",
    "    x, y = xy\n",
    "    xo = float(xo)\n",
    "    yo = float(yo)\n",
    "    a = 1 / sigma_x ** 2\n",
    "    b = rho / sigma_x / sigma_y\n",
    "    c = 1 / sigma_y ** 2\n",
    "    exponent=  - (1 / (2 * (1 - rho ** 2)))\\\n",
    "                 * (a * (x - xo) ** 2 - 2 * b * (x - xo) * (y - yo) + c * (y - yo) ** 2)\n",
    "    g = amplitude * np.exp(exponent)\n",
    "    return g.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbr_bins = 100\n",
    "B, xedges, yedges = np.histogram2d(grp['x'].values,grp['y'].values, bins=nbr_bins)\n",
    "extent = [xedges[0], xedges[-1], yedges[0], yedges[-1]]\n",
    "bin_centers_bx = (xedges[:-1] + xedges[1:]) / 2.0\n",
    "bin_centers_by = (yedges[:-1] + yedges[1:]) / 2.0\n",
    "X, Y = np.meshgrid(bin_centers_bx, bin_centers_by)\n",
    "data = B.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [0, 4]\n",
    "p0 = (B.max(),mean[0],mean[1],1.7,1.0,0.9)\n",
    "coeff, var_matrix = curve_fit(twoD_Gaussian, (X, Y), data, p0=p0)\n",
    "print('hist fit', coeff)\n",
    "print('var_matrix', var_matrix)\n",
    "data_fitted_hist = twoD_Gaussian((X, Y), *coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "xlimit=(-30,30)\n",
    "ylimit=(-30,30)\n",
    "ax[0].imshow(data.reshape((nbr_bins, nbr_bins)), origin=\"lower\",\n",
    "             extent=extent, interpolation=\"none\")\n",
    "ax[1].imshow(data.reshape((nbr_bins, nbr_bins)), origin=\"lower\",\n",
    "             extent=extent, interpolation=\"none\")\n",
    "ax[1].contour(X, Y, data_fitted_hist.reshape(nbr_bins, nbr_bins), 2, colors=\"w\",linestyles='dashed',linewidths=0.5)\n",
    "ax[0].set(\n",
    "        yticks=[-30,0.0,30],\n",
    "        xticks=[-30,0.0,30],\n",
    "        xlim=xlimit,ylim=ylimit)\n",
    "ax[1].set(\n",
    "        yticks=[-30,0.0,30],\n",
    "        xticks=[-30,0.0,30],\n",
    "        xlim=xlimit,ylim=ylimit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##plot the spatial distribution of virtual locusts in a 2D histogram\n",
    "\n",
    "distribution_with_entire_body=analysis_methods.get(\"distribution_with_entire_body\",True)\n",
    "xlimit=(-30,30)\n",
    "ylimit=(-30,30)\n",
    "for keys, grp in all_trials.groupby(['type']):\n",
    "    fig, ax = plt.subplots(dpi=300, figsize=(2,2))\n",
    "    if distribution_with_entire_body:\n",
    "        body_points=generate_points_within_rectangles(grp['x'].values,grp['y'].values,1,4,2,21)\n",
    "        ax.hist2d(body_points[:,0],body_points[:,1],bins=1000)\n",
    "    else:\n",
    "        ax.hist2d(grp['x'].values,grp['y'].values,bins=100)\n",
    "    ax.set(adjustable='box', aspect='equal')\n",
    "    ax.set(\n",
    "        yticks=[-30,0.0,30],\n",
    "        xticks=[-30,0.0,30],\n",
    "        xticklabels=(['-0.3', '0.0', '0.3']),\n",
    "        yticklabels=(['-0.3', '0.0', '0.3']),\n",
    "        xlim=xlimit,ylim=ylimit,title=f'agent:{keys[0]}')\n",
    "    '''\n",
    "    the position of virtual locust if their butt is at the origin\n",
    "    rect = patches.Rectangle((0,-1), 6, 2, linewidth=1, edgecolor='red',linestyle=\"--\",facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "    '''\n",
    "    cir = patches.Circle((0,0), radius=0.5, linewidth=0.5, edgecolor='red')\n",
    "    ax.add_patch(cir)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 2.4: Plot temporal distribution of follow epoch throughout the trial course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##plot the temporal distribution of follow epochs in a trial\n",
    "for keys, grp in all_trials.groupby(['type']):\n",
    "    print(keys)\n",
    "    sim_grp=all_simulated_trials[all_simulated_trials['type']==keys[0]]\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=1, ncols=2, figsize=(9,5), tight_layout=True\n",
    "    )\n",
    "    ax, ax2 = axes.flatten()\n",
    "    ax.hist(grp['ts'].values,bins=100,density=False,color='r')\n",
    "    ax.hist(sim_grp['ts'].values,bins=100,density=False,color='tab:gray',alpha=0.5)\n",
    "    ax2.hist(grp['ts'].values,bins=100,density=True,color='r',histtype=\"step\",cumulative=True,label=\"Cumulative histogram\")\n",
    "    ax2.hist(sim_grp['ts'].values,bins=100,color='tab:gray',alpha=0.5,density=True,histtype=\"step\",cumulative=True,label=\"Cumulative histogram\")\n",
    "    ax.set(xlim=(0,60))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 2.5: estimation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell is for dabest analysis. However, it is not good for experiment design with multiple trials\n",
    "# import dabest\n",
    "# con_follow_time_arr=np.hstack(con_follow_time_list)\n",
    "# exp_follow_time_arr=np.hstack(exp_follow_time_list)\n",
    "# dabest_pd = pd.DataFrame({\"Control\": con_follow_time_arr, \"Test\": exp_follow_time_arr})\n",
    "# two_groups_unpaired = dabest.load(dabest_pd, idx=(\"Control\", \"Test\"))\n",
    "# two_groups_unpaired.mean_diff.plot()\n",
    "''' a format that seperates trials and animals. Rows are animals and columns are trials\n",
    "c_name_list=column_name_list(con_follow_time_list[0].shape[0],'con')\n",
    "tmp = pd.DataFrame(con_follow_time_list,columns=c_name_list)\n",
    "c_name_list=column_name_list(exp_follow_time_list[0].shape[0],'exp')\n",
    "tmp2 = pd.DataFrame(exp_follow_time_list,columns=c_name_list)\n",
    "df_combined=pd.concat([tmp.reset_index(drop=True), tmp2.reset_index(drop=True)], axis=1)\n",
    "df_combined=df_combined.reset_index(names='ID')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 2.6: Exporting dataset into Mat or csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##save the raw data into mat file for matlab\n",
    "from scipy.io import savemat\n",
    "all_raw=pd.concat(relative_pos_all_animals)\n",
    "#all_raw['trial_id']=all_raw['trial_id'].astype(int)\n",
    "data_dict = {name: col.values for name, col in all_raw.items()}\n",
    "summary_file_name = Path(thisDataset) /\"time_series_curated.mat\"\n",
    "savemat(summary_file_name, data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## A helper function to export the data into csv file\n",
    "def summarise_as_csv(input_list,agent_type='glocust'):\n",
    "    df=pd.DataFrame(np.hstack(input_list))\n",
    "    df.insert(0, 'agent_type', np.repeat(agent_type,df.shape[0]).tolist())\n",
    "    df.insert(0, 'ID', np.repeat(np.arange(len(input_list)),int(df.shape[0]/len(input_list))).tolist())\n",
    "    df.to_csv(f'{agent_type}.csv')\n",
    "def summarise_as_csv2(list1,list2,type1='gregarious_locust',type2='black_locust'):\n",
    "    df=pd.DataFrame({\"ratio\":np.concat([np.hstack(list1),np.hstack(list2)])})\n",
    "    df.insert(0, 'agent_type', np.concat((np.repeat(type1,len(list1)*list1[0].shape[0]),np.repeat(type2,len(list2)*list2[0].shape[0]))).tolist())\n",
    "    df.insert(0, 'times',np.repeat(np.tile(np.arange(exp_follow_time_list[0].shape[0]),len(exp_follow_time_list)),2).tolist())\n",
    "    df.insert(0, 'ID', np.repeat(np.repeat(np.arange(len(exp_follow_time_list)),exp_follow_time_list[0].shape[0]),2).tolist())\n",
    "    df.to_csv(f'{type1}_vs_{type2}_repeated_measure.csv')\n",
    "#summarise_as_csv(exp_follow_time_list,'exp_agent')\n",
    "#summarise_as_csv(con_follow_time_list)\n",
    "summarise_as_csv2(con_follow_time_list,exp_follow_time_list,'con','exp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3.0: analysis walking behavours before and after the presence of stimulus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Session 3.1: combine list together and check their distribution to look for a threshold that separate stationary and behavioural states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if type(raster_across_animals_unity)==list:\n",
    "    all_trials=pd.concat(raster_across_animals_unity)\n",
    "    all_trials=fix_data_type(all_trials)\n",
    "else:\n",
    "    all_trials=fix_data_type(raster_across_animals_unity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_name='omega'\n",
    "check_baseline_distribution(all_trials,analysis_methods,metrics_name,3)\n",
    "# check_baseline_distribution(all_trials,analysis_methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Session 3.2: split trials based on stationary and moving state and retrieve their index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for simplicity, classifying trial only based on stationary and walk trails\n",
    "classify_trials=False\n",
    "trial_classfier='velocity'#'velocity' or 'omega'\n",
    "metrics_name='omega'#'velocity' or 'omega'\n",
    "_,these_metrics,these_normalised_metrics=split_trials(analysis_methods,all_trials,metrics_name,'normalised_omega',1)#1 degree or 0.0002 rad\n",
    "if classify_trials:\n",
    "    movement_trial_boolean,_,_=split_trials(analysis_methods,all_trials,trial_classfier)\n",
    "else:\n",
    "    movement_trial_boolean=[True]*len(these_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#movement_trial_boolean,these_metrics,these_normalised_metrics=split_trials(analysis_methods,all_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "after_movement_ith_trial,after_no_movement_ith_trial=extract_trial_index(movement_trial_boolean,len(all_trials['animal_id'].unique()),analysis_methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Session 3.3: select animals or trial of interest (related to follow response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##criteria to sort out data from good followers\n",
    "# fair_follower_threshold=0.20\n",
    "#fair_follower_threshold=0.1667\n",
    "# good_follower_threshold=0.3\n",
    "#data from grass1 secene\n",
    "# first 1/3 best of followers: 0.04542389707280022\n",
    "# middle 1/3 best of followers: 0.024365961537554066\n",
    "def select_animal_or_trial_to_analyse(all_evaluation,use_aba_threshold,based_on_follow_walk_ratio,threshold_value=0.25):\n",
    "    if based_on_follow_walk_ratio:\n",
    "        denominator='num_walk_epochs'\n",
    "    else:\n",
    "        denominator='number_frames'\n",
    "    if use_aba_threshold==True:\n",
    "        p_follow=all_evaluation.groupby(['animal_id'])['num_follow_epochs'].sum()/all_evaluation.groupby(['animal_id'])[denominator].sum()\n",
    "        #follower_of_interest=(p_follow>fair_follower_threshold) & (p_follow<good_follower_threshold)\n",
    "        #data_of_interest=p_follow>0.14 ### this data of interest means subjects of interest\n",
    "        data_of_interest=p_follow>threshold_value\n",
    "        #rows_of_follower=follower_of_interest.repeat(int(all_evaluation.shape[0]/follower_of_interest.shape[0]))\n",
    "    else:\n",
    "        data_of_interest=all_evaluation['num_follow_epochs']/all_evaluation[denominator]>threshold_value\n",
    "        #data_of_interest=(all_evaluation['num_follow_epochs']/all_evaluation[denominator]<threshold_value)&(all_evaluation['num_follow_epochs']/all_evaluation[denominator]>0.1)\n",
    "    return data_of_interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_aba_threshold=True\n",
    "based_on_follow_walk_ratio=True\n",
    "data_of_interest=select_animal_or_trial_to_analyse(all_evaluation,use_aba_threshold,based_on_follow_walk_ratio,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_of_interest=select_animal_or_trial_to_analyse(all_evaluation[all_evaluation['speed']==2],use_aba_threshold,based_on_follow_walk_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##these vars are for the experiment \"sta_black_locust_2dir_3_initial_position\"\n",
    "#var1='radial_distance'\n",
    "#var2='mu'\n",
    "##these vars are for the experiment \"closed_loop_sta_black_locust_open_loop_sta_black_locust\"\n",
    "var1='speed'\n",
    "var2='mu'\n",
    "##this is for the experiment \"choice_vr_locust_sta_black_locust\"\n",
    "# if all_evaluation['object'].unique().shape[0]>1:\n",
    "# var1='object'\n",
    "# var2='mu'\n",
    "var1='mu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Session 3.4: plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for type_key in all_evaluation[var1].unique():\n",
    "    print(type_key)\n",
    "    if use_aba_threshold==True:\n",
    "        rows_of_follower=data_of_interest.repeat(int(all_evaluation.shape[0]/data_of_interest.shape[0]))\n",
    "    if \"var2\" in locals():\n",
    "        for this_condition in all_evaluation[var2].unique():\n",
    "            print(this_condition)\n",
    "            if use_aba_threshold==True:\n",
    "                row_of_interest=(all_evaluation[var2].reset_index(drop=True)==this_condition)&(all_evaluation[var1].reset_index(drop=True)==type_key)&(rows_of_follower.reset_index(drop=True))\n",
    "            else:\n",
    "                row_of_interest=(all_evaluation[var2].reset_index(drop=True)==this_condition)&(all_evaluation[var1].reset_index(drop=True)==type_key)&(data_of_interest.reset_index(drop=True))\n",
    "            plot_visual_evoked_behaviour(these_metrics,these_normalised_metrics,after_movement_ith_trial,after_no_movement_ith_trial,analysis_methods,metrics_name,row_of_interest,type_key,this_condition)\n",
    "    else:\n",
    "        if use_aba_threshold==True:\n",
    "            row_of_interest=(all_evaluation[var1].reset_index(drop=True)==type_key)&rows_of_follower.reset_index(drop=True)\n",
    "        else:\n",
    "            row_of_interest=(all_evaluation[var1].reset_index(drop=True)==type_key)&(data_of_interest.reset_index(drop=True))\n",
    "        plot_visual_evoked_behaviour(these_metrics,these_normalised_metrics,after_movement_ith_trial,after_no_movement_ith_trial,analysis_methods,metrics_name,row_of_interest,type_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for type_key in all_evaluation[var1].unique():\n",
    "    print(type_key)\n",
    "    if use_aba_threshold==True:\n",
    "        rows_of_follower=data_of_interest.repeat(int(all_evaluation.shape[0]/data_of_interest.shape[0]))\n",
    "    for this_condition in all_evaluation[var2].unique():\n",
    "        print(this_condition)\n",
    "        if use_aba_threshold==True:\n",
    "            row_of_interest=(all_evaluation[var2].reset_index(drop=True)==this_condition)&(all_evaluation[var1].reset_index(drop=True)==type_key)&(rows_of_follower.reset_index(drop=True))\n",
    "        else:\n",
    "            row_of_interest=(all_evaluation[var2].reset_index(drop=True)==this_condition)&(all_evaluation[var1].reset_index(drop=True)==type_key)&(data_of_interest.reset_index(drop=True))\n",
    "        plot_visual_evoked_behaviour(these_metrics,these_normalised_metrics,after_movement_ith_trial,after_no_movement_ith_trial,analysis_methods,metrics_name,row_of_interest,type_key,this_condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for simplicity, classifying trial only based on stationary and walk trails\n",
    "classify_trials=True\n",
    "trial_classfier='velocity'#'velocity' or 'omega'\n",
    "metrics_name='velocity'#'velocity' or 'omega'\n",
    "_,these_metrics,these_normalised_metrics=split_trials(analysis_methods,all_trials)\n",
    "if classify_trials:\n",
    "    movement_trial_boolean,_,_=split_trials(analysis_methods,all_trials,trial_classfier)\n",
    "else:\n",
    "    movement_trial_boolean=[True]*len(these_metrics)\n",
    "after_movement_ith_trial,after_no_movement_ith_trial=extract_trial_index(movement_trial_boolean,len(all_trials['animal_id'].unique()),analysis_methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_name='velocity'\n",
    "for type_key in all_evaluation[var1].unique():\n",
    "    print(type_key)\n",
    "    if use_aba_threshold==True:\n",
    "        rows_of_follower=data_of_interest.repeat(int(all_evaluation.shape[0]/data_of_interest.shape[0]))\n",
    "    for this_condition in all_evaluation[var2].unique():\n",
    "        print(this_condition)\n",
    "        if use_aba_threshold==True:\n",
    "            row_of_interest=(all_evaluation[var2].reset_index(drop=True)==this_condition)&(all_evaluation[var1].reset_index(drop=True)==type_key)&(rows_of_follower.reset_index(drop=True))\n",
    "        else:\n",
    "            row_of_interest=(all_evaluation[var2].reset_index(drop=True)==this_condition)&(all_evaluation[var1].reset_index(drop=True)==type_key)&(data_of_interest.reset_index(drop=True))\n",
    "        plot_visual_evoked_behaviour(these_metrics,these_normalised_metrics,after_movement_ith_trial,after_no_movement_ith_trial,analysis_methods,metrics_name,row_of_interest,type_key,this_condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_name='velocity'\n",
    "for type_key in all_evaluation[var1].unique():\n",
    "    print(type_key)\n",
    "    if use_aba_threshold==True:\n",
    "        rows_of_follower=data_of_interest.repeat(int(all_evaluation.shape[0]/data_of_interest.shape[0]))\n",
    "        row_of_interest=(all_evaluation[var1].reset_index(drop=True)==type_key)&rows_of_follower.reset_index(drop=True)\n",
    "    else:\n",
    "        row_of_interest=(all_evaluation[var1].reset_index(drop=True)==type_key)&(data_of_interest.reset_index(drop=True))\n",
    "    plot_visual_evoked_behaviour(these_metrics,these_normalised_metrics,after_movement_ith_trial,after_no_movement_ith_trial,analysis_methods,'velocity',row_of_interest,type_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session 4: New codes to analysis data for raster plot. These functions take data from fictrac directly so can analyse what happened before the stimulus onset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Session 4.0: summarise fictrac data with sequence config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_methods.update({\"analysis_window\":[-25,25]})\n",
    "var1='mu'\n",
    "var2=None\n",
    "step_interest=np.arange(1, seq_config_all_animals[0].shape[0], 2)\n",
    "export_to_matlab_list=[]\n",
    "step_interest=np.arange(1, seq_config_all_animals[0].shape[0], 2)\n",
    "## to avoid memory crushed, analyse each animal one by one. In this case we need to comment out the line 85-88 in sorting time series analysis\n",
    "for animal_interest in range(len(seq_config_all_animals)):\n",
    "    ready_to_plot=sort_raster_fictrac(raster_across_animals_fictrac,[animal_interest],step_interest,analysis_methods,all_evaluation,var1,var2)\n",
    "    export_to_matlab_list.append(ready_to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## export the data into matlab format\n",
    "from scipy.io import savemat\n",
    "all_raw=pd.concat(export_to_matlab_list)\n",
    "all_raw.drop(['run_trial', 'index'], axis=1,inplace=True)\n",
    "data_dict = {name: col.values for name, col in all_raw.items()}\n",
    "summary_file_name = Path(thisDataset) /\"time_series_curated.mat\"\n",
    "savemat(summary_file_name, data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Session 4.1: select a time window for the analysis and pick whether to choose animal of interest or trial of interest (related to follow behaviours) for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##this can select follower of interest\n",
    "use_aba_threshold=True\n",
    "threshold=0.045\n",
    "based_on_follow_walk_ratio=False\n",
    "if based_on_follow_walk_ratio:\n",
    "    denominator='num_walk_epochs'\n",
    "else:\n",
    "    denominator='number_frames'\n",
    "if \"all_evaluation\" in locals():\n",
    "    pass\n",
    "else:\n",
    "    print('For some response, this boolean overwrite the existing all_evaluation')\n",
    "    # all_evaluation=pd.concat(seq_config_all_animals)\n",
    "if \"configFile\" in all_evaluation.columns:\n",
    "    animal_interest=np.arange(len(seq_config_all_animals))\n",
    "    step_interest=np.arange(1, seq_config_all_animals[0].shape[0], 2)\n",
    "else:\n",
    "    if use_aba_threshold:\n",
    "        all_evaluation_aba = all_evaluation.groupby('animal_id').agg(\n",
    "            travel_distance_ISI=('travel_distance_ISI', 'sum'),\n",
    "            gross_turning_ISI=('gross_turning_ISI', 'sum'),\n",
    "            total_turning_ISI=('total_turning_ISI', 'sum'),\n",
    "            num_follow_epochs=('num_follow_epochs', 'sum'),\n",
    "            num_walk_epochs=('num_walk_epochs', 'sum'),\n",
    "            number_frames=('number_frames','sum'),\n",
    "            vr_no=('VR', 'first'),\n",
    "        )\n",
    "        animal_interest=all_evaluation_aba[all_evaluation_aba['num_follow_epochs']/all_evaluation_aba[denominator]>threshold].index\n",
    "        step_interest=np.arange(1, 2*len(all_evaluation['trial_id'].unique()), 2)\n",
    "    else:\n",
    "        ##this can select follow trials of interest and convert that into step_id\n",
    "        animal_interest=all_evaluation[all_evaluation['num_follow_epochs']/all_evaluation[denominator]>threshold]['animal_id']\n",
    "        step_interest=all_evaluation[all_evaluation['num_follow_epochs']/all_evaluation[denominator]>threshold]['trial_id']*2+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=sns.jointplot(data=all_evaluation_aba, x=\"travel_distance_ISI\", y=\"gross_turning_ISI\", hue=\"vr_no\")\n",
    "## add an additional marginal plot to show the distribution of the data\n",
    "a.plot_marginals(sns.rugplot, height=0.15, clip_on=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Session 4.2: create a pandas dataframe based on the time window, animal or trial of interest. The dataframe includes instead speed and angular velocity frame by frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# var1='configFile'\n",
    "# var2=None\n",
    "var1='mu'\n",
    "var2='object'\n",
    "#this_summary_table=pd.concat(seq_config_all_animals)\n",
    "this_summary_table=all_evaluation\n",
    "analysis_methods.update({\"analysis_window\":[-2,5]})\n",
    "analysis_window=analysis_methods.get(\"analysis_window\")\n",
    "monitor_fps=analysis_methods.get(\"monitor_fps\")\n",
    "n_datapoints=(analysis_window[1]-analysis_window[0])*monitor_fps\n",
    "ready_to_plot=sort_raster_fictrac(raster_across_animals_fictrac,animal_interest,step_interest,analysis_methods,this_summary_table,var1,var2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Session 4.3: plot the results. Using seaborn line plots for average response, customised codes for trial by trial responses. Note: there is not yet to use circular statistics on seaborn-related plots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.set_theme(style=\"darkgrid\")\n",
    "# Plot the responses for different events and regions\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=1, ncols=2, figsize=(9,5), tight_layout=True\n",
    ")\n",
    "i=0\n",
    "for keys, this_data in ready_to_plot.groupby(['run_trial']):\n",
    "    print(keys)\n",
    "    sns.lineplot(x=\"frame_count\", y=\"instant_speed\",hue=var1,data=this_data,ax=axes[i])\n",
    "    #axes[i].set_ylim([0,10])\n",
    "    axes[i].set(\n",
    "        xlabel=\"Time (s)\",\n",
    "        xticks=[0,abs(analysis_window[0]*monitor_fps)-1,n_datapoints-1],\n",
    "        xticklabels=([str(analysis_window[0]),'0', str(analysis_window[1])]),\n",
    "    )\n",
    "    # sns.move_legend(\n",
    "    #     axes[i], \"lower center\",\n",
    "    #     bbox_to_anchor=(.5, 1), ncol=3, title=None, frameon=False,\n",
    "    # )\n",
    "    i=i+1\n",
    "# fig_name = f\"constant_speed_constand_distance_speed1.jpg\"\n",
    "# fig.savefig(fig_name)\n",
    "# fig_name = f\"constant_speed_constand_distance_speed1.svg\"\n",
    "# fig.savefig(fig_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(\n",
    "    nrows=1, ncols=2, figsize=(9,5), tight_layout=True\n",
    ")\n",
    "i=0\n",
    "for keys, this_data in ready_to_plot.groupby(['run_trial']):\n",
    "    print(keys)\n",
    "    #arg=lambda x: (x.min(), x.max())\n",
    "    sns.lineplot(x=\"frame_count\",\n",
    "                y=\"heading\",\n",
    "                #y='instant_angular_velocity',\n",
    "                hue=var1,estimator='median',\n",
    "                #errorbar=arg,\n",
    "                data=this_data,ax=axes[i])\n",
    "    axes[i].set(\n",
    "        xlabel=\"Time (s)\",\n",
    "        xticks=[0,abs(analysis_window[0]*monitor_fps)-1,n_datapoints-1],\n",
    "        xticklabels=([str(analysis_window[0]),'0', str(analysis_window[1])]),\n",
    "        # xticklabels=([str(-1),'0', str(2)]),\n",
    "        # xlim=[1*monitor_fps,4*monitor_fps],\n",
    "        # ylim=[-10,10]\n",
    "    )\n",
    "    sns.move_legend(\n",
    "        axes[i], \"upper left\", bbox_to_anchor=(1, 1)\n",
    "    )\n",
    "    i=i+1\n",
    "# fig_name = f\"constant_speed_constand_distance_angular_velocity1.jpg\"\n",
    "# fig.savefig(fig_name)\n",
    "# fig_name = f\"constant_speed_constand_distance_angular_velocity1.svg\"\n",
    "# fig.savefig(fig_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(\n",
    "    nrows=2, ncols=1, figsize=(9,12), tight_layout=True\n",
    ")\n",
    "i=0\n",
    "for keys, this_data in ready_to_plot.groupby(['run_trial']):\n",
    "    print(keys)\n",
    "    #p1=np.reshape(this_data['instant_speed'].to_numpy(),(n_datapoints,-1))\n",
    "    p1=np.reshape(this_data['instant_speed'].to_numpy(),(-1,n_datapoints))\n",
    "    axes[i].plot(np.transpose(p1),linewidth=0.1)\n",
    "    mean_p1=np.nanmean(p1,axis=0)\n",
    "    axes[i].plot(mean_p1,'k',linewidth=1)\n",
    "    dif_y1,dif_y2=get_fill_between_range(p1,True,False)\n",
    "    \n",
    "    axes[i].fill_between(np.arange(n_datapoints),dif_y1,dif_y2, alpha=0.4,color='k')\n",
    "    axes[i].set_ylim([0,10])\n",
    "    axes[i].set(\n",
    "        xlabel=\"Time (s)\",\n",
    "        xticks=[0,abs(analysis_window[0]*monitor_fps)-1,n_datapoints-1],\n",
    "        xticklabels=([str(analysis_window[0]),'0', str(analysis_window[1])]),\n",
    "    )\n",
    "    i=i+1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(\n",
    "    nrows=6, ncols=1, figsize=(9,18), tight_layout=True\n",
    ")\n",
    "i=0\n",
    "for keys, this_data in ready_to_plot.groupby([var1]):\n",
    "    print(keys)\n",
    "    #p1=np.reshape(this_data['instant_speed'].to_numpy(),(n_datapoints,-1))\n",
    "    p1=np.reshape(this_data['heading'].to_numpy(),(-1,n_datapoints))\n",
    "\n",
    "    axes[i].plot(np.transpose(p1),linewidth=0.1)\n",
    "    #mean_p1=np.median(p1,axis=0)\n",
    "    mean_p1=circmean(p1,high=180,low=-180,axis=0)\n",
    "    axes[i].plot(mean_p1,'k',linewidth=1)\n",
    "    dif_y1,dif_y2=get_fill_between_range(p1,False,True)\n",
    "    axes[i].fill_between(np.arange(n_datapoints),dif_y1,dif_y2, alpha=0.4,color='k')\n",
    "    axes[i].set_ylim([-10,10])\n",
    "    axes[i].set(\n",
    "        xlabel=\"Time (s)\",\n",
    "        xticks=[0,abs(analysis_window[0]*monitor_fps)-1,n_datapoints-1],\n",
    "        xticklabels=([str(analysis_window[0]),'0', str(analysis_window[1])]),\n",
    "    )\n",
    "    i=i+1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session 5: analyse time-series response with locustvr database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Session 5.0: introduce the function to sort the data into columns within time windows"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T14:12:35.789833Z",
     "start_time": "2025-07-01T14:12:35.756806Z"
    }
   },
   "source": [
    "def sort_raster_locustvr(focal_animal_file,summary_file,analysis_methods,count):\n",
    "    analysis_window=analysis_methods.get(\"analysis_window\")\n",
    "    camera_fps=analysis_methods.get(\"camera_fps\")\n",
    "    df_focal_animal = pd.read_hdf(focal_animal_file)\n",
    "    df_summary = pd.read_hdf(summary_file)\n",
    "    column_list = [\"labels\", \"elapsed_time\", \"instant_speed\", \"instant_angular_velocity\"]\n",
    "    X=df_focal_animal[\"X\"].to_numpy()\n",
    "    Y=df_focal_animal[\"Y\"].to_numpy()\n",
    "    #trial_id=df_focal_animal[\"trial_id\"].to_numpy()\n",
    "    state_type=df_focal_animal[\"state_type\"].to_numpy()\n",
    "    elapsed_time=df_focal_animal[\"ts\"].to_numpy()\n",
    "    #df_focal_animal[\"heading\"].to_csv(\"heading_angle.csv\", header=False, index=False)\n",
    "    rot_y=df_focal_animal[\"heading\"].to_numpy()\n",
    "    rot_y = interp_fill(rot_y)\n",
    "    unwrapped_rad = np.unwrap(rot_y)\n",
    "    ## chatGPT suggested to use \n",
    "    # degree_array = np.degrees(unwrapped_rad)\n",
    "    # instant_angular_velocity = np.gradient(degree_array, 0.01) \n",
    "    # filtered_velocity = medfilt(instant_angular_velocity, kernel_size=5)\n",
    "    # smoothed_velocity=gaussian_filter1d(filtered_velocity, sigma=2)\n",
    "    # but not sure\n",
    "    rad_diff = np.diff(unwrapped_rad)\n",
    "    instant_angular_velocity = rad_diff*camera_fps\n",
    "    filtered_delta_theta = medfilt(instant_angular_velocity, kernel_size=5)\n",
    "    delta_degrees = (180/np.pi) * filtered_delta_theta\n",
    "    # fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10,5), tight_layout=True)\n",
    "    # ax1, ax2= axes.flatten()\n",
    "    # ax1.plot(filtered_delta_theta)\n",
    "    # #ax1.hist(filtered_delta_theta,bins=10000)\n",
    "    # ax2.plot(delta_degrees)\n",
    "    # #ax2.hist(delta_degrees,bins=10000)\n",
    "    # trajec_lim=360\n",
    "    # ax1.set(ylim=(-1 * trajec_lim, trajec_lim))\n",
    "    # ax2.set(ylim=(-1 * trajec_lim, trajec_lim))\n",
    "    instant_speed = calculate_speed(np.diff(X),np.diff(Y),elapsed_time,0)\n",
    "    start_idx=np.where(np.diff(state_type)>0)[0]+analysis_window[0]*camera_fps\n",
    "    start_big=np.repeat(start_idx,(analysis_window[1]-analysis_window[0])*camera_fps)\n",
    "    pts_tile=np.tile(np.arange((analysis_window[1]-analysis_window[0])*camera_fps),start_idx.shape[0])\n",
    "    label_tiles=np.repeat(df_summary['trial_label'].values,(analysis_window[1]-analysis_window[0])*camera_fps)\n",
    "    tmp = np.vstack(\n",
    "    (\n",
    "        label_tiles,\n",
    "        elapsed_time[start_big+pts_tile],\n",
    "        instant_speed[start_big+pts_tile],\n",
    "        #delta_degrees[start_big+pts_tile]\n",
    "        instant_angular_velocity[start_big+pts_tile]\n",
    "    ))\n",
    "    dynamics_pd = pd.DataFrame(np.transpose(tmp))\n",
    "    dynamics_pd.columns=column_list\n",
    "    dynamics_pd.insert(0, 'frame_count', pts_tile)\n",
    "    dynamics_pd.insert(0, 'animal_id',count)\n",
    "    return dynamics_pd"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Session 5.1: load data from locustvr database"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T14:12:42.260558Z",
     "start_time": "2025-07-01T14:12:42.223818Z"
    }
   },
   "source": [
    "time_series_analysis = analysis_methods.get(\"time_series_analysis\")\n",
    "analysis_methods.update({\"analysis_window\":[-2,5]})\n",
    "file_suffix = \"_full\" if time_series_analysis else \"\"\n",
    "agent_pattern = f\"agent{file_suffix}.h5\"\n",
    "xy_pattern = f\"XY{file_suffix}.h5\"\n",
    "summary_pattern = f\"summary{file_suffix}.h5\"\n",
    "pd_list=[]\n",
    "for index, this_dir in enumerate(dir_list):\n",
    "    agent_file = find_file(Path(this_dir), agent_pattern)\n",
    "    focal_animal_file = find_file(Path(this_dir), xy_pattern)\n",
    "    summary_file = find_file(Path(this_dir), summary_pattern)\n",
    "    this_pd=sort_raster_locustvr(focal_animal_file,summary_file,analysis_methods,index)\n",
    "    pd_list.append(this_pd)"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T14:12:45.343106Z",
     "start_time": "2025-07-01T14:12:45.276045Z"
    }
   },
   "source": [
    "ready_to_plot=pd.concat(pd_list,ignore_index=True)"
   ],
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[14]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m ready_to_plot=\u001B[43mpd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mconcat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpd_list\u001B[49m\u001B[43m,\u001B[49m\u001B[43mignore_index\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniforge3/envs/unity_analysis/lib/python3.11/site-packages/pandas/core/reshape/concat.py:382\u001B[39m, in \u001B[36mconcat\u001B[39m\u001B[34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001B[39m\n\u001B[32m    379\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m copy \u001B[38;5;129;01mand\u001B[39;00m using_copy_on_write():\n\u001B[32m    380\u001B[39m     copy = \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m382\u001B[39m op = \u001B[43m_Concatenator\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    383\u001B[39m \u001B[43m    \u001B[49m\u001B[43mobjs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    384\u001B[39m \u001B[43m    \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m=\u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    385\u001B[39m \u001B[43m    \u001B[49m\u001B[43mignore_index\u001B[49m\u001B[43m=\u001B[49m\u001B[43mignore_index\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    386\u001B[39m \u001B[43m    \u001B[49m\u001B[43mjoin\u001B[49m\u001B[43m=\u001B[49m\u001B[43mjoin\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    387\u001B[39m \u001B[43m    \u001B[49m\u001B[43mkeys\u001B[49m\u001B[43m=\u001B[49m\u001B[43mkeys\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    388\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlevels\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlevels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    389\u001B[39m \u001B[43m    \u001B[49m\u001B[43mnames\u001B[49m\u001B[43m=\u001B[49m\u001B[43mnames\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    390\u001B[39m \u001B[43m    \u001B[49m\u001B[43mverify_integrity\u001B[49m\u001B[43m=\u001B[49m\u001B[43mverify_integrity\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    391\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcopy\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    392\u001B[39m \u001B[43m    \u001B[49m\u001B[43msort\u001B[49m\u001B[43m=\u001B[49m\u001B[43msort\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    393\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    395\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m op.get_result()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniforge3/envs/unity_analysis/lib/python3.11/site-packages/pandas/core/reshape/concat.py:445\u001B[39m, in \u001B[36m_Concatenator.__init__\u001B[39m\u001B[34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001B[39m\n\u001B[32m    442\u001B[39m \u001B[38;5;28mself\u001B[39m.verify_integrity = verify_integrity\n\u001B[32m    443\u001B[39m \u001B[38;5;28mself\u001B[39m.copy = copy\n\u001B[32m--> \u001B[39m\u001B[32m445\u001B[39m objs, keys = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_clean_keys_and_objs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobjs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeys\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    447\u001B[39m \u001B[38;5;66;03m# figure out what our result ndim is going to be\u001B[39;00m\n\u001B[32m    448\u001B[39m ndims = \u001B[38;5;28mself\u001B[39m._get_ndims(objs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniforge3/envs/unity_analysis/lib/python3.11/site-packages/pandas/core/reshape/concat.py:507\u001B[39m, in \u001B[36m_Concatenator._clean_keys_and_objs\u001B[39m\u001B[34m(self, objs, keys)\u001B[39m\n\u001B[32m    504\u001B[39m     objs_list = \u001B[38;5;28mlist\u001B[39m(objs)\n\u001B[32m    506\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(objs_list) == \u001B[32m0\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m507\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mNo objects to concatenate\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    509\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m keys \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    510\u001B[39m     objs_list = \u001B[38;5;28mlist\u001B[39m(com.not_none(*objs_list))\n",
      "\u001B[31mValueError\u001B[39m: No objects to concatenate"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T14:13:09.352449Z",
     "start_time": "2025-07-01T14:13:09.302891Z"
    }
   },
   "source": [
    "ready_to_plot"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ready_to_plot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[15]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mready_to_plot\u001B[49m\n",
      "\u001B[31mNameError\u001B[39m: name 'ready_to_plot' is not defined"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Session 5.2: plot the result with seaborn library"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T14:13:25.354566Z",
     "start_time": "2025-07-01T14:13:25.100602Z"
    }
   },
   "source": [
    "monitor_fps=analysis_methods.get(\"monitor_fps\")\n",
    "analysis_window=analysis_methods.get(\"analysis_window\")\n",
    "n_datapoints=(analysis_window[1]-analysis_window[0])*monitor_fps\n",
    "fig, (ax1,ax2) = plt.subplots(\n",
    "    nrows=2, ncols=1, figsize=(9,5), tight_layout=True\n",
    ")\n",
    "\n",
    "sns.lineplot(x=\"frame_count\", y=\"instant_angular_velocity\",hue=\"labels\",data=ready_to_plot,ax=ax1)\n",
    "ylimit=5\n",
    "ax1.set(\n",
    "    ylim=(-1 * ylimit, ylimit),\n",
    "    xlabel=\"Time (s)\",\n",
    "    xticks=[0,abs(analysis_window[0]*monitor_fps)-1,n_datapoints-1],\n",
    "    xticklabels=([str(analysis_window[0]),'0', str(analysis_window[1])]),\n",
    ")\n",
    "sns.lineplot(x=\"frame_count\", y=\"instant_speed\",hue=\"labels\",data=ready_to_plot,ax=ax2)\n",
    "ylimit=10\n",
    "ax2.set(\n",
    "    ylim=(0, ylimit),\n",
    "    xlabel=\"Time (s)\",\n",
    "    xticks=[0,abs(analysis_window[0]*monitor_fps)-1,n_datapoints-1],\n",
    "    xticklabels=([str(analysis_window[0]),'0', str(analysis_window[1])]),\n",
    ")\n",
    "    # sns.move_legend(\n",
    "    #     axes[i], \"lower center\",\n",
    "    #     bbox_to_anchor=(.5, 1), ncol=3, title=None, frameon=False,\n",
    "    # )\n",
    "# fig_name = f\"constant_speed_constand_distance_speed1.jpg\"\n",
    "# fig.savefig(fig_name)\n",
    "# fig_name = f\"constant_speed_constand_distance_speed1.svg\"\n",
    "# fig.savefig(fig_name)"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ready_to_plot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[16]\u001B[39m\u001B[32m, line 8\u001B[39m\n\u001B[32m      3\u001B[39m n_datapoints=(analysis_window[\u001B[32m1\u001B[39m]-analysis_window[\u001B[32m0\u001B[39m])*monitor_fps\n\u001B[32m      4\u001B[39m fig, (ax1,ax2) = plt.subplots(\n\u001B[32m      5\u001B[39m     nrows=\u001B[32m2\u001B[39m, ncols=\u001B[32m1\u001B[39m, figsize=(\u001B[32m9\u001B[39m,\u001B[32m5\u001B[39m), tight_layout=\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m      6\u001B[39m )\n\u001B[32m----> \u001B[39m\u001B[32m8\u001B[39m sns.lineplot(x=\u001B[33m\"\u001B[39m\u001B[33mframe_count\u001B[39m\u001B[33m\"\u001B[39m, y=\u001B[33m\"\u001B[39m\u001B[33minstant_angular_velocity\u001B[39m\u001B[33m\"\u001B[39m,hue=\u001B[33m\"\u001B[39m\u001B[33mlabels\u001B[39m\u001B[33m\"\u001B[39m,data=\u001B[43mready_to_plot\u001B[49m,ax=ax1)\n\u001B[32m      9\u001B[39m ylimit=\u001B[32m5\u001B[39m\n\u001B[32m     10\u001B[39m ax1.set(\n\u001B[32m     11\u001B[39m     ylim=(-\u001B[32m1\u001B[39m * ylimit, ylimit),\n\u001B[32m     12\u001B[39m     xlabel=\u001B[33m\"\u001B[39m\u001B[33mTime (s)\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     13\u001B[39m     xticks=[\u001B[32m0\u001B[39m,\u001B[38;5;28mabs\u001B[39m(analysis_window[\u001B[32m0\u001B[39m]*monitor_fps)-\u001B[32m1\u001B[39m,n_datapoints-\u001B[32m1\u001B[39m],\n\u001B[32m     14\u001B[39m     xticklabels=([\u001B[38;5;28mstr\u001B[39m(analysis_window[\u001B[32m0\u001B[39m]),\u001B[33m'\u001B[39m\u001B[33m0\u001B[39m\u001B[33m'\u001B[39m, \u001B[38;5;28mstr\u001B[39m(analysis_window[\u001B[32m1\u001B[39m])]),\n\u001B[32m     15\u001B[39m )\n",
      "\u001B[31mNameError\u001B[39m: name 'ready_to_plot' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 900x500 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 16
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "matrexvr_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
